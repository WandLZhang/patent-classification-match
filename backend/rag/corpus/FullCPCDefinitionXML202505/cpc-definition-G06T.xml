<?xml version="1.0" encoding="UTF-8"?>
<definitions publication-date="2024-08-01" publication-type="official">
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T</classification-symbol><definition-title>IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Processor architectures or memory management for general purpose image data processing</paragraph-text></list-item><list-item><paragraph-text type="body">Geometric image transformations</paragraph-text></list-item><list-item><paragraph-text type="body">Image enhancement or restoration</paragraph-text></list-item><list-item><paragraph-text type="body">Image analysis</paragraph-text></list-item><list-item><paragraph-text type="body">Image coding</paragraph-text></list-item><list-item><paragraph-text type="body">Two-dimensional image generation</paragraph-text></list-item><list-item><paragraph-text type="body">Animation</paragraph-text></list-item><list-item><paragraph-text type="body">Three-dimensional image rendering</paragraph-text></list-item><list-item><paragraph-text type="body">Three-dimensional modelling for computer graphics</paragraph-text></list-item><list-item><paragraph-text type="body">Manipulating three-dimensional models or images for computer graphics</paragraph-text></list-item></list></section-body></definition-statement><relationship><section-title>Relationships with other classification places</section-title><section-body><paragraph-text type="body"><class-ref scheme="cpc">G06T</class-ref> is the functional place for image data processing or generation. Image data processing or generation specially adapted for a particular application is classified in the relevant subclass. Documents which merely mention the general use of image processing or generation without detailing of the underlying details of such, are classified in the application place. Where the essential technical characteristics of an invention relate both to the image processing or generation and to its particular use or special adaptation, classification is made in both <class-ref scheme="cpc">G06T</class-ref> and the application place.</paragraph-text></section-body></relationship><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.41cm"><paragraph-text type="body">Apparatus for radiation diagnosis</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">A61B6/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.41cm"><paragraph-text type="body">Aspects of games using an electronically generated display having two or more dimensions</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">A63F13/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.41cm"><paragraph-text type="body">Measuring, by optical means, length, thickness or similar linear dimensions, angles, areas, irregularities of surfaces or contours</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G01B11/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Reading or recognising printed or written characters or recognising patterns, e.g. fingerprints</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/00</class-ref>, <class-ref scheme="cpc">G06V</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.41cm"><paragraph-text type="body">Coding, decoding or code conversion</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H03M13/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.41cm"><paragraph-text type="body">Pictorial communication, television systems</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N1/00</class-ref> - <class-ref scheme="cpc">H04N21/00</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Symbols under <class-ref scheme="cpc">G06T1/00</class-ref> - <class-ref scheme="cpc">G06T19/20</class-ref> may only be allocated as invention information.</paragraph-text><paragraph-text type="body">Whenever possible, additional information should be classified using one or more of the Indexing Codes from the range of <class-ref scheme="cpc">G06T</class-ref>.</paragraph-text><paragraph-text type="body">The indexing codes under <class-ref scheme="cpc">G06T2200/00</class-ref> - <class-ref scheme="cpc">G06T2219/2024</class-ref> may only be allocated to documents to which a symbol under <class-ref scheme="cpc">G06T1/00</class-ref> - <class-ref scheme="cpc">G06T19/20</class-ref> is allocated as invention information as well.</paragraph-text><paragraph-text type="body">The following list of symbols from the series <class-ref scheme="cpc">G06T2200/00</class-ref>&#160;are for allocation to documents within the whole range of <class-ref scheme="cpc">G06T</class-ref>&#160;except <class-ref scheme="cpc">G06T9/00</class-ref>:</paragraph-text><table>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2200/00</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">Indexing scheme for image data processing or generation, in general - Not used for classification</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2200/04</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">involving 3D image data - processing of 3D image data, i.e. voxels; relevant for <class-ref scheme="cpc">G06T3/00</class-ref>, <class-ref scheme="cpc">G06T5/00</class-ref>, <class-ref scheme="cpc">G06T7/00</class-ref> or <class-ref scheme="cpc">G06T11/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2200/08</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">involving all processing steps from image acquisition to 3D model generation - complete systems from acquisition to modelling</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2200/12</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">involving antialiasing - dejagging, staircase effect</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2200/16</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">involving adaptation to the client&apos;s capabilities - adapting the colour or resolution of an image to the client&apos;s capabilities</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2200/21</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">involving computational photography</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2200/24</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">involving graphical user interfaces [GUIs]</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2200/28</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">involving image processing hardware - relevant for groups not directly related to hardware; not used in <class-ref scheme="cpc">G06T1/20</class-ref>, <class-ref scheme="cpc">G06T1/60</class-ref>, <class-ref scheme="cpc">G06T15/005</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2200/32</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">involving image mosaicing - image mosaicing, panoramic images</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2200/36</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">Review paper; Tutorial; Survey - basic documents describing the state of the art.</paragraph-text></table-column></table-row></table><paragraph-text type="body">There are further series of symbols for <class-ref scheme="cpc">G06T</class-ref> whose use is reserved to particular maingroups or ranges of maingroups and whose full list and description are given in the FCRs of the respective maingroups:</paragraph-text><paragraph-text type="body"><class-ref scheme="cpc">G06T2201/00</class-ref> for <class-ref scheme="cpc">G06T1/0021</class-ref> only</paragraph-text><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/00</class-ref> for <class-ref scheme="cpc">G06T5/00</class-ref> and <class-ref scheme="cpc">G06T7/00</class-ref> only</paragraph-text><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/00</class-ref> for <class-ref scheme="cpc">G06T9/00</class-ref> only</paragraph-text><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/00</class-ref> for <class-ref scheme="cpc">G06T11/00</class-ref>&#160;-&#160;<class-ref scheme="cpc">G06T19/00</class-ref> only; see list below</paragraph-text><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/40</class-ref> for <class-ref scheme="cpc">G06T11/003</class-ref> only</paragraph-text><paragraph-text type="body"><class-ref scheme="cpc">G06T2213/00</class-ref> for <class-ref scheme="cpc">G06T13/00</class-ref> only;</paragraph-text><paragraph-text type="body"><class-ref scheme="cpc">G06T2215/00</class-ref> for <class-ref scheme="cpc">G06T15/00</class-ref> only;</paragraph-text><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/00</class-ref> for <class-ref scheme="cpc">G06T19/00</class-ref> only;</paragraph-text><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/20</class-ref> for <class-ref scheme="cpc">G06T19/20</class-ref> only</paragraph-text><paragraph-text type="body">Symbols from the series <class-ref scheme="cpc">G06T2210/00</class-ref> for allocation in the range of <class-ref scheme="cpc">G06T11/00</class-ref>&#160;-&#160;<class-ref scheme="cpc">G06T19/00</class-ref> only:</paragraph-text><table>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/00</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">Indexing scheme for image generation or computer graphics - Not used for classification</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/04</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">architectural design, interior design - interior/garden/facade design, architectural layout plans</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/08</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">bandwidth reduction</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/12</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">bounding box - convex hull for polygons or 3D objects</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/16</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">cloth - animation, rendering or modeling of cloth/garment/textile, virtual dressing rooms</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/21</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">collision detection, intersection - intersection/collision detection of 3D objects</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/22</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">cropping - cropping of image borders</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/24</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">fluid dynamics - animation, rendering or modelling of fluid flows</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/28</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">force feedback - virtual force</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/32</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">image data format - conversion between different image or graphics formats</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/36</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">level of detail - level of detail, also for textures (e.g. mip-mapping)</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/41</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">medical - medical applications concerning e.g. heart, lung, brain, tumors</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/44</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">morphing - morphing or warping</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/52</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">parallel processing</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/56</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">particle system, point based geometry or rendering - rendering and animation of particle systems (e.g. fireworks, dust, clouds), point clouds, splatting</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/61</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">scene description - scene graphs, scene description languages, e.g. VRML</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/62</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">semi-transparency - screen-door effect, change of transparency values</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="3.17cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2210/64</class-ref></paragraph-text></table-column><table-column preferred-width="11.84cm"><paragraph-text type="body">weathering - weathering effects like e.g. aging, corrosion</paragraph-text></table-column></table-row></table></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">2D</paragraph-text></table-column><table-column><paragraph-text type="body">Two-dimensional</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">3D</paragraph-text></table-column><table-column><paragraph-text type="body">Three-dimensional</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">4D</paragraph-text></table-column><table-column><paragraph-text type="body">Four-dimensional, 3D in time</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">CAD</paragraph-text></table-column><table-column><paragraph-text type="body">Computer-Aided Design (in computer graphics); Computer-Aided Detection (in image analysis)</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">MR</paragraph-text></table-column><table-column><paragraph-text type="body">Magnetic Resonance (in image analysis); Mixed Reality (in computer graphics)</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Stereo</paragraph-text></table-column><table-column><paragraph-text type="body">Treatment of the images of exactly two cameras in a pairwise manner</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><abbreviations>
<paragraph-text type="preamble">In patent documents, the following abbreviations are often used:</paragraph-text>
<table>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">ANN</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Artificial Neural Network</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">AR</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Augmented Reality</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">CT</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Computed Tomography</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">DCE-MRI</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Dynamic Contrast-Enhanced Magnetic Resonance Imaging</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">DCT</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Discrete Cosine Transform</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">DRR</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Digitally Reconstructed Radiograph</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">DTS</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Digital Tomosynthesis</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">GUI</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Graphical User Interface</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">IC</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Integrated Circuit</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">ICP</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Iterative Closest Point</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">LCD</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Liquid Crystal Display</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">MRF</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Markov Random Field</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">MRI</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Magnetic Resonance Imaging</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">PCB</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Printed Circuit Board</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">RGB</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Red, Green, Blue</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">ROI</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Region of Interest</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">SLAM</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Simultaneous Localisation And Mapping</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">SNR</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Signal-to-Noise Ratio</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">SPECT</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Single Photon Emission Computed Tomography</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">US</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Ultrasound</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">VOI</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Volume of Interest</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">VR</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">Virtual Reality</paragraph-text></table-column></table-row></table>
</abbreviations></synonyms-keywords></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T1/00</classification-symbol><definition-title>General purpose image data processing</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">General purpose image data processing systems and methods.</paragraph-text></section-body></definition-statement><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">The IPC class <class-ref scheme="not-mapped">G06T1/40</class-ref> is not used. The corresponding documents are classified in <class-ref scheme="cpc">G06T1/20</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T1/0007</classification-symbol><definition-title>{Image acquisition}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Capturing or storing images from or to memory</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Scanning, transmission or reproduction of documents or the like</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N1/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body"> Television cameras</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N23/00</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T1/0014</classification-symbol><definition-title>{Image feed-back for automatic industrial control, e.g. robot with camera  (robots <class-ref scheme="cpc">B25J19/023</class-ref>)}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Machine vision or tool control</paragraph-text></list-item><list-item><paragraph-text type="body">Image feedback for robot navigation or walking</paragraph-text></list-item><list-item><paragraph-text type="body">3D vision systems.</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Vision controlled manipulators</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">B25J9/1697</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Accessories fitted to manipulators including video camera means</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">B25J19/023</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Control of position, course, altitude or attitude of land, water, air or space vehicles using means capturing signals occurring naturally from the environment for determining position or orientation</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G05D1/243</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references></definition-item>
<definition-item date-revised="2017-08-01"><classification-symbol scheme="cpc">G06T1/0021</classification-symbol><definition-title>{Image watermarking}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Image watermarking in general.</paragraph-text></list-item><list-item><paragraph-text type="body">Applications or software packages for watermarking.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example - Hiding a digital image (message) into another digital image (carrier) (US6094483 - UNIV NEW YORK STATE RES FOUND):</paragraph-text><paragraph-text type="body"><media id="media0.png" file-name="cpc-def-G06T-0000.png" type="png" preferred-width="8.9cm" preferred-height="5.22cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Testing specially adapted to determine the identity or genuineness of paper currency or similar valuable papers</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G07D7/1205</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body"> Audio watermarking</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G10L19/018</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Arrangements for secret or secure communication using encryption of data</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04L9/06</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Arrangements for secret or secure communication using electronic signatures</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04L9/3247</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body"> Security arrangements for protecting computers or computer systems against unauthorised activity</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F21/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Circuits for prevention of unauthorised reproduction or copying</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G11B20/00086</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body"> Scanning, transmission or reproduction of documents involving image watermarking</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N1/32144</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T1/0028</classification-symbol><definition-title>{Adaptive watermarking, e.g. Human Visual System [HVS]-based watermarking}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Adaptations based on Human Visual System [HVS].</paragraph-text></list-item><list-item><paragraph-text type="body">Perceptual masking.</paragraph-text></list-item><list-item><paragraph-text type="body">Preservation of image quality; Distortion minimization.</paragraph-text></list-item><list-item><paragraph-text type="body">Methods to measure quality of watermarked images.</paragraph-text></list-item><list-item><paragraph-text type="body">Measuring the balance between quality and robustness, i.e., fixed robustness, adapting quality, or vice versa.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example - Changing a portion of an image based on an embedding strength map (EP1170938 - HITACHI LTD):</paragraph-text><paragraph-text type="body"><media id="media1.jpg" file-name="cpc-def-G06T-0001.jpg" type="jpeg" preferred-width="9.13cm" preferred-height="6.78cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T1/0035</classification-symbol><definition-title>{Output size adaptive watermarking}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Embedding without modifying the size of input.</paragraph-text></list-item><list-item><paragraph-text type="body">Embedding or modifying the watermark directly in a coded image or video stream, without decoding first.</paragraph-text></list-item></list></section-body></definition-statement></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T1/0042</classification-symbol><definition-title>{Fragile watermarking, e.g. so as to detect tampering}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Birthday attacks.</paragraph-text></list-item><list-item><paragraph-text type="body">Forgery.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example - Changing pixels at selected positions according to a replacement table (WO2011021114 - NDS LIMITED):</paragraph-text><paragraph-text type="body"><media id="media2.png" file-name="cpc-def-G06T-0002.png" type="png" preferred-width="5.16cm" preferred-height="6.31cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T1/005</classification-symbol><definition-title>{Robust watermarking, e.g. average attack or collusion attack resistant}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Resistance; Resistance to attacks or distortions; Distortion compensation.</paragraph-text></list-item><list-item><paragraph-text type="body">Strength.</paragraph-text></list-item><list-item><paragraph-text type="body">Collusion attacks; Average attacks; Averaging.</paragraph-text></list-item><list-item><paragraph-text type="body">Reliable detection, e.g. with reduced likelihood of false positive/negative.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example - Watermarking an image using the difference of average intensity of two adjacent blocks (EP1927948 - FUJITSU LTD):</paragraph-text><paragraph-text type="body"><media id="media3.png" file-name="cpc-def-G06T-0003.png" type="png" preferred-width="6.17cm" preferred-height="5.34cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T1/0057</classification-symbol><definition-title>{Compression invariant watermarking}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Watermarking techniques for JPEG or MPEG or for a wavelet transformed image.</paragraph-text><paragraph-text type="body">Illustrative example - Embedded a watermark in a DC component region of a wavelet transformed image (US2004047489 - KOREA ELECTRONICS TELECOMM):</paragraph-text><paragraph-text type="body"><media id="media4.png" file-name="cpc-def-G06T-0004.png" type="png" preferred-width="8.26cm" preferred-height="4.87cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T1/0064</classification-symbol><definition-title>{Geometric transfor invariant watermarking, e.g. affine transform invariant}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Robust against resizing or rotation or cropping, etc.</paragraph-text></list-item><list-item><paragraph-text type="body">Determining the rescaling factor or rotation angle by using the watermarks so as to compensate the image, i.e. as a calibration signal.</paragraph-text></list-item><list-item><paragraph-text type="body">Desynchronization attacks.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example - Combining a reference mark with an identification mark and embedding them in image textures to detect the applied transformations (GB2378602 - CENTRAL RESEARCH LAB LTD):</paragraph-text><paragraph-text type="body"><media id="media5.png" file-name="cpc-def-G06T-0005.png" type="png" preferred-width="7.93cm" preferred-height="4.34cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T1/0071</classification-symbol><definition-title>{using multiple or alternating watermarks}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Many, possibly different, watermarks on the same image, e.g. for copy or distribution control.</paragraph-text></list-item><list-item><paragraph-text type="body">Same watermark repeated on different parts of the image.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example - Encoding payload in relative positions and/or polarities of multiple embedded watermarks (WO0111563 - KONINKL PHILIPS ELECTRONICS NV):</paragraph-text><paragraph-text type="body"><media id="media6.png" file-name="cpc-def-G06T-0006.png" type="png" preferred-width="6.03cm" preferred-height="4.56cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T1/0078</classification-symbol><definition-title>{using multiple thresholds}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Using thresholds to define ranges of detection probability or ranges of robustness.</paragraph-text><paragraph-text type="body">Illustrative example - Multiple thresholds for reducing false detection likelihood</paragraph-text><paragraph-text type="body">(EP1271401 - SONY UK LTD):</paragraph-text><paragraph-text type="body"><media id="media7.png" file-name="cpc-def-G06T-0007.png" type="png" preferred-width="7.09cm" preferred-height="3.92cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T1/0085</classification-symbol><definition-title>{Time domain based watermarking, e.g. watermarks spread over several images}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Watermarks spread over several images or frames or a sequence.</paragraph-text><paragraph-text type="body">Illustrative example - Alternating watermark patterns (e.g. by translation, mirror, rotation) to improve the reliability of scale factor measurement (WO2005109338 - KONINKL PHILIPS ELECTRONICS NV):</paragraph-text><paragraph-text type="body"><media id="media8.png" file-name="cpc-def-G06T-0008.png" type="png" preferred-width="6.02cm" preferred-height="4.25cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T1/0092</classification-symbol><definition-title>{Payload characteristic determination in a watermarking scheme, e.g. number of bits to be embedded}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Illustrative example - Calculating capacity of DCT coefficients of a digital image file and selecting the ones apted to embedding, thereby providing robustness (US6724913 - HSU WEN-HSING):</paragraph-text><paragraph-text type="body"><media id="media9.png" file-name="cpc-def-G06T-0009.png" type="png" preferred-width="8.57cm" preferred-height="4.78cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2019-01-01"><classification-symbol scheme="cpc">G06T1/20</classification-symbol><definition-title>Processor architectures; Processor configuration, e.g. pipelining</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Graphics accelerators; Graphic processing units (GPUs).</paragraph-text></list-item><list-item><paragraph-text type="body">Graphics pipelines.</paragraph-text></list-item><list-item><paragraph-text type="body">Parallel or massively parallel data bus specially adapted for image data processing.</paragraph-text></list-item><list-item><paragraph-text type="body">Architecture or signal processor specially adapted for image data processing.</paragraph-text></list-item><list-item><paragraph-text type="body">VLSI or SIMD or fine-grained machines specially adapted for image data processing.</paragraph-text></list-item><list-item><paragraph-text type="body">Multiprocessor or multicomputer or multi-core specially adapted for image data processing.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example - Ring architecture for image data processing:</paragraph-text><paragraph-text type="body"><media id="media10.jpg" file-name="cpc-def-G06T-0010.jpg" type="jpeg" preferred-width="7.75cm" preferred-height="7.15cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Architectures of general purpose stored program computers</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F15/76</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Pipelining</paragraph-text></table-column><table-column><paragraph-text type="body">the use of a sequence (pipeline) of image processing stages for execution of instructions in a series of units, arranged so that several units can be used for simultaneously processing appropriate parts of several instructions.</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Multiprocessor</paragraph-text></table-column><table-column><paragraph-text type="body">processor arrangements comprising a computer system consisting of two or more processors for the simultaneous execution of two or more programs or sequences of instructions.</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><abbreviations>
<paragraph-text type="preamble">In patent documents, the following abbreviations are often used:</paragraph-text>
<table>
<table-row><table-column><paragraph-text type="body">GPU</paragraph-text></table-column><table-column><paragraph-text type="body">Graphics Processing Unit</paragraph-text></table-column></table-row></table>
</abbreviations></synonyms-keywords></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T1/60</classification-symbol><definition-title>Memory management</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Address generation or addressing circuit or BitBlt for image data processing.</paragraph-text></list-item><list-item><paragraph-text type="body">3D or virtual or cache memory specially adapted for image data processing.</paragraph-text></list-item><list-item><paragraph-text type="body">Frame or screen or image memory specially adapted for image data processing.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example - Cache memory for image processing (EP0589724 - QUANTEL LTD)</paragraph-text><paragraph-text type="body"><media id="media11.jpg" file-name="cpc-def-G06T-0011.jpg" type="jpeg" preferred-width="8.99cm" preferred-height="5.61cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Accessing, addressing or allocating within memory systems or architectures</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F12/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body"> Ping-pong buffers</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G09G5/399</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Arrangements for selecting an address in a digital store</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G11C8/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Digital stores characterised by the use of particular electric or magnetic storage elements</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G11C11/00</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/00</classification-symbol><definition-title>Geometric image transformations in the plane of the image</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Geometric image transformations in the plane of the image.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Image enhancement or restoration</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T5/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image animation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T13/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Geometric effects for 3D image rendering</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T15/10</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Perspective computation for 3D image rendering</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T15/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Geographic models in 3D modelling for computer graphics</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T17/05</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Matrix or vector computation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F17/16</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Conversion of standards for television systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N7/01</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/02</classification-symbol><definition-title>Affine transformations  (for image registration <class-ref scheme="cpc">G06T3/147</class-ref>; for image mosaicing <class-ref scheme="cpc">G06T3/4038</class-ref>)</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Affine transformations not further specified.</paragraph-text></list-item><list-item><paragraph-text type="body">Combinations of affine transformations including rotation, scaling or shear.</paragraph-text></list-item></list></section-body></definition-statement><relationship><section-title>Relationships with other classification places</section-title><section-body><paragraph-text type="body">This place covers the combination of rotation, scaling or shear. When the invention information in the document involves image scaling or image rotation per se, the image scaling should be classified in group <class-ref scheme="cpc">G06T3/40</class-ref>, and the image rotation should be classified in group <class-ref scheme="cpc">G06T3/60</class-ref>.</paragraph-text></section-body></relationship><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Transformations for image registration using affine transformations</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T3/147</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image mosaicing, e.g. composing plane images from plane sub-images</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T3/4038</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/04</classification-symbol><definition-title>Context-preserving transformations, e.g. by using an importance map  (panospheric to cylindrical image transformations <class-ref scheme="cpc">G06T3/12</class-ref>)</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Selective warping according to an importance map; Smart image reduction.</paragraph-text></list-item><list-item><paragraph-text type="body">Seam carving; Liquid resizing; Image retargeting.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media12.jpg" file-name="cpc-def-G06T-0012.jpg" type="jpeg" preferred-width="7.47cm" preferred-height="5.21cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Panospheric to cylindrical image transformation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T3/12</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/047</classification-symbol><definition-title>Fisheye or wide-angle transformations</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Establishing a lens for a region-of-interest.</paragraph-text><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media13.jpg" file-name="cpc-def-G06T-0013.jpg" type="jpeg" preferred-width="8.36cm" preferred-height="9.25cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/053</classification-symbol><definition-title>Detail-in-context presentations  (fisheye or wide-angle transformations <class-ref scheme="cpc">G06T3/047</class-ref>)</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Side or corner panels; Perspective wall.</paragraph-text></list-item><list-item><paragraph-text type="body">Document lens.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media230.png" file-name="cpc-def-G06T-0230.png" type="png" preferred-width="14.31cm" preferred-height="10.27cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Fisheye, wide-angle transformation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T3/047</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/06</classification-symbol><definition-title>Topological mapping of higher dimensional structures onto lower dimensional surfaces</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Flattening the scanned image of a bound book.</paragraph-text><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media15.png" file-name="cpc-def-G06T-0015.png" type="png" preferred-width="12.96cm" preferred-height="10.65cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Panospheric to cylindrical image transformation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T3/12</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Texture mapping</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T15/04</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Manipulating 3D models or images for computer graphics</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/067</classification-symbol><definition-title>Reshaping or unfolding 3D tree structures onto 2D planes</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Curved planar reformation [CPR].</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Manipulating 3D models or images for computer graphics</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/073</classification-symbol><definition-title>Transforming surfaces of revolution to planar images, e.g. cylindrical surfaces to planar images</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Mapping a surface of revolution to a plane, e.g. mapping a pot or a can to a plane.</paragraph-text><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media231.png" file-name="cpc-def-G06T-0231.png" type="png" preferred-width="12.32cm" preferred-height="16.11cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T3/08</classification-symbol><definition-title>Projecting images onto non-planar surfaces, e.g. geodetic screens</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Geometric image transformation for projecting an image on a multi-projectors system or on a geodetic screen; Dome imaging.</paragraph-text></list-item><list-item><paragraph-text type="body">Geometric image transformation for projecting an image through multi-planar displays.</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body"> Texture mapping</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T15/04</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/10</classification-symbol><definition-title>Selection of transformation methods according to the characteristics of the input images</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Selecting the interpolation method depending on the scale factor.</paragraph-text></list-item><list-item><paragraph-text type="body">Selecting the interpolation method depending on media type or image appearance characteristics.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media17.png" file-name="cpc-def-G06T-0017.png" type="png" preferred-width="12.19cm" preferred-height="6.37cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/12</classification-symbol><definition-title>Panospheric to cylindrical image transformations</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Omnidirectional or hyperboloidal to cylindrical image transformation or mapping; Catadioptric transformation, e.g. images from surveillance cameras.</paragraph-text></list-item><list-item><paragraph-text type="body">Panospheric image transformation or mapping by using the output of a multiple cameras system.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media232.png" file-name="cpc-def-G06T-0232.png" type="png" preferred-width="13.55cm" preferred-height="16.26cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/14</classification-symbol><definition-title>Transformations for image registration, e.g. adjusting or mapping for alignment of images</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Geometric image transformations:</paragraph-text><list><list-item><paragraph-text type="body">for iterative image registration;</paragraph-text></list-item><list-item><paragraph-text type="body">for spline-based image registration;</paragraph-text></list-item><list-item><paragraph-text type="body">for mutual-information-based registration;</paragraph-text></list-item><list-item><paragraph-text type="body">for phase correlation or FFT-based methods;</paragraph-text></list-item><list-item><paragraph-text type="body">using fiducial points, e.g. landmarks;</paragraph-text></list-item><list-item><paragraph-text type="body">for maximised mutual information-based methods.</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Determination of transform parameters for the alignment of images, i.e. image registration</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/30</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/153</classification-symbol><definition-title>using elastic snapping</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Elastic mapping or snapping or matching; Deformable mapping.</paragraph-text></list-item><list-item><paragraph-text type="body">Diffeomorphic representations of deformations to control the image registration process.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media233.png" file-name="cpc-def-G06T-0233.png" type="png" preferred-width="5.52cm" preferred-height="9.06cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T3/16</classification-symbol><definition-title>Spatio-temporal transformations, e.g. video cubism</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Video cubism; Video cube.</paragraph-text></list-item><list-item><paragraph-text type="body">Dynamic panoramic video.</paragraph-text></list-item><list-item><paragraph-text type="body">Stylized video cubes.</paragraph-text></list-item></list></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T3/18</classification-symbol><definition-title>Image warping, e.g. rearranging pixels individually</definition-title><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Image animation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T13/00</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/40</classification-symbol><definition-title>Scaling of whole images or parts thereof, e.g. expanding or contracting</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Resampling; Resolution conversion.</paragraph-text></list-item><list-item><paragraph-text type="body">Zooming or expanding or magnifying or enlarging or upscaling.</paragraph-text></list-item><list-item><paragraph-text type="body">Shrinking or reducing or compressing or downscaling.</paragraph-text></list-item><list-item><paragraph-text type="body">Pyramidal partitions; Storing sub-sampled copies.</paragraph-text></list-item><list-item><paragraph-text type="body">Area based or weighted interpolation; Scaling by surface fitting, e.g. piecewise polynomial surfaces, B-splines or Beta-splines.</paragraph-text></list-item><list-item><paragraph-text type="body">Two-steps image scaling, e.g. by stretching.</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Control of means for changing angle of the field of view, e.g. optical zoom objectives or electronic zooming</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/69</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Polynomial surface description for image modeling</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T17/30</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Enlarging or reducing for scanning, transmission or reproduction of documents or the like, e.g. facsimile transmission</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/393</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Studio circuits for television systems involving alteration of picture size or orientation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N5/2628</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Frame rate conversion; De-interlacing</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N7/01</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving spatial sub-sampling or interpolation, e.g. alteration of picture size or resolution</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N19/59</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/4007</classification-symbol><definition-title>based on interpolation, e.g. bilinear interpolation  (image demosaicing <class-ref scheme="cpc">G06T3/4015</class-ref>; edge-driven or edge-based scaling <class-ref scheme="cpc">G06T3/403</class-ref>)</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Linear or bi-linear or tetrahedral or cubic image interpolation.</paragraph-text></list-item><list-item><paragraph-text type="body">Adaptive interpolation, e.g. the coefficients of the interpolation depend on the pattern of the local structure.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media234.png" file-name="cpc-def-G06T-0234.png" type="png" preferred-width="11.43cm" preferred-height="6.77cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Image demosaicing, e.g. colour filter arrays [CFA] or Bayer patterns</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T3/4015</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Edge-driven scaling; Edge-based scaling</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T3/403</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/4015</classification-symbol><definition-title>Image demosaicing, e.g. colour filter arrays [CFA] or Bayer patterns</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">CFA demosaicing or demosaicking or interpolating.</paragraph-text></list-item><list-item><paragraph-text type="body">Bayer pattern.</paragraph-text></list-item><list-item><paragraph-text type="body">Colour-separated images, i.e. one colour in each image quadrant.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples of subject matter classified in this place: </paragraph-text><paragraph-text type="body">1. Image demosaicing</paragraph-text><paragraph-text type="body"><media id="media235.png" file-name="cpc-def-G06T-0235.png" type="png" preferred-width="9.95cm" preferred-height="6.41cm"/></paragraph-text><paragraph-text type="body">2. Colour-separated image</paragraph-text><paragraph-text type="body"><media id="media23.png" file-name="cpc-def-G06T-0023.png" type="png" preferred-width="5.72cm" preferred-height="4.71cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/4023</classification-symbol><definition-title>based on decimating pixels or lines of pixels; based on inserting pixels or lines of pixels</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Pixel or row deletion or removal.</paragraph-text></list-item><list-item><paragraph-text type="body">Pixel or row insertion or duplication or replication.</paragraph-text></list-item><list-item><paragraph-text type="body">Decimating FIR filters.</paragraph-text></list-item><list-item><paragraph-text type="body">Array indexes or tables, e.g. LUT.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body">Decimating by using two arrays of indexes</paragraph-text><paragraph-text type="body"><media id="media236.png" file-name="cpc-def-G06T-0236.png" type="png" preferred-width="10.63cm" preferred-height="4.09cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/403</classification-symbol><definition-title>Edge-driven scaling; Edge-based scaling</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Edge adaptive or directed or dependent or following or preserving interpolation; Edge preservation.</paragraph-text></list-item><list-item><paragraph-text type="body">Edge map injecting or projecting or combining or superimposing.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body">Correcting for abnormalities next to boundaries</paragraph-text><paragraph-text type="body"><media id="media237.png" file-name="cpc-def-G06T-0237.png" type="png" preferred-width="9.53cm" preferred-height="9.78cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/4038</classification-symbol><definition-title>Image mosaicing, e.g. composing plane images from plane sub-images</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Image mosaicing or mosaiking.</paragraph-text></list-item><list-item><paragraph-text type="body">Panorama views.</paragraph-text></list-item><list-item><paragraph-text type="body">Mosaic of video sequences; Salient video still; Video collage or synopsis.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body">Image mosaicing for microscopy applications</paragraph-text><paragraph-text type="body"><media id="media238.png" file-name="cpc-def-G06T-0238.png" type="png" preferred-width="14.1cm" preferred-height="9.69cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Image processing arrangements associated with discharge tubes with provision for introducing objects or material to be exposed to the discharge</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H01J37/222</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/4046</classification-symbol><definition-title>using neural networks</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Using neural networks specially adapted for image interpolation.</paragraph-text></list-item><list-item><paragraph-text type="body">Using neural networks specially adapted for interpolation coefficient selection.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body">Using a neural network to select the coefficients of a polynomial interpolation</paragraph-text><paragraph-text type="body"><media id="media27.png" file-name="cpc-def-G06T-0027.png" type="png" preferred-width="6.98cm" preferred-height="6.99cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Image enhancement or restoration using machine learning, e.g. neural networks</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T5/60</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Neural networks</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06N3/02</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Machine learning</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06N20/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Arrangements for image or video recognition or understanding using pattern recognition or machine learning using neural networks</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/82</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/4053</classification-symbol><definition-title>based on super-resolution, i.e. the output image resolution being higher than the sensor resolution</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Super resolution by fitting the pixel intensity to a mathematical function.</paragraph-text></list-item><list-item><paragraph-text type="body">Super resolution from image sequences; Images or frames addition, coaddition or combination.</paragraph-text></list-item><list-item><paragraph-text type="body">Super resolution by iteratively applying constraints, e.g. energy reduction, on the transform domain and inverse transforming.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body">Fitting a mathematical function and resampling:</paragraph-text><paragraph-text type="body"><media id="media239.png" file-name="cpc-def-G06T-0239.png" type="png" preferred-width="7.96cm" preferred-height="12.13cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Image enhancement or restoration using two or more images, e.g. averaging or subtraction</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T5/50</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/4061</classification-symbol><definition-title>by injecting details from different spectral ranges</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Fusion of multi-sensor or multiband images fusion.</paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/4069</classification-symbol><definition-title>by subpixel displacements</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body">Displaying sub-frames at spatially offset positions</paragraph-text><paragraph-text type="body"><media id="media29.png" file-name="cpc-def-G06T-0029.png" type="png" preferred-width="5.72cm" preferred-height="5.36cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/4076</classification-symbol><definition-title>using the original low-resolution images to iteratively correct the high-resolution images</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body">Iterative correction of the high-resolution image:</paragraph-text><paragraph-text type="body"><media id="media30.png" file-name="cpc-def-G06T-0030.png" type="png" preferred-width="5.04cm" preferred-height="10.0cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/4084</classification-symbol><definition-title>in the transform domain, e.g. fast Fourier transform [FFT] domain scaling</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">DCT coefficients decimation or insertion for image scaling.</paragraph-text></list-item><list-item><paragraph-text type="body">Zero padding DCT coefficients for image scaling.</paragraph-text></list-item><list-item><paragraph-text type="body">Downscaling by selecting a specific wavelet sub-band.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body">Enlargement/reduction through DCT interpolation/decimation</paragraph-text><paragraph-text type="body"><media id="media31.png" file-name="cpc-def-G06T-0031.png" type="png" preferred-width="9.2cm" preferred-height="11.9cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/4092</classification-symbol><definition-title>Image resolution transcoding, e.g. by using client-server architectures</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Adapting the image resolution to the client&apos;s capabilities.</paragraph-text><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media240.png" file-name="cpc-def-G06T-0240.png" type="png" preferred-width="16cm" preferred-height="9.81cm"/></paragraph-text><paragraph-text type="body">In the figure above, the processing unit is coupled downstream from video cross-point switcher for generating additionally scaled video streams by additional video scaling on initially scaled video stream.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N19/10</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using video transcoding, i.e. partial or full decoding of a coded input stream followed by re-encoding of the decoded output stream</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N19/40</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Server adapted for processing of video elementary streams, involving reformatting operations of video signals for distribution or compliance with end-user requests or end-user device requirements</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N21/234363</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Selective content distribution in client devices adapted for processing of additional data</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N21/4356</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Selective content distribution in client devices adapted for processing of video elementary streams involving reformatting operations of video signals for household redistribution, storage or real-time display</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N21/440263</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/60</classification-symbol><definition-title>Rotation of whole images or parts thereof</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Transpose or continuous write-transpose-read.</paragraph-text></list-item><list-item><paragraph-text type="body">Mirror.</paragraph-text></list-item><list-item><paragraph-text type="body">Rung-length (RL) rotation.</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Scanning, transmission or reproduction of documents involving composing, repositioning or otherwise modifying originals</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/3877</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Studio circuits for television</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N5/262</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/602</classification-symbol><definition-title>by block rotation, e.g. by recursive reversal or rotation</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body">Rotation by recursive reversing</paragraph-text><paragraph-text type="body"><media id="media33.png" file-name="cpc-def-G06T-0033.png" type="png" preferred-width="6.56cm" preferred-height="8.92cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/606</classification-symbol><definition-title>by memory addressing or mapping</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body">Continuous read-transpose-write</paragraph-text><paragraph-text type="body"><media id="media241.png" file-name="cpc-def-G06T-0241.png" type="png" preferred-width="7.77cm" preferred-height="7.75cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T3/608</classification-symbol><definition-title>by skew deformation, e.g. two-pass or three-pass rotation</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Shift processing;</paragraph-text></list-item><list-item><paragraph-text type="body">Rotation by shearing.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body">Image rotation by two-pass de-skewing</paragraph-text><paragraph-text type="body"><media id="media242.png" file-name="cpc-def-G06T-0242.png" type="png" preferred-width="8.95cm" preferred-height="10.41cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/00</classification-symbol><definition-title>Image enhancement or restoration</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Image enhancement or restoration:</paragraph-text><list><list-item><paragraph-text type="body">using non-spatial domain filtering;</paragraph-text></list-item><list-item><paragraph-text type="body">using local operators;</paragraph-text></list-item><list-item><paragraph-text type="body">using morphological operators, i.e. erosion or dilatation;</paragraph-text></list-item><list-item><paragraph-text type="body">using histogram techniques;</paragraph-text></list-item><list-item><paragraph-text type="body">using two or more images, e.g. averaging or subtraction;</paragraph-text></list-item><list-item><paragraph-text type="body">using machine learning, e.g. neural networks;</paragraph-text></list-item><list-item><paragraph-text type="body">Denoising; Smoothing;</paragraph-text></list-item><list-item><paragraph-text type="body">Deblurring; Sharpening;</paragraph-text></list-item><list-item><paragraph-text type="body">Unsharp masking;</paragraph-text></list-item><list-item><paragraph-text type="body">Retouching; Inpainting; Scratch removal;</paragraph-text></list-item><list-item><paragraph-text type="body">Geometric correction;</paragraph-text></list-item><list-item><paragraph-text type="body">Dynamic range modification of images or parts thereof.</paragraph-text></list-item></list></section-body></definition-statement><relationship><section-title>Relationships with other classification places</section-title><section-body><paragraph-text type="body">Group <class-ref scheme="cpc">G06T5/00</class-ref>&#160;is the function place for image enhancement or restoration. Image enhancement or restoration specially adapted for a particular application is classified in the relevant application field, e.g. in subclasses&#160;<class-ref scheme="cpc">G06V</class-ref>&#160;or&#160;<class-ref scheme="cpc">H04N</class-ref>.</paragraph-text></section-body></relationship><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Circuitry for compensating brightness variation in the scene in cameras or camera modules comprising electronic image sensors</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/70</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Camera processing pipelines in cameras or camera modules comprising electronic image sensors</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/80</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Noise processing, e.g. detecting, correcting, reducing or removing noise in circuitry of solid-state image sensors [SSIS]</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N25/60</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Neural networks</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06N3/02</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image preprocessing for image or video recognition or understanding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image processing adapted to be used in scanners, printers, photocopying machines, displays or similar devices, including composing, repositioning or otherwise modifying originals</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/387</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Picture signal circuits adapted to be used in scanners, printers, photocopying machines, displays or similar devices</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/40</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Processing of colour picture signals in scanners, printers, photocopying machines, displays or similar devices</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/56</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Computational photography systems, e.g. light-field imaging systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/95</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">This group focuses on image processing algorithms. Although such algorithms sometimes need to consider characteristics of the underlying image acquisition apparatus, inventions to the image acquisition apparatus per se are outside the scope of this group.</paragraph-text><paragraph-text type="body">Whenever possible, additional information should be classified using one or more of the indexing codes from the ranges of&#160;<class-ref scheme="cpc">G06T2200/00</class-ref> (see definitions re.&#160;<class-ref scheme="cpc">G06T</class-ref>) or&#160;<class-ref scheme="cpc">G06T2207/00</class-ref>&#160;(see definitions re.&#160;<class-ref scheme="cpc">G06T2207/00</class-ref>).</paragraph-text><paragraph-text type="body">The classification symbol <class-ref scheme="cpc">G06T5/00</class-ref> should be allocated to documents concerning:</paragraph-text><list><list-item><paragraph-text type="body">Interactive / multiple choice image processing, e.g. choosing outputs from multiple enhancement algorithms;</paragraph-text></list-item><list-item><paragraph-text type="body">Image restoration based on properties or models of the human vision system [HVS]</paragraph-text></list-item></list></section-body></special-rules><synonyms-keywords><section-title>Synonyms and Keywords</section-title><abbreviations>
<paragraph-text type="preamble">In patent documents, the following abbreviations are often used:</paragraph-text>
<table>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">HDR</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">high dynamic range</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">HDRI</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">high dynamic range imaging</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">HMM</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">hidden Markov model</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.6cm"><paragraph-text type="body">PSF</paragraph-text></table-column><table-column preferred-width="7.43cm"><paragraph-text type="body">point spread function</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">SDR</paragraph-text></table-column><table-column><paragraph-text type="body">standard dynamic range</paragraph-text></table-column></table-row></table>
</abbreviations></synonyms-keywords></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/10</classification-symbol><definition-title>using non-spatial domain filtering</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">All transform domain-based enhancement methods, e.g. using:</paragraph-text><list><list-item><paragraph-text type="body">Fourier transform, discrete Fourier transform [DFT] or fast Fourier transform [FFT]; </paragraph-text></list-item><list-item><paragraph-text type="body">Hadamard transform;</paragraph-text></list-item><list-item><paragraph-text type="body">Discrete cosine transform [DCT]; </paragraph-text></list-item><list-item><paragraph-text type="body">Wavelet transform, discrete wavelet transform [DWT]. </paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media51.png" file-name="cpc-def-G06T-0051.png" type="png" preferred-width="12.69cm" preferred-height="5.56cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Picture signal generating by scanning motion picture films or slide opaques, e.g. for telecine</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N5/253</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Circuitry for compensating brightness variation in the scene in cameras or camera modules comprising electronic image sensors </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/70</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Camera processing pipelines in cameras or camera modules comprising electronic image sensors</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/80</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Noise processing, e.g. detecting, correcting, reducing, or removing noise in circuitry of solid-state image sensors [SSIS]</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N25/60</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/20</classification-symbol><definition-title>using local operators</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Convolution with a mask or kernel in the spatial domain;</paragraph-text></list-item><list-item><paragraph-text type="body">High-pass filter, low-pass filter;</paragraph-text></list-item><list-item><paragraph-text type="body">Gauss filter, Laplace filter;</paragraph-text></list-item><list-item><paragraph-text type="body">Averaging filter, mean filter, blurring filter;</paragraph-text></list-item><list-item><paragraph-text type="body">Differential filters (e.g. Sobel operator);</paragraph-text></list-item><list-item><paragraph-text type="body">Median filter;</paragraph-text></list-item><list-item><paragraph-text type="body">Bilateral filter;</paragraph-text></list-item><list-item><paragraph-text type="body">Minimum, maximum or and rank filtering;</paragraph-text></list-item><list-item><paragraph-text type="body">Wiener filter;</paragraph-text></list-item><list-item><paragraph-text type="body">Phase-locked loops, detectors, mixers;</paragraph-text></list-item><list-item><paragraph-text type="body">Recursive filter;</paragraph-text></list-item><list-item><paragraph-text type="body">Distance transforms;</paragraph-text></list-item><list-item><paragraph-text type="body">Local image processing architectures.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:&#160;</paragraph-text><paragraph-text type="body"><media id="media223.jpeg" file-name="cpc-def-G06T-0223.jpeg" type="jpeg" preferred-width="9.25cm" preferred-height="11.47cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Picture signal generating by scanning motion picture films or slide opaques, e.g. for telecine</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N5/253</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Circuitry for compensating brightness variation in the scene in cameras or camera modules comprising electronic image sensors</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/70</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Camera processing pipelines in cameras or camera modules comprising electronic image sensors</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/80</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Noise processing, e.g. detecting, correcting, reducing, or removing noise in circuitry of solid-state image sensors [SSIS]</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N25/60</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Applying local operators for during image preprocessing for image or video recognition or understanding</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06V10/36</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/30</classification-symbol><definition-title>Erosion or dilatation, e.g. thinning</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">All morphology-based operations for image enhancement, e.g. using:</paragraph-text><list><list-item><paragraph-text type="body">Thickening, thinning;</paragraph-text></list-item><list-item><paragraph-text type="body">Opening, closing;</paragraph-text></list-item><list-item><paragraph-text type="body">Erosion, dilation;</paragraph-text></list-item><list-item><paragraph-text type="body">Structuring elements;</paragraph-text></list-item><list-item><paragraph-text type="body">Skeletons;</paragraph-text></list-item><list-item><paragraph-text type="body">Geodesic transforms.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples of subject matter classified in this place:&#160;</paragraph-text><paragraph-text type="body">1.</paragraph-text><paragraph-text type="body"><media id="media53.png" file-name="cpc-def-G06T-0053.png" type="png" preferred-width="8.67cm" preferred-height="7.35cm"/></paragraph-text><paragraph-text type="body">2.</paragraph-text><paragraph-text type="body"><media id="media54.png" file-name="cpc-def-G06T-0054.png" type="png" preferred-width="8.81cm" preferred-height="7.74cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Segmentation or edge detection involving morphological operators</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/155</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Smoothing or thinning of patterns during image preprocessing for image or video recognition or understanding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/34</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/40</classification-symbol><definition-title>using histogram techniques</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">All histogram-based image enhancement methods.</paragraph-text><paragraph-text type="body">Illustrative example of subject matter classified in this place:&#160;</paragraph-text><paragraph-text type="body"><media id="media224.jpeg" file-name="cpc-def-G06T-0224.jpeg" type="jpeg" preferred-width="16cm" preferred-height="7.52cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Circuitry for compensating brightness variation in the scene in cameras or camera modules comprising electronic image sensors</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N23/70</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Camera processing pipelines in cameras or camera modules comprising electronic image sensors</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/80</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Dynamic range modification of images or parts thereof </paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T5/90</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Histogram techniques adapted to be used in scanners, printers, photocopying machines, displays or similar devices</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N1/4074</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Equalising the characteristics of different image components, e.g. their average brightness or colour balance, in stereoscopic or multi-view video systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/133</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/50</classification-symbol><definition-title>using two or more images, e.g. averaging or subtraction</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Image averaging;</paragraph-text></list-item><list-item><paragraph-text type="body">Image fusion, image merging; </paragraph-text></list-item><list-item><paragraph-text type="body">Image subtraction;</paragraph-text></list-item><list-item><paragraph-text type="body">Enhanced final image by combining multiple, e.g. degraded, images, while maintaining the same number of pixels (for increased number of pixels: see&#160;<class-ref scheme="cpc">G06T3/40</class-ref>);</paragraph-text></list-item><list-item><paragraph-text type="body">Full-field focus from multiple of depth-of-field images, e.g. from confocal microscopy;</paragraph-text></list-item><list-item><paragraph-text type="body">Processing of synthetic aperture radar [SAR] images;</paragraph-text></list-item><list-item><paragraph-text type="body">Energy subtraction;</paragraph-text></list-item><list-item><paragraph-text type="body">Bright field, dark field processing;</paragraph-text></list-item><list-item><paragraph-text type="body">Angiography image processing;</paragraph-text></list-item><list-item><paragraph-text type="body">High dynamic range [HDR] image processing;</paragraph-text></list-item><list-item><paragraph-text type="body">Multispectral image processing;</paragraph-text></list-item><list-item><paragraph-text type="body">Computational photography, e.g. coded aperture imaging.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:&#160;</paragraph-text><paragraph-text type="body"><media id="media56.png" file-name="cpc-def-G06T-0056.png" type="png" preferred-width="10.6cm" preferred-height="8.81cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Circuitry for compensating brightness variation in the scene in cameras or camera modules comprising electronic image sensors</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N23/70</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Camera processing pipelines in cameras or camera modules comprising electronic image sensors</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N23/80</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Scaling of whole images or parts thereof based on super-resolution</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T3/4053</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Unsharp masking</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T5/75</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Radar or analogous systems, specially adapted for mapping or imaging using synthetic aperture techniques</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01S13/90</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Spatial compounding in short-range sonar imaging systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01S15/8995</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Confocal scanning microscopes</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G02B21/0024</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Computational photography systems, e.g. light-field imaging systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/95</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/60</classification-symbol><definition-title>using machine learning, e.g. neural networks</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">All machine learning-based image enhancement methods, e.g. using:</paragraph-text><list><list-item><paragraph-text type="body">artificial neural networks [ANN], convolutional neural networks [CNN], generative adversarial networks [GAN] or deep learning;</paragraph-text></list-item><list-item><paragraph-text type="body">decision trees;</paragraph-text></list-item><list-item><paragraph-text type="body">support-vector machines;</paragraph-text></list-item><list-item><paragraph-text type="body">regression analysis;</paragraph-text></list-item><list-item><paragraph-text type="body">Bayesian networks;</paragraph-text></list-item><list-item><paragraph-text type="body">Gaussian processes;</paragraph-text></list-item><list-item><paragraph-text type="body">genetic algorithms.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media209.png" file-name="cpc-def-G06T-0209.png" type="png" preferred-width="16cm" preferred-height="10.82cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Neural networks</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06N3/02</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Learning methods</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06N3/08</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Machine learning</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06N20/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Arrangements for image or video recognition or understanding using pattern recognition or machine learning using neural networks</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/82</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Arrangements for image or video recognition or understanding using pattern recognition or machine learning using probabilistic graphical models from image or video features, e.g. Markov models or Bayesian networks</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/84</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/70</classification-symbol><definition-title>Denoising; Smoothing</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Removing noise from images;</paragraph-text></list-item><list-item><paragraph-text type="body">Temporal denoising, spatio-temporal noise filtering;</paragraph-text></list-item><list-item><paragraph-text type="body">Removing pattern noise from images;</paragraph-text></list-item><list-item><paragraph-text type="body">Image smoothing;</paragraph-text></list-item><list-item><paragraph-text type="body">Image blurring, adding motion blur to images, adding blur to images;</paragraph-text></list-item><list-item><paragraph-text type="body">Edge-adaptive smoothing;</paragraph-text></list-item><list-item><paragraph-text type="body">Smoothing of depth map in stereo or range images;</paragraph-text></list-item><list-item><paragraph-text type="body">Antialiasing by image filtering;</paragraph-text></list-item><list-item><paragraph-text type="body">Denoising or smoothing using singular value decomposition [SVD].</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Camera processing pipelines for suppressing or minimising disturbance in the image signal generation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/81</class-ref> </paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Noise processing in circuitry of solid-state image sensors [SSIS], e.g. detecting, correcting, reducing or removing noise</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N25/60</class-ref> </paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Antialiasing during drawing of lines</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T11/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Antialiasing during filling a planar surface by adding surface attributes, e.g. colour or texture</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T11/40</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Noise filtering in image pre-processing for image or video recognition or understanding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/30</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Noise or error suppression in colour picture communication systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/58</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Processing image signals for flicker reduction in stereoscopic or multi-view video systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/144</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever possible or appropriate, documents classified in group <class-ref scheme="cpc">G06T5/70</class-ref> should additionally be classified in groups <class-ref scheme="cpc">G06T5/10</class-ref> - <class-ref scheme="cpc">G06T5/60</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/73</classification-symbol><definition-title>Deblurring; Sharpening</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Deblurring;</paragraph-text></list-item><list-item><paragraph-text type="body">Removing motion blur from images;</paragraph-text></list-item><list-item><paragraph-text type="body">Point-spread function [PSF] model of blurring;</paragraph-text></list-item><list-item><paragraph-text type="body">Deconvolution;</paragraph-text></list-item><list-item><paragraph-text type="body">Modulation transfer function [MTF];</paragraph-text></list-item><list-item><paragraph-text type="body">Sharpening, crispening;</paragraph-text></list-item><list-item><paragraph-text type="body">Edge enhancement, edge boosting.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples of subject matter classified in this place:</paragraph-text><paragraph-text type="body">1.</paragraph-text><paragraph-text type="body"><media id="media211.png" file-name="cpc-def-G06T-0211.png" type="png" preferred-width="5.74cm" preferred-height="5.27cm"/></paragraph-text><paragraph-text type="body">2.</paragraph-text><paragraph-text type="body"><media id="media225.jpeg" file-name="cpc-def-G06T-0225.jpeg" type="jpeg" preferred-width="13.91cm" preferred-height="9.95cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Vibration or motion blur correction for stable pick-up of the scene in cameras or camera modules comprising electronic image sensors</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/682</class-ref> </paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Edge-driven scaling</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T3/403</class-ref> </paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Edge or detail enhancement for scanning, transmission or reproduction of documents or the like, e.g. facsimile transmission</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/4092</class-ref> </paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Edge or detail enhancement in colour picture communication systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/58</class-ref> </paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever possible or appropriate, documents classified in group <class-ref scheme="cpc">G06T5/73</class-ref> should additionally be classified in groups <class-ref scheme="cpc">G06T5/10</class-ref> - <class-ref scheme="cpc">G06T5/60</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/75</classification-symbol><definition-title>Unsharp masking</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Unsharp masking;</paragraph-text></list-item><list-item><paragraph-text type="body">Adding or subtracting a processed version of an image to or from the image.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media226.jpeg" file-name="cpc-def-G06T-0226.jpeg" type="jpeg" preferred-width="14.48cm" preferred-height="11.28cm"/></paragraph-text></section-body></definition-statement><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever possible or appropriate, documents classified in group <class-ref scheme="cpc">G06T5/75</class-ref> should additionally be classified in groups <class-ref scheme="cpc">G06T5/10</class-ref> - <class-ref scheme="cpc">G06T5/60</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/77</classification-symbol><definition-title>Retouching; Inpainting; Scratch removal</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Concealing defective pixels in images;</paragraph-text></list-item><list-item><paragraph-text type="body">Scratch removal;</paragraph-text></list-item><list-item><paragraph-text type="body">Inpainting by image filtering or by replacing patches within an image using a generated image or texture patch, or a patch retrieved from another source, e.g. image databases or the internet;</paragraph-text></list-item><list-item><paragraph-text type="body">Correcting red-eye defects.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media227.jpeg" file-name="cpc-def-G06T-0227.jpeg" type="jpeg" preferred-width="15.18cm" preferred-height="10.37cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Scratch removal adapted to be used in scanners, printers, photocopying machines, displays or similar devices</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/4097</class-ref> </paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Picture signal generating by scanning motion picture films or slide opaques, e.g. for telecine</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N5/253</class-ref> </paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Noise processing, e.g. detecting, correcting, reducing or removing noise in circuitry of solid-state image sensors [SSIS]</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N25/60</class-ref> </paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Segmentation or edge detection in image analysis</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/10</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Analysis of geometric attributes in image analysis</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/60</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Determining position or orientation of objects or cameras in image analysis</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/70</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Determination of colour characteristics in image analysis</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/90</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Texture generation as such</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T11/001</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Recognition of eye characteristics</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V40/18</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Modification of content of picture, e.g. retouching</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/40093</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Retouching colour images adapted to be used in scanners, printers, photocopying machines, displays or similar devices</paragraph-text></table-column><table-column><paragraph-text type="body"> <class-ref scheme="cpc">H04N1/62</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Red-eye correction adapted to be used in scanners, printers, photocopying machines, displays or similar devices</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/624</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever possible or appropriate, documents classified in group <class-ref scheme="cpc">G06T5/77</class-ref> should additionally be classified in groups <class-ref scheme="cpc">G06T5/10</class-ref> - <class-ref scheme="cpc">G06T5/60</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/80</classification-symbol><definition-title>Geometric correction</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Correcting lens distortions or aberrations;</paragraph-text></list-item><list-item><paragraph-text type="body">Correcting pincushion, barrel, trapezoidal or fish-eye distortions;</paragraph-text></list-item><list-item><paragraph-text type="body">Calibrating parameters of lens distortion;</paragraph-text></list-item><list-item><paragraph-text type="body">Reference grids, coordinate mapping.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media228.png" file-name="cpc-def-G06T-0228.png" type="png" preferred-width="11.54cm" preferred-height="7.43cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Geometric image transformations in the plane of the image</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T3/00</class-ref> </paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Analysis of captured images to determine intrinsic or extrinsic camera parameters, i.e. camera calibration</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/80</class-ref> </paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Normalisation of the pattern dimension during image preprocessing for image or video recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/32</class-ref> </paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever possible or appropriate, documents classified in group <class-ref scheme="cpc">G06T5/80</class-ref> should additionally be classified in groups&#160;<class-ref scheme="cpc">G06T5/10</class-ref> - <class-ref scheme="cpc">G06T5/60</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/90</classification-symbol><definition-title>Dynamic range modification of images or parts thereof</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Contrast enhancement based on a combination of local and global properties.</paragraph-text><paragraph-text type="body">Illustrative examples of subject matter classified in this place:</paragraph-text><paragraph-text type="body">1.</paragraph-text><paragraph-text type="body"><media id="media216.png" file-name="cpc-def-G06T-0216.png" type="png" preferred-width="7.13cm" preferred-height="4.06cm"/></paragraph-text><paragraph-text type="body">2.</paragraph-text><paragraph-text type="body"><media id="media229.jpeg" file-name="cpc-def-G06T-0229.jpeg" type="jpeg" preferred-width="12.13cm" preferred-height="7.01cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Circuitry for compensating brightness variation in the scene by increasing the dynamic range of the image compared to the dynamic range of the electronic image sensors</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/741</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Bracketing, i.e. taking a series of images with varying exposure conditions </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/743</class-ref> </paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Control of the dynamic range in Circuitry of solid-state image sensors [SSIS]</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N25/57</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Equalising the characteristics of different image components of stereoscopic or multi-view image signals, e.g. their average brightness or colour balance</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/133</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever possible or appropriate, documents classified in group <class-ref scheme="cpc">G06T5/90</class-ref> should additionally be classified in groups <class-ref scheme="cpc">G06T5/10</class-ref> - <class-ref scheme="cpc">G06T5/60</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/92</classification-symbol><definition-title>based on global image properties</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Global contrast enhancement or tone mapping to increase the dynamic range of an image, based on properties of the whole image, e.g. global statistics or histograms;</paragraph-text></list-item><list-item><paragraph-text type="body">Contrast stretching, brightness equalisation;</paragraph-text></list-item><list-item><paragraph-text type="body">Gamma and gradation correction in general;</paragraph-text></list-item><list-item><paragraph-text type="body">Tone mapping for high dynamic range [HDR] imaging;</paragraph-text></list-item><list-item><paragraph-text type="body">Intensity mapping, e.g. using lookup tables [LUT].</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of subject matter classified in this place:</paragraph-text><paragraph-text type="body"><media id="media218.png" file-name="cpc-def-G06T-0218.png" type="png" preferred-width="9.76cm" preferred-height="5.69cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Picture signal circuitry for controlling amplitude response in television systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N5/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Gamma control in television systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N5/202</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Circuitry for compensating brightness variation in the scene</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/70</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Camera processing pipelines comprising electronic image sensors</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/80</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever possible or appropriate, documents classified in group <class-ref scheme="cpc">G06T5/92</class-ref> should additionally be classified in groups <class-ref scheme="cpc">G06T5/10</class-ref> - <class-ref scheme="cpc">G06T5/60</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T5/94</classification-symbol><definition-title>based on local image properties, e.g. for local contrast enhancement</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Local contrast enhancement, e.g. locally adaptive filtering;</paragraph-text></list-item><list-item><paragraph-text type="body">Retinex processing.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples of subject matter classified in this place:</paragraph-text><paragraph-text type="body">1.</paragraph-text><paragraph-text type="body"><media id="media219.png" file-name="cpc-def-G06T-0219.png" type="png" preferred-width="11.9cm" preferred-height="4.34cm"/></paragraph-text><paragraph-text type="body">2.</paragraph-text><paragraph-text type="body"><media id="media220.png" file-name="cpc-def-G06T-0220.png" type="png" preferred-width="8.87cm" preferred-height="5.8cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Unsharp masking</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T5/75</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever possible or appropriate, documents classified in group <class-ref scheme="cpc">G06T5/94</class-ref> should additionally be classified in groups <class-ref scheme="cpc">G06T5/10</class-ref> - <class-ref scheme="cpc">G06T5/60</class-ref>. </paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T7/00</classification-symbol><definition-title>Image analysis</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Analysis of motion, i.e. determining motion of an image subject, or of the camera having acquired the images; Tracking; Change detection; e.g. by block matching, feature-based methods, gradient-based methods, hierarchical or stochastic approaches, motion estimation from a sequence of stereo images.</paragraph-text></list-item><list-item><paragraph-text type="body">Analysis of texture, i.e. analysis of colour or intensity features which represent a perceived image texture, e.g. based on statistical or structural descriptions.</paragraph-text></list-item><list-item><paragraph-text type="body">Analysis of geometric attributes, e.g. area, perimeter, diameter, volume, convexity, concavity, centre of gravity, moments or symmetry.</paragraph-text></list-item><list-item><paragraph-text type="body">Analysis of captured images to determine intrinsic or extrinsic camera parameters, i.e. camera calibration; Calibration of stereo cameras, e.g. determining the transformation between left and right camera coordinate systems</paragraph-text></list-item><list-item><paragraph-text type="body">Computational analysis of images to determine information, e.g. parameters or characteristics, therefrom</paragraph-text></list-item><list-item><paragraph-text type="body">Inspection-detection on images, e.g. flaw detection; Industrial image inspection using e.g. a design-rule based approach or an image reference. Industrial image inspection checking presence / absence; Biomedical image inspection.</paragraph-text></list-item><list-item><paragraph-text type="body">Segmentation, i.e. partitioning an image into regions, or edge detection, i.e. detection of edge features in an image, e.g. involving probabilistic or graph-based approaches, deformable models, morphological operators, transform domain-based approaches or the use of more than two images.</paragraph-text></list-item><list-item><paragraph-text type="body">Motion-based segmentation.</paragraph-text></list-item><list-item><paragraph-text type="body">Determination of transform parameters for the alignment of images, i.e. image registration, e.g. by correlation-, feature- or transform domain-based or statistical approaches.</paragraph-text></list-item><list-item><paragraph-text type="body">Depth or shape recovery, i.e. determination of scene depth parameters by consideration of image characteristics; Depth or shape recovery from shading, specularities, texture, perspective effects, e.g. vanishing points, or line drawings; Depth or shape recovery from multiple images involving amongst others contours, focus, motion, multiple light sources, photometric stereo or stereo images.</paragraph-text></list-item><list-item><paragraph-text type="body">Determining the position or orientation of objects, e.g. by feature- or transform domain-based or statistical approaches.</paragraph-text></list-item><list-item><paragraph-text type="body">Determination of image colour characteristics.</paragraph-text></list-item></list></section-body></definition-statement><relationship><section-title>Relationships with other classification places</section-title><section-body><paragraph-text type="body"><class-ref scheme="cpc">G06T7/00</class-ref> covers the details of image analysis algorithms, insofar as it deals with the related image processing algorithms per se. Documents which merely mention the general use of image analysis, without details of the underlying image analysis algorithms, are classified in the application place. Where the image analysis is functionally linked and restricted to specific image acquisition or display hardware or processes, it is classified in the application place; otherwise, it is classified in <class-ref scheme="cpc">G06T7/00</class-ref>. Where the essential technical characteristics relate both to the image analysis detail and to its particular use or special adaptation, classification is made in both <class-ref scheme="cpc">G06T7/00</class-ref> and the application place.</paragraph-text></section-body></relationship><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Computed tomography</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">A61B6/03</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Signal processing for Nuclear Magnetic Resonance (NMR) imaging systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01R33/54</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">ICT specially adapted for processing medical images, e.g. editing 30/40</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G16H30/40</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Scanning, transmission or reproduction of documents or the like</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Stereoscopic television systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Methods of arrangements for coding, decoding, compressing or decompressing digital video signals</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N19/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Transforming light or analogous information into electric information using solid-state image sensors</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N25/00</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Image Acquisition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T1/0007</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Processor architectures; Processor configuration, e.g. pipelining</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T1/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Processing seismic data</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01V1/28</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Methods or arrangements for reading or recognising printed or written characters or for recognising patterns</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/00</class-ref>, <class-ref scheme="cpc">G06V10/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Bioinformatics</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G16B</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Medical informatics</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G16H</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Where the essential technical characteristics of the invention relate both to the image analysis detail and to its particular use or special adaptation, classification is made in both <class-ref scheme="cpc">G06T7/00</class-ref> and the relevant application place in other subclasses.</paragraph-text><paragraph-text type="body"><class-ref scheme="cpc">G06T7/00</class-ref> focuses on image processing algorithms. Although such algorithms sometimes need to take into account characteristics of the underlying image acquisition apparatus, inventions to the image acquisition apparatus per se are outside the scope of this group.</paragraph-text><paragraph-text type="body">Additional information should be classified using one or more of the Indexing Codes from the ranges of <class-ref scheme="cpc">G06T2200/00</class-ref> or <class-ref scheme="cpc">G06T2207/00</class-ref>. Their use is obligatory.</paragraph-text><paragraph-text type="body">The classification symbol <class-ref scheme="cpc">G06T7/00</class-ref> is allocated to documents concerning:</paragraph-text><list><list-item><paragraph-text type="body">Architectures of image analysis systems, fif not provided for elsewhere</paragraph-text></list-item><list-item><paragraph-text type="body">Extraction of MPEG7 descriptors, if not provided for elsewhere</paragraph-text></list-item></list></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Stereo</paragraph-text></table-column><table-column><paragraph-text type="body">Treatment of two images, e.g. from two cameras or a single camera that is displaced, in a pairwise manner</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Feature</paragraph-text></table-column><table-column><paragraph-text type="body">a significant image region or pixel with certain characteristics, for example a feature point, landmark, edge, corner or blob, typically determined by image operators.</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image analysis</paragraph-text></table-column><table-column><paragraph-text type="body">the extraction of information from images through the use of image processing techniques acting upon image data, such as intensity, colour, motion and spatial frequency characteristics.</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><abbreviations>
<paragraph-text type="preamble">In patent documents, the following abbreviations are often used:</paragraph-text>
<table>
<table-row><table-column preferred-width="4.0cm"><paragraph-text type="body">AAM</paragraph-text></table-column><table-column preferred-width="11.04cm"><paragraph-text type="body">Active appearance model</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="4.0cm"><paragraph-text type="body">ASM</paragraph-text></table-column><table-column preferred-width="11.04cm"><paragraph-text type="body">Active shape model</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="4.0cm"><paragraph-text type="body">HMM</paragraph-text></table-column><table-column preferred-width="11.04cm"><paragraph-text type="body">Hidden Markov Model</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="4.0cm"><paragraph-text type="body">LBP</paragraph-text></table-column><table-column preferred-width="11.04cm"><paragraph-text type="body">Local Binary Pattern</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="4.0cm"><paragraph-text type="body">LPE</paragraph-text></table-column><table-column preferred-width="11.04cm"><paragraph-text type="body">ligne de partage des eaux (French expression for watershed segmentation)</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="4.0cm"><paragraph-text type="body">RANSAC</paragraph-text></table-column><table-column preferred-width="11.04cm"><paragraph-text type="body">Random Sampling (and) Consensus</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">CAD</paragraph-text></table-column><table-column><paragraph-text type="body">Computer-Aided Detection</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">SLAM</paragraph-text></table-column><table-column><paragraph-text type="body">Simultaneous Localization and Mapping</paragraph-text></table-column></table-row></table>
</abbreviations></synonyms-keywords></definition-item>
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T7/0002</classification-symbol><definition-title>{Inspection of images, e.g. flaw detection}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Quality, conformity control</paragraph-text></list-item><list-item><paragraph-text type="body">Defects, abnormality, incompleteness</paragraph-text></list-item><list-item><paragraph-text type="body">Acceptability determination</paragraph-text></list-item><list-item><paragraph-text type="body">User interface for automated visual inspection</paragraph-text></list-item><list-item><paragraph-text type="body">Database-to-object inspection</paragraph-text></list-item><list-item><paragraph-text type="body">Image quality inspection</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Determining position or orientation of objects</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/70</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Validation, performance evaluation or active pattern learning techniques</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/217</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Pattern matching criteria, e.g. proximity measures</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/22</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Clustering techniques for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/23</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Classification techniques for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/24</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image or video pattern matching</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/74</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Pattern recognition or machine learning using clustering within arrangements for image or video recognition or understanding </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/762</class-ref>, <class-ref scheme="cpc">G06V10/764</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Detection or correction of errors in pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/98</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Evaluation of the quality of the acquired pattern in pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/993</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">In relation to the remaining, function-oriented groups of <class-ref scheme="cpc">G06T7/00</class-ref>, this subgroup is an application-oriented group. Therefore, documents classified herein should also be classified in a function-oriented group under <class-ref scheme="cpc">G06T7/00</class-ref>, if they contain a considerable contribution on the respective function.</paragraph-text><paragraph-text type="body">For image quality inspection <class-ref scheme="cpc">G06T2207/30168</class-ref> (Image quality inspection) should be added.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/0004</classification-symbol><definition-title>{Industrial image inspection}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Quality, conformity control in industrial context </paragraph-text></list-item><list-item><paragraph-text type="body">Defects, abnormality in industrial context</paragraph-text></list-item><list-item><paragraph-text type="body">Acceptability determination in industrial context</paragraph-text></list-item><list-item><paragraph-text type="body">User interfaces for automated visual inspection in industrial context</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Teaching&quot; (macros for inspection algorithms)</paragraph-text></list-item><list-item><paragraph-text type="body">Database-to-object inspection in industrial context</paragraph-text></list-item><list-item><paragraph-text type="body">Printing quality</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Investigating the presence of flaws or contamination on materials</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01N21/88</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Contactless testing using optical radiation for printed circuits</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G01R31/309</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Contactless testing using optical radiation for individual semiconductor devices</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G01R31/311</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Photolithography mask inspection</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G03F7/7065</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Component placement (in PCB manufacturing)</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H05K3/0008</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">When classifying in this group, the use of the indexing scheme <class-ref scheme="cpc">G06T2207/30108</class-ref> - <class-ref scheme="cpc">G06T2207/30164</class-ref> is mandatory for additional information related to industrial image inspection.</paragraph-text><paragraph-text type="body">For user interfaces for automated visual inspection in industrial context, Indexing code <class-ref scheme="cpc">G06T2200/24</class-ref> (involving graphical user interfaces [GUIs]) should be added.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/0006</classification-symbol><definition-title>{using a design-rule based approach}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Verifying geometric design rules or known geometric parameters, e.g. width or spacing of structures, repetitive patterns</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media189.png" file-name="cpc-def-G06T-0189.png" type="png" preferred-width="7.97cm" preferred-height="7.14cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/0008</classification-symbol><definition-title>{checking presence/absence}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Detecting the absence of an item that should be there</paragraph-text></list-item><list-item><paragraph-text type="body">Detecting incompleteness</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples:</paragraph-text><paragraph-text type="body"><media id="media190.png" file-name="cpc-def-G06T-0190.png" type="png" preferred-width="10.61cm" preferred-height="8.57cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T7/001</classification-symbol><definition-title>{using an image reference approach}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Industrial image inspection where an image is compared to a reference image, standard image, ground truth image, gold standard: either by image comparison at image level, e.g. by image correlation, or by comparison of parameters extracted from the images</paragraph-text></list-item><list-item><paragraph-text type="body">Reference images originated from an image acquisition apparatus or derived from computer-aided design data</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples:</paragraph-text><paragraph-text type="body"><media id="media191.png" file-name="cpc-def-G06T-0191.png" type="png" preferred-width="8.99cm" preferred-height="8.16cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Determining representative reference patterns or generating dictionaries </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/28</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Determining representative reference patterns or generating dictionaries for image or video recognition or understanding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/772</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/0012</classification-symbol><definition-title>{Biomedical image inspection}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Defects, abnormality in biomedical context</paragraph-text><paragraph-text type="body">Computer-aided detection [CAD]</paragraph-text><paragraph-text type="body">Detecting, measuring, scoring, grading of</paragraph-text><list><list-item><paragraph-text type="body">Disease, pathology, lesions</paragraph-text></list-item><list-item><paragraph-text type="body">Cancer, tumor, tumour, malignancy, nodule</paragraph-text></list-item><list-item><paragraph-text type="body">Emphysema</paragraph-text></list-item><list-item><paragraph-text type="body">Microcalcifications</paragraph-text></list-item><list-item><paragraph-text type="body">Polyps</paragraph-text></list-item><list-item><paragraph-text type="body">Scar, non-viable tissue</paragraph-text></list-item><list-item><paragraph-text type="body">Osteoporosis, fracture risk prediction, Arthritis</paragraph-text></list-item><list-item><paragraph-text type="body">Alzheimer disease</paragraph-text></list-item><list-item><paragraph-text type="body">Scoring wrinkles, ageing</paragraph-text></list-item><list-item><paragraph-text type="body">Tissue abnormalities in microscopic images, e.g. inflammation, deformations</paragraph-text></list-item><list-item><paragraph-text type="body">Grading of living plants</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples:</paragraph-text><paragraph-text type="body"><media id="media60.png" file-name="cpc-def-G06T-0060.png" type="png" preferred-width="6.49cm" preferred-height="5.71cm"/></paragraph-text><paragraph-text type="body">Characterising skin imperfections</paragraph-text><paragraph-text type="body"><media id="media194.png" file-name="cpc-def-G06T-0194.png" type="png" preferred-width="8.48cm" preferred-height="5.05cm"/></paragraph-text><paragraph-text type="body">Evaluating spine balance</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Apparatus for radiation diagnostics</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">A61B6/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Diagnosis using ultrasound</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">A61B8/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Signal processing for Nuclear Magnetic Resonance (NMR) imaging systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01R33/54</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Ultrasound imaging</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01S7/52017</class-ref>, <class-ref scheme="cpc">G01S15/8906</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">ICT specially adapted for processing medical images, e.g. editing</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G16H30/40</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Recognising microscopic objects</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06V20/69</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Bioinformatics</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G16B</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Medical informatics</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G16H</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">When classifying in this group, the use of the indexing scheme <class-ref scheme="cpc">G06T2207/30004</class-ref> - <class-ref scheme="cpc">G06T2207/30104</class-ref> is mandatory for additional information related to biomedical image processing.</paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Biomedical</paragraph-text></table-column><table-column><paragraph-text type="body">biological or medical</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T7/0014</classification-symbol><definition-title>{using an image reference approach}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Comparison to a reference image, standard image, atlas...</paragraph-text></list-item><list-item><paragraph-text type="body">Reference image taken from different patient or patients, or reference image taken from spatially different anatomical regions of the same patient, e.g. comparison of left and right body parts.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples</paragraph-text><paragraph-text type="body">Superposition of a perfusion image and the brain atlas images in contour representation</paragraph-text><paragraph-text type="body"><media id="media63.png" file-name="cpc-def-G06T-0063.png" type="png" preferred-width="14.63cm" preferred-height="8.52cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Determining representative reference patterns or generating dictionaries </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/28</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Determining representative reference patterns or generating dictionaries for image or video recognition or understanding </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/772</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T7/0016</classification-symbol><definition-title>{involving temporal comparison}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Follow-up studies, comparison of images from different points of time, temporal difference images, temporal subtraction images, biomedical change detection.</paragraph-text></list-item><list-item><paragraph-text type="body">Reference image taken from the same patient and the same anatomical region.</paragraph-text></list-item><list-item><paragraph-text type="body">Subtraction angiography for abnormality detection.</paragraph-text></list-item><list-item><paragraph-text type="body">Assessment of dynamic contrast enhancement, wash-in/wash-out for abnormality detection.</paragraph-text></list-item><list-item><paragraph-text type="body">Plethysmography based on image analysis</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body">Floating image, reference image and temporal subtraction image</paragraph-text><paragraph-text type="body"><media id="media64.png" file-name="cpc-def-G06T-0064.png" type="png" preferred-width="9.4cm" preferred-height="10.0cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Analysis of motion, e.g. change detection in general</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T7/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Pattern matching criteria, e.g. proximity measures</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/22</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Temporal feature extraction for image or video recognition or understanding </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/62</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image or video pattern matching </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/74</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For plethysmography based on image analysis, Indexing Code <class-ref scheme="cpc">G06T2207/30076</class-ref> should be added.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T7/10</classification-symbol><definition-title>Segmentation; Edge detection  (motion-based segmentation <class-ref scheme="cpc">G06T7/215</class-ref>)</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Segmentation, i.e. partitioning an image into regions</paragraph-text></list-item><list-item><paragraph-text type="body"> Edge detection, i.e. detection of edge features in an image</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Motion-based segmentation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/215</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Separation of touching or overlapping patterns for pattern recognition,e.g. character segmentation for optical character recognition (OCR)</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/26</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Extraction of image features/characteristics for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/40</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Detecting partial patterns, e.g. edges or contours, or configurations, e.g. loops, corners, strokes, intersections, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/44</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Analysis of texture</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/40</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Determination of colour characteristics</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/90</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Clustering techniques in pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/23</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Classification techniques in pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/24</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Feature extraction related to colour, for pattern recognition </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/56</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Pattern recognition or machine learning using clustering within arrangements for image or video recognition or understanding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/762</class-ref> , <class-ref scheme="cpc">G06V10/764</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/11</classification-symbol><definition-title>Region-based segmentation</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Methods evaluating properties or features of image regions to determine the segmentation result, e.g.:</paragraph-text><list><list-item><paragraph-text type="body">Thresholding, fixed threshold binarisation, multiple and histogram-derived thresholds</paragraph-text></list-item><list-item><paragraph-text type="body">Region growing, splitting and merging</paragraph-text></list-item><list-item><paragraph-text type="body">Colour-based segmentation</paragraph-text></list-item><list-item><paragraph-text type="body">Texture-based segmentation</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Quantising the analogue image signal, e.g. histogram thresholding for discrimination between background and foreground patterns, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/28</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Extraction of features or characteristics of the image related to colour, for pattern recognition </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/56</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Cutting or merging image elements, e.g. region growing, watershed, clustering-based techniques, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V40/23</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Analysis of texture</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/40</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Determination of colour characteristics</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/90</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/12</classification-symbol><definition-title>Edge-based segmentation</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Methods evaluating (closed) contours, edges or outlines of image portions to determine the segmentation result, e.g.:</paragraph-text><list><list-item><paragraph-text type="body">Contour-based segmentation</paragraph-text></list-item><list-item><paragraph-text type="body">Detection of straight edge-lines (e.g. buildings or roads from aerial images) which partition an image into regions</paragraph-text></list-item><list-item><paragraph-text type="body">Finding and linking edge candidate points or segments (edgels)</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media132.png" file-name="cpc-def-G06T-0132.png" type="png" preferred-width="7.73cm" preferred-height="7.82cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Detecting partial patterns, e.g. edges or contours, or configurations, e.g. loops, corners, strokes, intersections, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/44</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Extraction of features or characteristics of the image by coding the contour of a pattern, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/46</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/13</classification-symbol><definition-title>Edge detection</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">In contrast to <class-ref scheme="cpc">G06T7/12</class-ref>, this group covers documents pertaining purely to edge-detection without partitioning an image into regions, e.g.:</paragraph-text><list><list-item><paragraph-text type="body">Derivative methods (first-order or gradient, second order, e.g. Laplacian)</paragraph-text></list-item><list-item><paragraph-text type="body">Zero crossing</paragraph-text></list-item><list-item><paragraph-text type="body">Corner detection</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media133.png" file-name="cpc-def-G06T-0133.png" type="png" preferred-width="10.71cm" preferred-height="5.97cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Detecting partial patterns, e.g. edges or contours, or configurations, e.g. loops, corners, strokes, intersections, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/44</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Extraction of features or characteristics of the image by coding the contour of a pattern, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/46</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/136</classification-symbol><definition-title>involving thresholding</definition-title><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Quantising the analogue image signal, e.g. histogram thresholding for discrimination between background and foreground patterns, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/28</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references></definition-item>
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T7/143</classification-symbol><definition-title>involving probabilistic approaches, e.g. Markov random field [MRF] modelling</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Statistical/Probabilistic methods for segmentation</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media134.png" file-name="cpc-def-G06T-0134.png" type="png" preferred-width="7.32cm" preferred-height="9.95cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Classification techniques based on a parametric (probabilistic) model, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/2415</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Markov models or related models, Markov random fields or networks embedding Markov models for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/295</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Detecting partial patterns or configurations by analysing connectivity relationship of elements of the pattern, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/457</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Pattern recognition or machine learning using classification within arrangements for image or video recognition or understanding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/764</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T7/149</classification-symbol><definition-title>involving deformable models, e.g. active contour models</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Model-based segmentation (in particular when applied to biomedical images)</paragraph-text></list-item><list-item><paragraph-text type="body">Methods based on active shape models</paragraph-text></list-item><list-item><paragraph-text type="body">Methods based on active appearance models</paragraph-text></list-item><list-item><paragraph-text type="body">Methods based on active contours, active surfaces, snakes or deformable templates</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media99.png" file-name="cpc-def-G06T-0099.png" type="png" preferred-width="10.85cm" preferred-height="4.97cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Pattern recognition techniques involving a deformation of the sample or reference pattern or elastic matching</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/754</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Matching of contours based on a local optimisation criterion, e.g. snakes or active contours, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/755</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Matching based on shape statistics, e.g. active shape models, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/7553</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Matching based on statistics of image patches, e.g. active appearance models, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/7557</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For Active shape model [ASM], Indexing Code <class-ref scheme="cpc">G06T2207/20124</class-ref> should be added.</paragraph-text><paragraph-text type="body">For Active appearance model [AAM], Indexing Code <class-ref scheme="cpc">G06T2207/20121</class-ref> should be added.</paragraph-text><paragraph-text type="body">For Active contour; Active surface; Snakes, Indexing Code <class-ref scheme="cpc">G06T2207/20116</class-ref> should be added.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/155</classification-symbol><definition-title>involving morphological operators</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Morphological methods</paragraph-text></list-item><list-item><paragraph-text type="body">Watersheds</paragraph-text></list-item><list-item><paragraph-text type="body">Toboggan-based methods</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples:</paragraph-text><paragraph-text type="body"><media id="media136.png" file-name="cpc-def-G06T-0136.png" type="png" preferred-width="9.74cm" preferred-height="8.43cm"/></paragraph-text><paragraph-text type="body">Figure 1. The 1D profile I(x) representing the intensity of a dark object of interest on a light background, forms three basins which correspond to local minima Min1, Min2 and Min3 of the intensity of the segmented region. The three basins give rise to two watershed lines LPE1 and LPE2, which divide the segmented region into three sub-regions SR1, SR2 and SR3.</paragraph-text><paragraph-text type="body"><media id="media137.png" file-name="cpc-def-G06T-0137.png" type="png" preferred-width="8.54cm" preferred-height="6.69cm"/></paragraph-text><paragraph-text type="body">Figure 2. Toboggan-based object segmentation</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Smoothing or thinning the pattern, e.g. by morphological operators, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/34</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Combinations of pre-processing functions using a local operator, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/36</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Cutting or merging image elements, e.g. region growing, watershed, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V40/23</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For Morphological image processing, an Indexing Code from the range of <class-ref scheme="cpc">G06T2207/20036</class-ref> - <class-ref scheme="cpc">G06T2207/20044</class-ref> should be added.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T7/162</classification-symbol><definition-title>involving graph-based methods</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Graph-cut methods</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media102.png" file-name="cpc-def-G06T-0102.png" type="png" preferred-width="10.58cm" preferred-height="6.76cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Feature extraction by graphical representation, e.g. directed attributed graphs, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/426</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Hierarchical clustering techniques, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/231</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Non-hierarchical partitioning techniques based on graph theory, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/2323</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Graph matching, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V30/1988</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/168</classification-symbol><definition-title>involving transform domain methods</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Fourier-, FFT-, Wavelet-based methods</paragraph-text></list-item><list-item><paragraph-text type="body">Gabor-, Laplace-transform-based methods</paragraph-text></list-item><list-item><paragraph-text type="body">Discrete cosine transform [DCT]-based methods</paragraph-text></list-item><list-item><paragraph-text type="body">Walsh-Hadamard transform [WHT]-based methods</paragraph-text></list-item><list-item><paragraph-text type="body">Hough transform</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media139.png" file-name="cpc-def-G06T-0139.png" type="png" preferred-width="8.75cm" preferred-height="12.44cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Feature extraction by deriving mathematical or geometrical properties, frequency domain transformations, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/431</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Detecting partial patterns using transforms (e.g. Hough transform), for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/48</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Feature extraction by deriving mathematical or geometrical properties, scale-space transformation, e.g. wavelet transform, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/52</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For Transform domain processing, an Indexing Code from the range of <class-ref scheme="cpc">G06T2207/20052</class-ref> - <class-ref scheme="cpc">G06T2207/20064</class-ref> should be added.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/174</classification-symbol><definition-title>involving the use of two or more images</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Using information from multiple images to determine segmentation result</paragraph-text></list-item><list-item><paragraph-text type="body">Segmentation based on several images taken under varying illumination, focus, exposure, etc.</paragraph-text></list-item><list-item><paragraph-text type="body">Segmentation of a video frame involving several image frames of the video sequence, e.g. neighbouring frames</paragraph-text></list-item><list-item><paragraph-text type="body">Temporal and spatio-temporal segmentation, if not based on motion information</paragraph-text></list-item><list-item><paragraph-text type="body">Segmentation using several (neighbouring) slices of a tomographic data set (CT, MRI, PET, etc.), propagation of segmentation results between neighbouring slices</paragraph-text></list-item><list-item><paragraph-text type="body">Hierarchical segmentation methods (including wavelet-based schemes), if final segmentation result is derived from (partial) results at different resolution levels</paragraph-text></list-item><list-item><paragraph-text type="body">Multispectral image segmentation using information from different spectral bands (beyond the visible spectrum)</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media140.png" file-name="cpc-def-G06T-0140.png" type="png" preferred-width="9.92cm" preferred-height="8.01cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Motion-based segmentation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/215</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/181</classification-symbol><definition-title>involving edge growing; involving edge linking</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Image segmentation or edge detection methods based on</paragraph-text><list><list-item><paragraph-text type="body">edge growing</paragraph-text></list-item><list-item><paragraph-text type="body">edge linking</paragraph-text></list-item><list-item><paragraph-text type="body">edge following</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Detecting partial patterns by analysis of the connectivity relationships of elements of the pattern, e.g. by edge linking, connected component or neighbouring slice analysis, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/457</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/187</classification-symbol><definition-title>involving region growing; involving region merging; involving connected component labelling</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Image segmentation methods based on</paragraph-text><list><list-item><paragraph-text type="body">region growing; region merging</paragraph-text></list-item><list-item><paragraph-text type="body">split-and-merge</paragraph-text></list-item><list-item><paragraph-text type="body">connected component labelling</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media141.png" file-name="cpc-def-G06T-0141.png" type="png" preferred-width="6.75cm" preferred-height="6.75cm"/></paragraph-text><paragraph-text type="body">Figure 1. Region growing method which accumulates costs along a pixel path and as soon as the accumulated costs between neighbouring pixels (91, 92) become higher than a threshold, the growing is stopped.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Detecting partial patterns by analysis of the connectivity relationships of elements of the pattern, e.g. by edge linking, connected component or neighbouring slice analysis, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/457</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Segmentation of touching or overlapping patterns, cutting or merging image elements, e.g. region growing, watersheds, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V40/23</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/194</classification-symbol><definition-title>involving foreground-background segmentation</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Image segmentation or edge detection methods based on a separation of foreground, i.e. relevant parts, and background, i.e. non-relevant parts of an image.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Quantising the analogue image signal, e.g. histogram thresholding for discrimination between background and foreground patterns, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/28</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/20</classification-symbol><definition-title>Analysis of motion  (motion estimation for coding, decoding, compressing or decompressing digital video signals <class-ref scheme="cpc">H04N19/43</class-ref>, <class-ref scheme="cpc">H04N19/51</class-ref>)</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Image analysis algorithms for determining motion of an image subject, or of the camera having acquired the images. Determination of scene movement and between image frames, e.g. Change detection</paragraph-text></list-item><list-item><paragraph-text type="body">Tracking</paragraph-text></list-item><list-item><paragraph-text type="body">Motion capture</paragraph-text></list-item><list-item><paragraph-text type="body">Determining camera ego-motion add the Indexing Code <class-ref scheme="cpc">G06T2207/30244</class-ref>: Camera pose</paragraph-text></list-item><list-item><paragraph-text type="body">Medical motion analysis, e.g. of the left ventricle of the heart add the Indexing Code <class-ref scheme="cpc">G06T2207/30048</class-ref>: Heart; Cardiac</paragraph-text></list-item><list-item><paragraph-text type="body">Trajectory representation add the Indexing Code: <class-ref scheme="cpc">G06T2207/30241</class-ref> Trajectory</paragraph-text></list-item><list-item><paragraph-text type="body">Stabilisation of video sequences (see also <class-ref scheme="cpc">G06T7/30</class-ref>)</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Motion estimation for coding, decoding, compressing or decompressing digital video signals </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N19/43</class-ref>, <class-ref scheme="cpc">H04N19/51</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Scene recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V20/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Recognising video content</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V20/52</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Recognising scenes under surveillance</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V20/52</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Recognising scenes perceived from a vehicle</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V20/56</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Recognising scenes inside a vehicle</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V20/59</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Gesture recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V40/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Burglar, theft or intruder alarms using cameras and image comparison</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G08B13/196</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Determination of transform parameters for the alignment of images, i.e. image registration</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/30</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Depth or shape recovery from motion</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/579</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Determining position or orientation of objects</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/70</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Video games</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">A63F13/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Target following using TV type tracking systems</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G01S3/7864</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Light barriers</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G01V8/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Data indexing of video sequences</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F16/50</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Surveillance systems using closed-circuit television systems (CCTV)</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N7/18</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For camera pose, Indexing Code <class-ref scheme="cpc">G06T2207/30244</class-ref> should be added. For heart, cardiac, Indexing Code <class-ref scheme="cpc">G06T2207/30048</class-ref> should be added. For trajectory details, Indexing Code <class-ref scheme="cpc">G06T2207/30241</class-ref> should be added. For sports video, sports image, Indexing Code <class-ref scheme="cpc">G06T2207/30221</class-ref> should be added</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T7/207</classification-symbol><definition-title>for motion estimation over a hierarchy of resolutions  (multi-resolution motion estimation or hierarchical motion estimation for coding, decoding, compressing or decompressing digital video signals <class-ref scheme="cpc">H04N19/53</class-ref>)</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media116.png" file-name="cpc-def-G06T-0116.png" type="png" preferred-width="10.75cm" preferred-height="8.72cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Multi-resolution motion estimation or hierarchical motion estimation for coding, decoding, compressing or decompressing digital video signals</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N19/53</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/215</classification-symbol><definition-title>Motion-based segmentation</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Figure-ground segmentation by detection of moving object(s) from dense motion representation</paragraph-text></list-item><list-item><paragraph-text type="body">Partitioning an image into regions of homogenous 2D (apparent) motion</paragraph-text></list-item><list-item><paragraph-text type="body">Based on analysis of motion vector field or motion flow</paragraph-text></list-item><list-item><paragraph-text type="body">Grouping from optical flow</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media143.png" file-name="cpc-def-G06T-0143.png" type="png" preferred-width="7.7cm" preferred-height="7.7cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Retrieval of video data using motion, e.g. objection motion</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F16/786</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Segmenting video sequences, e.g. scene change analysis</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V20/49</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Scene change analysis</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N5/147</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Segmentation; Edge detection</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/10</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/223</classification-symbol><definition-title>using block-matching</definition-title><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Movement estimation for television pictures</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N5/144</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Predictive coding in television systems using temporal prediction with motion detection</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N19/503</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Image coding using predictors</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T9/004</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Use of motion vectors for image compression, coding using predictors, video coding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N19/52</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/231</classification-symbol><definition-title>using full search</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Full, exhaustive, brute force search</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media144.png" file-name="cpc-def-G06T-0144.png" type="png" preferred-width="11.73cm" preferred-height="5.73cm"/></paragraph-text><paragraph-text type="body">Figure 1. A motion vector between the m-th frame (1) and the (m+n)-th frame (2) is detected. At first, the image data of the m-th frame 1 is divided into a plurality of first blocks 11, and the first blocks 11 are extracted sequentially .The second block 12 of the same size and shape as the extracted first block 11 is extracted from the image data of the (m+n)-th frame 2. The absolute difference value of the corresponding pixels of the extracted first block 11 and the extracted second block 12 is computed every pixel.</paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/238</classification-symbol><definition-title>using non-full search, e.g. three-step search</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Non-full, layered structure, fast, adaptive, efficient search</paragraph-text></list-item><list-item><paragraph-text type="body">Three-Step, New Three-Step, Four-Step Search</paragraph-text></list-item><list-item><paragraph-text type="body">Simple and Efficient Search</paragraph-text></list-item><list-item><paragraph-text type="body">Binary Search</paragraph-text></list-item><list-item><paragraph-text type="body">Spiral Search</paragraph-text></list-item><list-item><paragraph-text type="body">Two-Dimensional Logarithmic Search</paragraph-text></list-item><list-item><paragraph-text type="body">Cross Search Algorithm</paragraph-text></list-item><list-item><paragraph-text type="body">Adaptive Rood Pattern Search</paragraph-text></list-item><list-item><paragraph-text type="body">Orthogonal Search</paragraph-text></list-item><list-item><paragraph-text type="body">One-at-a-Time Algorithm</paragraph-text></list-item><list-item><paragraph-text type="body">Diamond Search</paragraph-text></list-item><list-item><paragraph-text type="body">Hierarchical search</paragraph-text></list-item><list-item><paragraph-text type="body">Spatial dependency check</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example of an hierarchical search:</paragraph-text><paragraph-text type="body"><media id="media145.png" file-name="cpc-def-G06T-0145.png" type="png" preferred-width="11.71cm" preferred-height="8.73cm"/></paragraph-text></section-body></definition-statement><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For Hierarchical, coarse-to-fine, multiscale or multiresolution image processing; Pyramid transform, Indexing Code <class-ref scheme="cpc">G06T2207/20016</class-ref> should be added.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/246</classification-symbol><definition-title>using feature-based methods, e.g. the tracking of corners or segments</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Feature points, e.g. determined by image operators; also matching of point descriptors, feature vectors; significant segments, blobs</paragraph-text></list-item><list-item><paragraph-text type="body">Feature, landmark, marker, fiducial, edge, corner, etc.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media146.png" file-name="cpc-def-G06T-0146.png" type="png" preferred-width="14.31cm" preferred-height="6.71cm"/></paragraph-text></section-body></definition-statement><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Feature</paragraph-text></table-column><table-column><paragraph-text type="body">a significant image region or pixel with certain characteristics</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/248</classification-symbol><definition-title>{involving reference images or patches}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Involving correlation of &quot;true to reality&quot; image patches, templates, regions of interest</paragraph-text></list-item><list-item><paragraph-text type="body">Correlation used for 1) finding features in each image or for 2) finding regions of interest from one image in the other images</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media147.png" file-name="cpc-def-G06T-0147.png" type="png" preferred-width="10.75cm" preferred-height="4.75cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Face recognition using comparisons between temporally consecutive images</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V40/167</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Analysis of motion using block-matching (where blocks are arbitrarily defined by a grid, not as a significant image region)</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/223</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image matching for pattern recognition or image matching in general</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V40/167</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/251</classification-symbol><definition-title>{involving models}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Involving matching of intermediary 2D or 3D models extracted from each image before motion analysis, e.g. skeletons, stick models, ellipses, geometric models of all kinds, polygon models, active appearance and shape models, as opposed to reference images or patches</paragraph-text></list-item><list-item><paragraph-text type="body">Model matching used for 1) finding features in each image or for 2) finding structure of interest from one image in the other images</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media148.png" file-name="cpc-def-G06T-0148.png" type="png" preferred-width="8.16cm" preferred-height="11.94cm"/></paragraph-text><paragraph-text type="body">For each frame of a captured video sequence, a basic human body model 800 for diving competitions is superimposed on the frame and adjusted to provide an accurate representation of the diver&apos;s positioning in that frame, the sequence of adjusted models describing the entire motion sequence of the diver.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Matching of contours in general or matching of contours for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/752</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Syntactic or structural pattern recognition, e.g. symbolic string recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V30/1983</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/254</classification-symbol><definition-title>involving subtraction of images</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Subtraction of previous image</paragraph-text></list-item><list-item><paragraph-text type="body">Subtraction of background image, background maintenance, background models therefor</paragraph-text></list-item><list-item><paragraph-text type="body">Also involving ratio or more general comparison of corresponding pixels in successive frames</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media149.png" file-name="cpc-def-G06T-0149.png" type="png" preferred-width="13.10cm" preferred-height="9.24cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Burglar, theft or intruder alarms using cameras and image comparison</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G08B13/196</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Change detection in biomedical image inspection</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/0014</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T7/262</classification-symbol><definition-title>using transform domain methods, e.g. Fourier domain methods</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Fourier, DCT, Wavelet, Gabor, etc.</paragraph-text></list-item><list-item><paragraph-text type="body">Using phase correlation</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples:</paragraph-text><paragraph-text type="body"><media id="media150.png" file-name="cpc-def-G06T-0150.png" type="png" preferred-width="9.75cm" preferred-height="10.75cm"/></paragraph-text><paragraph-text type="body">Figure 1.</paragraph-text><paragraph-text type="body"><media id="media113.png" file-name="cpc-def-G06T-0113.png" type="png" preferred-width="10.36cm" preferred-height="9.75cm"/></paragraph-text><paragraph-text type="body">Figure 2.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Feature extraction by deriving mathematical or geometrical properties, frequency domain transformations, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/431</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Detecting partial patterns using Hough transform for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/48</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Feature extraction by deriving mathematical or geometrical properties, scale-space transformation, e.g. wavelet transform, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/52</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For Transform domain processing, an Indexing Code from the range of <class-ref scheme="cpc">G06T2207/20052</class-ref> - <class-ref scheme="cpc">G06T2207/20064</class-ref> should be added.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/269</classification-symbol><definition-title>using gradient-based methods</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Optic (optical) flow involving the calculation of spatial and temporal gradient</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media152.png" file-name="cpc-def-G06T-0152.png" type="png" preferred-width="7.46cm" preferred-height="4.25cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/277</classification-symbol><definition-title>involving stochastic approaches, e.g. using Kalman filters</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Bayesian methods</paragraph-text></list-item><list-item><paragraph-text type="body">HMM</paragraph-text></list-item><list-item><paragraph-text type="body">Particle filtering</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples:</paragraph-text><paragraph-text type="body"><media id="media153.png" file-name="cpc-def-G06T-0153.png" type="png" preferred-width="7.16cm" preferred-height="4.93cm"/></paragraph-text><paragraph-text type="body">Figure 1.</paragraph-text><paragraph-text type="body"><media id="media154.png" file-name="cpc-def-G06T-0154.png" type="png" preferred-width="13.91cm" preferred-height="4.91cm"/></paragraph-text><paragraph-text type="body">Figure 2. Kalman filter-based tracking of 3D heart model</paragraph-text></section-body></definition-statement><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever possible, documents classified herein should also be classified in one of the other subgroups of <class-ref scheme="cpc">G06T7/20</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/285</classification-symbol><definition-title>using a sequence of stereo image pairs</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media155.png" file-name="cpc-def-G06T-0155.png" type="png" preferred-width="12.12cm" preferred-height="4.91cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T7/292</classification-symbol><definition-title>Multi-camera tracking</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Algorithms for camera networks</paragraph-text></list-item><list-item><paragraph-text type="body">Interaction, cooperation between trackers</paragraph-text></list-item><list-item><paragraph-text type="body">Multi-view tracking, multi-camera tracking</paragraph-text></list-item><list-item><paragraph-text type="body">The cameras view the same scene (cooperation, e.g. by voting, fusion)</paragraph-text></list-item><list-item><paragraph-text type="body">The cameras view different scenes (cooperation, e.g. by handover, tracklet joining, trajectory joining)</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media119.png" file-name="cpc-def-G06T-0119.png" type="png" preferred-width="14.18cm" preferred-height="6.10cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Classification of unknown faces, i.e. recognising the same non-enrolled faces, e.g. recognising the unknown faces across different face tracks</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V40/173</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Analysis of motion using a sequence of stereo pairs, e.g. cooperative motion analysis from a single stereo camera pair or motion analysis from at least three views, wherein at least one pair of views is processed as stereo pair</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/285</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever possible, documents classified herein should also be classified in one of the other subgroups of <class-ref scheme="cpc">G06T7/20</class-ref>.</paragraph-text><paragraph-text type="body">In particular, in the case of motion analysis from multiple monocular views with subsequent merging or joining of analysis results, details about the respective analysis algorithm per view should be classified in the subgroups of <class-ref scheme="cpc">G06T7/20</class-ref> as well.</paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Multi-camera</paragraph-text></table-column><table-column><paragraph-text type="body">Treatment of multiple image sequences, not in a pairwise manner</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Stereo</paragraph-text></table-column><table-column><paragraph-text type="body">Treatment of two images, e.g. from two cameras or a single camera that is displaced, in a pairwise manner</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T7/30</classification-symbol><definition-title>Determination of transform parameters for the alignment of images, i.e. image registration</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Image analysis algorithms for determining geometric transformations required to register (i.e. align) separate images. The process involves the estimation of transform parameters. Registration means determining the alignment of images or finding their relative position.</paragraph-text><list><list-item><paragraph-text type="body">Registration of image subparts for the construction of mosaics image</paragraph-text></list-item><list-item><paragraph-text type="body">Multi-modal, cross-modal, across-modal registration of medical image data sets</paragraph-text></list-item><list-item><paragraph-text type="body">Registration with medical atlas Registration of pre-operative and intra-operative medical image data sets</paragraph-text></list-item><list-item><paragraph-text type="body">Registration for change detection in biomedical or remote sensing images (change detection see also <class-ref scheme="cpc">G06T7/20</class-ref></paragraph-text></list-item><list-item><paragraph-text type="body"> Registration of models</paragraph-text></list-item><list-item><paragraph-text type="body">Registration of a model with an image</paragraph-text></list-item><list-item><paragraph-text type="body"> Registration of range data, point clouds (ICP algorithm)</paragraph-text></list-item><list-item><paragraph-text type="body">2D/2D, 2D/3D, 3D/3D registration</paragraph-text></list-item><list-item><paragraph-text type="body">Interactive registration </paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Segmentation involving deformable models</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/149</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Recognising three-dimensional objects, e.g. range data matching for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V20/64</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Geometric image transformation in the plane of the image for image registration</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T3/14</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Analysis of motion</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Combining images from different aspect angles, e.g. spatial compounding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01S15/8995</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Pattern matching criteria, e.g. proximity measures </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/22</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image or video pattern matching</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/74</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Comparing pixel values or logical combinations thereof, e.g. template matching</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/751</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For registration of medical image data, an Indexing Code from the range of <class-ref scheme="cpc">G06T2207/30004</class-ref>-<class-ref scheme="cpc">G06T2207/30104</class-ref>(Biomedical image processing) should be added.</paragraph-text><paragraph-text type="body">For involving image mosaicing, Indexing Code <class-ref scheme="cpc">G06T2200/32</class-ref> should be added.</paragraph-text><paragraph-text type="body">For Interactive image processing based on input by user, an Indexing Code from the range of <class-ref scheme="cpc">G06T2207/20092</class-ref>-<class-ref scheme="cpc">G06T2207/20108</class-ref> should be added.</paragraph-text></section-body></special-rules><synonyms-keywords><section-title>Synonyms and Keywords</section-title><special-meanings>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used with the meaning indicated:</paragraph-text>
<table>
<table-row><table-column><paragraph-text type="body">Recalage (French)</paragraph-text></table-column><table-column><paragraph-text type="body">Registration (English)</paragraph-text></table-column></table-row></table>
</special-meanings></synonyms-keywords></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/32</classification-symbol><definition-title>using correlation-based methods</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Global correlation</paragraph-text></list-item><list-item><paragraph-text type="body">Block-matching like correlation, if not for motion analysis</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media157.png" file-name="cpc-def-G06T-0157.png" type="png" preferred-width="9.81cm" preferred-height="6.74cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Analysis of motion using block-matching</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/223</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/33</classification-symbol><definition-title>using feature-based methods</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Feature points, e.g. determined by image operators; also matching of point descriptors, feature vectors; significant segments, blobs</paragraph-text></list-item><list-item><paragraph-text type="body">Feature, landmark, marker, fiducial, edge, corner, etc.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media158.png" file-name="cpc-def-G06T-0158.png" type="png" preferred-width="9.06cm" preferred-height="6.01cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Extraction of features or characteristics of the image, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/40</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Feature</paragraph-text></table-column><table-column><paragraph-text type="body">significant image region or pixel with certain characteristics</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T7/337</classification-symbol><definition-title>{involving reference images or patches}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Involving correlation with &quot;true to reality&quot; image patches, templates, regions of interest; correlation used for 1) finding features in each image, or for 2) finding regions of interest from one image in the other image.</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media159.png" file-name="cpc-def-G06T-0159.png" type="png" preferred-width="11.28cm" preferred-height="5.56cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Image registration using correlation of complete images or block-matching-like registration (where blocks are arbitrarily defined by a grid, not as a significant image region, region of interest)</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/32</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Pattern matching criteria, e.g. proximity measures</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/22</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image or video pattern matching </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/74</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/344</classification-symbol><definition-title>{involving models}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Involving matching of intermediary 2D or 3D models extracted from each image before registration, e.g. geometric models of all kinds, polygon models, active appearance and shape models, as opposed to reference images or patches</paragraph-text></list-item><list-item><paragraph-text type="body">Corresponding models are adapted to each image to be registered, respectively, transform parameters between the images are determined from a comparison/matching of the adapted models</paragraph-text></list-item><list-item><paragraph-text type="body">Model matching used for 1) finding features in each image, or for 2) finding structure of interest from one image in the other image</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media160.png" file-name="cpc-def-G06T-0160.png" type="png" preferred-width="8.70cm" preferred-height="9.54cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Matching of contours</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/752</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Syntactic or structural pattern recognition, e.g. symbolic string recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V30/1983</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/35</classification-symbol><definition-title>using statistical methods</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Involving probabilistic feature points, statistical features or reference images / patches, statistical models, statistical matching</paragraph-text></list-item><list-item><paragraph-text type="body">Approaches based on mutual information</paragraph-text></list-item><list-item><paragraph-text type="body">RANSAC</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Matching configurations of points or features for pattern recognition, e.g. using RANSAC</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/757</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image matching by comparing statistics of regions for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/758</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever possible, documents classified herein should also be classified in one of the other subgroups of <class-ref scheme="cpc">G06T7/30</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T7/37</classification-symbol><definition-title>using transform domain methods</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Fourier, DCT, Wavelet, Gabor, etc.</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media71.png" file-name="cpc-def-G06T-0071.png" type="png" preferred-width="12.3cm" preferred-height="7.86cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Feature extraction by deriving mathematical or geometrical properties, frequency domain transformations, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/431</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Detecting partial patterns using transforms (e.g. Hough transform) for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/48</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Feature extraction by deriving mathematical or geometrical properties, scale-space transformation, e.g. wavelet transform, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/52</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For Transform domain processing, an Indexing Code from the range of <class-ref scheme="cpc">G06T2207/20052</class-ref> - <class-ref scheme="cpc">G06T2207/20064</class-ref> should be added.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/38</classification-symbol><definition-title>Registration of image sequences</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Aligning one image sequence or image set to the other, i.e. finding spatially or temporally corresponding frames between one image sequence and the other (inter-sequence alignment), as opposed to spatial alignment of image frames within a single image sequence (intra-sequence alignment)</paragraph-text></list-item><list-item><paragraph-text type="body">Temporal alignment = alignment along the t-axis, e.g. alignment of two video sequences</paragraph-text></list-item><list-item><paragraph-text type="body">Spatial alignment = alignment along the z-axis, e.g. alignment of two stacks of CT slices</paragraph-text></list-item><list-item><paragraph-text type="body">Additionally, spatially aligning the temporally or spatially corresponding frames in the x-y-plane (intra-sequence alignment) is possible</paragraph-text></list-item><list-item><paragraph-text type="body">Source sequences can be of any orientation</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples:</paragraph-text><paragraph-text type="body"><media id="media162.png" file-name="cpc-def-G06T-0162.png" type="png" preferred-width="9.3cm" preferred-height="6.31cm"/></paragraph-text><paragraph-text type="body">Figure 1. Spatial alignment</paragraph-text><paragraph-text type="body"><media id="media163.png" file-name="cpc-def-G06T-0163.png" type="png" preferred-width="9.63cm" preferred-height="6.97cm"/></paragraph-text><paragraph-text type="body">Figure 2.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Matching video sequences for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V20/48</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Document matching for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V30/418</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever possible, documents classified herein should also be classified in one of the other subgroups of <class-ref scheme="cpc">G06T7/30</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2018-01-01"><classification-symbol scheme="cpc">G06T7/40</classification-symbol><definition-title>Analysis of texture  (depth or shape recovery from texture <class-ref scheme="cpc">G06T7/529</class-ref>)</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Analysis of the spatial arrangement of image colour or intensity characteristics representative of a perceived image texture.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Depth or shape recovery from texture </paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T7/529</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Segmentation; Edge detection </paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T7/10</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Depth or shape recovery from shading</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/507</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Filling a planar surface by adding texture in 2D image generation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T11/40</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Texture mapping in 3D image rendering</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T15/04</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/41</classification-symbol><definition-title>based on statistical description of texture</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Analysis of texture using:</paragraph-text><list><list-item><paragraph-text type="body">First-order statistics</paragraph-text></list-item><list-item><paragraph-text type="body">Global histogram-based measures: mean, variance, skewness, kurtosis, energy, entropy</paragraph-text></list-item><list-item><paragraph-text type="body">Autocorrelation</paragraph-text></list-item><list-item><paragraph-text type="body">Run-length based algorithms</paragraph-text></list-item></list></section-body></definition-statement></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/42</classification-symbol><definition-title>using transform domain methods</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Fourier, DCT, Wavelet, Gabor, etc.</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media164.png" file-name="cpc-def-G06T-0164.png" type="png" preferred-width="9.50cm" preferred-height="6.22cm"/></paragraph-text><paragraph-text type="body">Texture-based image retrieval method using a Gabor filter in the frequency domain, wherein the frequency domain representation is divided according to a predetermined layout for extracting texture descriptors of respective feature channels.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Feature extraction by deriving mathematical or geometrical properties, frequency domain transformations, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/431</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Detecting partial patterns using transforms (e.g. Hough transform), for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/48</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Feature extraction by deriving mathematical or geometrical properties, scale-space transformation, e.g. wavelet transform, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/52</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For Transform domain processing, an Indexing Code from the range of <class-ref scheme="cpc">G06T2207/20052</class-ref> - <class-ref scheme="cpc">G06T2207/20064</class-ref> should be added.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/44</classification-symbol><definition-title>using image operators, e.g. filters, edge density metrics or local histograms</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Laws texture energy measure</paragraph-text></list-item><list-item><paragraph-text type="body">Texture analysis using edge operators</paragraph-text></list-item><list-item><paragraph-text type="body">Texture analysis using difference of Gaussians</paragraph-text></list-item><list-item><paragraph-text type="body">Texture analysis using local linear transforms</paragraph-text></list-item><list-item><paragraph-text type="body">Local Binary Pattern [LBP]</paragraph-text></list-item><list-item><paragraph-text type="body">Grey level difference method</paragraph-text></list-item><list-item><paragraph-text type="body">Local rank order correlation</paragraph-text></list-item></list></section-body></definition-statement></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/45</classification-symbol><definition-title>using co-occurrence matrix computation</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Second-order statistics</paragraph-text></list-item><list-item><paragraph-text type="body">Generalised co-occurrence matrix</paragraph-text></list-item></list></section-body></definition-statement></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/46</classification-symbol><definition-title>using random fields</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Markov Random Fields, Gaussian Random Fields, Gibbs Random Fields</paragraph-text></list-item><list-item><paragraph-text type="body">Autoregressive Model</paragraph-text></list-item></list></section-body></definition-statement></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/48</classification-symbol><definition-title>using fractals</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">fractal texture analysis methods</paragraph-text></list-item><list-item><paragraph-text type="body">fractal dimension</paragraph-text></list-item><list-item><paragraph-text type="body">box counting methods</paragraph-text></list-item></list></section-body></definition-statement></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/49</classification-symbol><definition-title>based on structural texture description, e.g. using primitives or placement rules</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Shape chain grammars, graph grammars</paragraph-text></list-item><list-item><paragraph-text type="body">Grouping of primitives in hierarchical textures</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media165.png" file-name="cpc-def-G06T-0165.png" type="png" preferred-width="13.75cm" preferred-height="9.88cm"/></paragraph-text><paragraph-text type="body">Figure 1 (top) and 2 (bottom). Method for finding periodic structures in a layer of an integrated circuit that have identical optical properties. Fig. 2 illustrates a geometric hierarchy of the periodic elements in the cell layer of Fig. 1.</paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2018-01-01"><classification-symbol scheme="cpc">G06T7/50</classification-symbol><definition-title>Depth or shape recovery</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Image analysis algorithms for determining scene depth parameters from image characteristics.</paragraph-text></list-item><list-item><paragraph-text type="body">Shape from X</paragraph-text></list-item><list-item><paragraph-text type="body">Depth map determination</paragraph-text></list-item><list-item><paragraph-text type="body">Disparity calculation for shape recovery</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Picture taking arrangements specially adapted for photogrammetry or photographic surveying</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01C11/02</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">LIDAR systems for mapping or imaging</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01S17/89</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/507</classification-symbol><definition-title>from shading  (<class-ref scheme="cpc">G06T7/586</class-ref> takes precedence)</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Shape from shading or shadows</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media166.png" file-name="cpc-def-G06T-0166.png" type="png" preferred-width="9.68cm" preferred-height="6.22cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Depth or shape recovery from multiple light sources, e.g. photometric stereo</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/586</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/514</classification-symbol><definition-title>from specularities</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media167.png" file-name="cpc-def-G06T-0167.png" type="png" preferred-width="8.83cm" preferred-height="10.75cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2018-01-01"><classification-symbol scheme="cpc">G06T7/521</classification-symbol><definition-title>from laser ranging, e.g. using interferometry; from the projection of structured light</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media127.png" file-name="cpc-def-G06T-0127.png" type="png" preferred-width="4.4cm" preferred-height="5.4cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Image acquisition and arrangements for measuring contours or curvatures of an object by projecting a pattern thereupon</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01B11/25</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Structured</paragraph-text></table-column><table-column><paragraph-text type="body">characterises the illumination</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/529</classification-symbol><definition-title>from texture</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">shape from texture</paragraph-text></list-item><list-item><paragraph-text type="body">shape from blur in a single image</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media168.png" file-name="cpc-def-G06T-0168.png" type="png" preferred-width="7.22cm" preferred-height="9.11cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Depth or shape recovery from focus</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/571</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T7/536</classification-symbol><definition-title>from perspective effects, e.g. by using vanishing points</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media83.png" file-name="cpc-def-G06T-0083.png" type="png" preferred-width="12.57cm" preferred-height="5.35cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/543</classification-symbol><definition-title>from line drawings</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">shape from line drawings</paragraph-text></list-item><list-item><paragraph-text type="body">shape from contours in a single image</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media170.png" file-name="cpc-def-G06T-0170.png" type="png" preferred-width="11.41cm" preferred-height="13.41cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2018-05-01"><classification-symbol scheme="cpc">G06T7/55</classification-symbol><definition-title>from multiple images</definition-title><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Volumetric display with depth sampling, i.e. the volume being constructed from a stack or sequence of 2D image planes</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/388</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Determining parameters from multiple pictures, e.g. disparity calculation as such</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/97</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For documents concerning trilinear computations, trifocal tensor: add the Indexing Code <class-ref scheme="cpc">G06T2207/20088</class-ref>: Trinocular vision calculations; trifocal tensor.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/557</classification-symbol><definition-title>from light fields, e.g. from plenoptic cameras</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Depth reconstruction using, or based on, light field representations, i.e. 5D plenoptic function, 4D light field, lumigraph, ray space; such light field representations may originate, e.g. from plenoptic cameras, light field cameras, cameras with a lenslet array or integral imaging.</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media171.png" file-name="cpc-def-G06T-0171.png" type="png" preferred-width="12.75cm" preferred-height="4.05cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Depth using trinocular vision calculations/trifocal tensor</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/55</class-ref>, <class-ref scheme="cpc">G06T2207/20088</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Depth from focus</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/571</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Depth from motion</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/579</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Depth from multiple light sources</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/586</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Depth from stereo images</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/593</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/564</classification-symbol><definition-title>from contours</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Shape from contours</paragraph-text></list-item><list-item><paragraph-text type="body">Shape from silhouettes</paragraph-text></list-item><list-item><paragraph-text type="body">Shape from visual hulls</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media172.png" file-name="cpc-def-G06T-0172.png" type="png" preferred-width="9.84cm" preferred-height="6.64cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Depth or shape recovery from line drawings, e.g. shape from contours involving one image only</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/543</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/571</classification-symbol><definition-title>from focus</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Shape from focus</paragraph-text></list-item><list-item><paragraph-text type="body">Shape from defocus of multiple images</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media173.png" file-name="cpc-def-G06T-0173.png" type="png" preferred-width="11.98cm" preferred-height="3.41cm"/></paragraph-text><paragraph-text type="body">Figure 1</paragraph-text><paragraph-text type="body"><media id="media174.png" file-name="cpc-def-G06T-0174.png" type="png" preferred-width="11.98cm" preferred-height="3.41cm"/></paragraph-text><paragraph-text type="body">Figure 2</paragraph-text><paragraph-text type="body">Figure 1 and 2. Input image sequence and resulting depth map</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Shape from texture, e.g. shape from blur in a single image </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/529</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Systems for automatic generation of focusing signals</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G02B7/28</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Focusing aids for cameras; Autofocus systems for cameras</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G03B13/00</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/579</classification-symbol><definition-title>from motion</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Shape from motion, structure from motion</paragraph-text></list-item><list-item><paragraph-text type="body">Extracting the shape of a scene from the spatial and temporal changes occurring in an image sequence (camera or scene moves)</paragraph-text></list-item><list-item><paragraph-text type="body">Simultaneous Localisation and Mapping [SLAM]</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples:</paragraph-text><paragraph-text type="body">Figure 1</paragraph-text><paragraph-text type="body"><media id="media175.png" file-name="cpc-def-G06T-0175.png" type="png" preferred-width="10.5cm" preferred-height="13.5cm"/></paragraph-text><paragraph-text type="body"><media id="media176.png" file-name="cpc-def-G06T-0176.png" type="png" preferred-width="11.6cm" preferred-height="6.95cm"/></paragraph-text><paragraph-text type="body">Figure 2. Shape from motion reconstruction</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Determining position or orientation of objects or cameras</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/70</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For Camera pose, Indexing Code <class-ref scheme="cpc">G06T2207/30244</class-ref> should be added.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2018-01-01"><classification-symbol scheme="cpc">G06T7/586</classification-symbol><definition-title>from multiple light sources, e.g. photometric stereo</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Algorithms for the determination of scene depth parameters from multiple images for which more than one source of illumination has been used. Typically, different illumination sources are used when capturing each of the multiple images to produce different images of the same scene under the different lighting conditions. The different images are used to determine depth and shape parameters in the scene.</paragraph-text><list><list-item><paragraph-text type="body">Different illumination intensities, e.g. ambient and flash</paragraph-text></list-item><list-item><paragraph-text type="body">Different directions of illumination</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media128.png" file-name="cpc-def-G06T-0128.png" type="png" preferred-width="8.4cm" preferred-height="8.4cm"/></paragraph-text></section-body></definition-statement><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Photometric stereo</paragraph-text></table-column><table-column><paragraph-text type="body">a technique for estimating the normal vectors at different points on an object&apos;s surface by observing the object under different lighting conditions.</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/593</classification-symbol><definition-title>from stereo images</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Shape from stereo images or sequences of stereo images</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media129.png" file-name="cpc-def-G06T-0129.png" type="png" preferred-width="7.5cm" preferred-height="6.5cm"/></paragraph-text><paragraph-text type="body"><media id="media130.png" file-name="cpc-def-G06T-0130.png" type="png" preferred-width="7.5cm" preferred-height="6.5cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Stereoscopic or multiview image generation wherein the generated image signals comprise depth maps or disparity maps</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/271</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Depth or shape recovery from multiple images using trilinear computations / the trifocal tensor</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/55</class-ref> and <class-ref scheme="cpc">G06T2207/20088</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Depth or shape recovery from multiple images using the quadrifocal tensor</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/55</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/596</classification-symbol><definition-title>{from three or more stereo images}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Multi-baseline stereo (special case only where</paragraph-text><list><list-item><paragraph-text type="body">each view is always treated together with the same reference view and</paragraph-text></list-item><list-item><paragraph-text type="body">the lengths of the respective baselines differ from each other)</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media177.png" file-name="cpc-def-G06T-0177.png" type="png" preferred-width="9.58cm" preferred-height="12.24cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/60</classification-symbol><definition-title>Analysis of geometric attributes</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Analysis of image subjects to determine geometric attributes thereof, e.g. area, centre of mass, perimeter, diameter or volume.</paragraph-text></list-item><list-item><paragraph-text type="body">Ellipse detection</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Extraction of image features for pattern recognition by deriving geometrical properties of the whole image</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/42</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Measuring characterised arrangements by the use of optical means</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G01B11/00</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/62</classification-symbol><definition-title>of area, perimeter, diameter or volume</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media178.png" file-name="cpc-def-G06T-0178.png" type="png" preferred-width="6.23cm" preferred-height="6.0cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T7/64</classification-symbol><definition-title>of convexity or concavity</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Convexity, concavity, curvature, circularity, sphericity, roundness</paragraph-text><paragraph-text type="body">Illustrative examples:</paragraph-text><paragraph-text type="body">Figure 1</paragraph-text><paragraph-text type="body"><media id="media123.png" file-name="cpc-def-G06T-0123.png" type="png" preferred-width="12.91cm" preferred-height="5.16cm"/></paragraph-text><paragraph-text type="body">Figure 2</paragraph-text><paragraph-text type="body"><media id="media180.png" file-name="cpc-def-G06T-0180.png" type="png" preferred-width="7.04cm" preferred-height="5.54cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/66</classification-symbol><definition-title>of image moments or centre of gravity</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Following centers of gravity of sections along elongated or tubular structure</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media181.png" file-name="cpc-def-G06T-0181.png" type="png" preferred-width="10.59cm" preferred-height="12.39cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Computation of moments, for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/435</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/68</classification-symbol><definition-title>of symmetry</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Determination of lines of symmetry, midlines</paragraph-text></list-item><list-item><paragraph-text type="body">Measurement of symmetry and asymmetry</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media182.png" file-name="cpc-def-G06T-0182.png" type="png" preferred-width="4.85cm" preferred-height="6.43cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T7/70</classification-symbol><definition-title>Determining position or orientation of objects or cameras  (camera calibration <class-ref scheme="cpc">G06T7/80</class-ref>)</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Image processing algorithms for determining the position or orientation of an image subject, or of the camera having acquired the image</paragraph-text></list-item><list-item><paragraph-text type="body">Position or orientation of the camera</paragraph-text></list-item><list-item><paragraph-text type="body">Estimation of position, pose, posture, attitude in 2D and 3D</paragraph-text></list-item><list-item><paragraph-text type="body">Gaze direction, head pose</paragraph-text></list-item><list-item><paragraph-text type="body">Bin picking </paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Camera calibration</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/80</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Orientation detection before recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/242</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Acquiring or recognising human faces, facial parts, facial sketches, facial expressions, eyes</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V40/16</class-ref>, <class-ref scheme="cpc">G06V40/18</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Image feed-back for automatic industrial control</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T1/0014</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Analysis of motion</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Measuring position in terms of linear or angular dimensions</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01B</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Locating or presence-detecting by the use of the reflection or reradiation of radio or other waves</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01S</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Pattern matching criteria, e.g. proximity measures</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/22</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image or video pattern matching </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/74</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Mask, wafer positioning, alignment</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H01L21/681</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Studio circuitry, e.g. for position determination of a camera in a television studio</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N5/222</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Aligning or positioning of tools relative to the circuit board for manufacturing printed circuits</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H05K3/0008</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For camera pose, Indexing Code <class-ref scheme="cpc">G06T2207/30244</class-ref> should be added. For workpiece; machine component, Indexing Code <class-ref scheme="cpc">G06T2207/30164</class-ref> should be added.</paragraph-text></section-body></special-rules><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;Rep&#233;rage&quot; (in French documents), &quot;location&quot;, and &quot;locating&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/73</classification-symbol><definition-title>using feature-based methods</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Feature points, e.g. determined by image operators; also point descriptors, feature vectors; significant segments, blobs</paragraph-text></list-item><list-item><paragraph-text type="body">Feature, landmark, marker, fiducial, edge, corner, etc.</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media183.png" file-name="cpc-def-G06T-0183.png" type="png" preferred-width="7.95cm" preferred-height="6.62cm"/></paragraph-text></section-body></definition-statement><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Feature</paragraph-text></table-column><table-column><paragraph-text type="body">significant image region or pixel with certain characteristics.</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T7/74</classification-symbol><definition-title>{involving reference images or patches}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Involving correlation with &quot;true to reality&quot; reference images, templates of various poses; for &quot;directly&quot; determining pose; correlation with &quot;true to reality&quot; templates of landmarks, markers, fiducials; for finding features in the image.</paragraph-text><paragraph-text type="body">Illustrative examples:</paragraph-text><paragraph-text type="body">Figure 1</paragraph-text><paragraph-text type="body"><media id="media184.png" file-name="cpc-def-G06T-0184.png" type="png" preferred-width="11.45cm" preferred-height="11.93cm"/></paragraph-text><paragraph-text type="body">Figure 2</paragraph-text><paragraph-text type="body"><media id="media185.png" file-name="cpc-def-G06T-0185.png" type="png" preferred-width="7.93cm" preferred-height="5.45cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Pattern matching criteria, e.g. proximity measures </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/22</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image or video pattern matching</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/74</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/75</classification-symbol><definition-title>{involving models}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Involving matching to a 2D or 3D model, e.g. geometric models of all kinds, polygon models, active appearance and shape models, also abstract models of landmarks, markers, fiducials with spatial extent, as opposed to reference images or patches</paragraph-text></list-item><list-item><paragraph-text type="body">Matching of a graphical, e.g. polygon model, may involve intermediate rendering of the model</paragraph-text></list-item><list-item><paragraph-text type="body">Model matching used for 1) finding features in each image, or for 2) &quot;directly&quot; determining pose of structure of interest</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media186.png" file-name="cpc-def-G06T-0186.png" type="png" preferred-width="9.64cm" preferred-height="4.75cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Segmentation involving deformable models</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/149</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Analysis of motion involving models</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/251</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Matching of contours</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/752</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Syntactic or structural pattern recognition, e.g. symbolic string recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V30/1983</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2022-01-01"><classification-symbol scheme="cpc">G06T7/77</classification-symbol><definition-title>using statistical methods</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Involving probabilistic feature points, statistical models, statistics of positions</paragraph-text></list-item><list-item><paragraph-text type="body">Features, reference images, patches or method itself can be statistical</paragraph-text></list-item><list-item><paragraph-text type="body">RANSAC</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media187.png" file-name="cpc-def-G06T-0187.png" type="png" preferred-width="8.56cm" preferred-height="7.75cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Segmentation or edge detection involving probabilistic approaches</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/143</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Analysis of motion involving a stochastic approach</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/277</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image matching by comparing statistics of regions for pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/758</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever possible, documents classified herein should also be classified in one of the other subgroups of <class-ref scheme="cpc">G06T7/70</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T7/80</classification-symbol><definition-title>Analysis of captured images to determine intrinsic or extrinsic camera parameters, i.e. camera calibration</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">The use of methods/algorithms to analyse camera images for the determination of intrinsic parameters defining the camera&apos;s properties, or for the determination of extrinsic parameters defining the camera&apos;s position and orientation. Camera calibration enables pixel positions in a captured 2D image to be mapped to real-world 3D coordinates of the subject represented in the image.</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media131.png" file-name="cpc-def-G06T-0131.png" type="png" preferred-width="7.4cm" preferred-height="7.4cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Geometric correction, e.g. of lens distortion</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T5/80</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Determining position or orientation of objects, e.g. of the camera, without calibration context</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/70</class-ref>, <class-ref scheme="cpc">G06T2207/30244</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Calibration patterns</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01B21/042</class-ref>, <class-ref scheme="cpc">G01C15/02</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Systems for automatic generation of focusing signals</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G02B7/28</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Focusing aids for cameras; Autofocus systems for cameras</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G03B13/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Colour balance, e.g. colour cast correction</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/6077</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Calibration of stereoscopic cameras</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/246</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Picture signal generators using solid state devices, e.g. correction of chromatic aberrations</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/10</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Suppressing or minimising disturbance in picture signal generation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N23/81</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Intrinsic parameters</paragraph-text></table-column><table-column><paragraph-text type="body">The geometric and optical characteristics of a camera, including effective focal length, a scale factor and the image centre or &quot;principal point&quot;.</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Extrinsic parameters</paragraph-text></table-column><table-column><paragraph-text type="body">The three-dimensional position and orientation of the camera in real-world coordinates.</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;Camera calibration&quot;, &quot;Geometric camera calibration&quot;, and &quot;Camera re-sectioning&quot;.</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/85</classification-symbol><definition-title>{Stereo camera calibration}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Camera calibration for stereoscopic cameras, e.g. for determining the transformation between left camera coordinate system and right camera coordinate system</paragraph-text><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media188.png" file-name="cpc-def-G06T-0188.png" type="png" preferred-width="6.75cm" preferred-height="6.75cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Calibration aspects relating to the control of a stereoscopic camera</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/246</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references></references></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T7/90</classification-symbol><definition-title>Determination of colour characteristics</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Determining colour characteristics by image analysis</paragraph-text></list-item><list-item><paragraph-text type="body">Redeye detection</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Colour image segmentation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/10</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Acquiring or recognising eyes, e.g. iris verification</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V40/18</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Retouching, i.e. modification of isolated colours only or in isolated picture areas only</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/62</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Correcting redeye defects by retouching or inpainting</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T5/77</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For redeye defect, Indexing Code <class-ref scheme="cpc">G06T2207/30216</class-ref> should be added.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T7/97</classification-symbol><definition-title>{Determining parameters from multiple pictures  (depth or shape recovery from multiple images <class-ref scheme="cpc">G06T7/55</class-ref>; stereo camera calibration <class-ref scheme="cpc">G06T7/85</class-ref>)}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Disparity, correspondence, stereopsis, if not provided for elsewhere</paragraph-text></list-item><list-item><paragraph-text type="body">Disparity calculation for the production of 3D images from 2D images without intermediate modelling</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Depth or shape recovery from multiple images</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/55</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Stereo camera calibration</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/85</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Industrial image inspection using an image reference approach</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/001</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Biomedical image inspection using an image reference approach</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/0014</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Segmentation involving the use of two or more images</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/174</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Computing motion using a sequence of stereo image pairs</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/285</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Determination of transform parameters for the alignment of images, i.e. image registration</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/30</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Image-based rendering</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T15/205</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">3D from 2D images with intermediate modelling</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T17/20</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For Disparity calculation for image-based rendering, Indexing Code <class-ref scheme="cpc">G06T2207/20228</class-ref> should be added.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T9/00</classification-symbol><definition-title>Image coding  (bandwidth or redundancy reduction for static pictures <class-ref scheme="cpc">H04N1/41</class-ref>; coding or decoding of static colour picture signals <class-ref scheme="cpc">H04N1/64</class-ref>; methods or arrangements for coding, decoding, compressing or decompressing digital video signals <class-ref scheme="cpc">H04N19/00</class-ref>)</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Coding/compression and decoding/decompression of computer graphics(CG) data and computer graphics compression methods applied on natural image/video.</paragraph-text><paragraph-text type="body">Apparatus/devices of coding/compressing and/or decoding/decompressing of computer graphics data.</paragraph-text><paragraph-text type="body">Computer graphics data mentioned including:</paragraph-text><list><list-item><paragraph-text type="body">object geometry models</paragraph-text></list-item><list-item><paragraph-text type="body">scene models</paragraph-text></list-item><list-item><paragraph-text type="body">2D/3D vector graphics</paragraph-text></list-item><list-item><paragraph-text type="body">3D/4D volumetric models</paragraph-text></list-item><list-item><paragraph-text type="body">CAD models</paragraph-text></list-item><list-item><paragraph-text type="body">contour shape data</paragraph-text></list-item><list-item><paragraph-text type="body">elevation data</paragraph-text></list-item><list-item><paragraph-text type="body">CG related metadata/parameters including depth, colour, texture, motion vectors, scene graph, position, connectivity information and similar.</paragraph-text></list-item></list></section-body></definition-statement><relationship><section-title>Relationships with other classification places</section-title><section-body><paragraph-text type="body">This group covers compression/coding/decompression/decoding of CG related data and CG related methods applied on natural image or video. Other compression techniques specific to the natural image/video without using CG related methods are covered by <class-ref scheme="cpc">H04N19/00</class-ref>.</paragraph-text><paragraph-text type="body">Compression in general is covered by <class-ref scheme="cpc">H03M1/00</class-ref>.</paragraph-text></section-body></relationship><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Bandwidth or redundancy reduction for static pictures</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/41</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Coding or decoding of static colour picture signals</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/64</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Methods or arrangements for coding, decoding, compressing or decompressing digital video signals</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N19/00</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Animation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T13/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Model based coding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T15/00</class-ref>, <class-ref scheme="cpc">G06T17/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Model based coding using a 3D model</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T15/00</class-ref>, <class-ref scheme="cpc">G06T17/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Rendering of computer graphics data</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T15/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Modeling of computer graphics data</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T17/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Re-meshing for manipulation, editing purpose</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T17/205</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Manipulation 3D objects</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Pattern recognition</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F18/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Computer aided design</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F30/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image or video recognition or understanding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Pattern recognition by contour coding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/46</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Coding or decoding, in general</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H03M</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Compression in general</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H03M1/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Transmission of TV signals</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N7/24</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Selective content distribution</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N21/00</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">In general, consult the g&#233;rant before using any sub-groups. This is a provisionary document which will be replaced in January , 2012, after completing reorganization in <class-ref scheme="cpc">G06T9/00</class-ref>.</paragraph-text><list><list-item><paragraph-text type="body">for classification, the main group <class-ref scheme="cpc">G06T9/00</class-ref> is assigned always before completing the reorganization.</paragraph-text></list-item><list-item><paragraph-text type="body">The Indexing Code series of symbols is reserved for the use of documents classified in <class-ref scheme="cpc">G06T9/00</class-ref> and subgroups. They should be allocated to documents in <class-ref scheme="cpc">G06T9/00</class-ref> and subgroups whenever relevant.</paragraph-text></list-item><list-item><paragraph-text type="body">the sub-groups <class-ref scheme="cpc">G06T9/004</class-ref>, <class-ref scheme="cpc">G06T9/005</class-ref>, <class-ref scheme="cpc">G06T9/005</class-ref>, <class-ref scheme="cpc">G06T9/008</class-ref> are not used anymore, the content, which is not related with computer graphics data compression/coding, will be transferred to the corresponding classes defined in the group definition statements below.</paragraph-text></list-item></list></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">4D volumetric models</paragraph-text></table-column><table-column><paragraph-text type="body">Sequences of volumetric images over time</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">MPEG</paragraph-text></table-column><table-column><paragraph-text type="body">Moving Picture Experts Group</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">SNHC</paragraph-text></table-column><table-column><paragraph-text type="body">Synthetic/Natural Hybrid Coding</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">BIFS</paragraph-text></table-column><table-column><paragraph-text type="body">Binary Format for Scene</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">VRML</paragraph-text></table-column><table-column><paragraph-text type="body">Virtual Reality Modeling Language</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">SVG</paragraph-text></table-column><table-column><paragraph-text type="body">Scalable Vector Graphics</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">NN</paragraph-text></table-column><table-column><paragraph-text type="body">Neural Networks</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">TV</paragraph-text></table-column><table-column><paragraph-text type="body">Television</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><abbreviations>
<paragraph-text type="preamble">In patent documents, the following abbreviations are often used:</paragraph-text>
<table>
<table-row><table-column preferred-width="7.33cm"><paragraph-text type="body">CG</paragraph-text></table-column><table-column preferred-width="7.72cm"><paragraph-text type="body">Computer graphics</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.33cm"><paragraph-text type="body">3D</paragraph-text></table-column><table-column preferred-width="7.72cm"><paragraph-text type="body">Three dimensional</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.33cm"><paragraph-text type="body">4D</paragraph-text></table-column><table-column preferred-width="7.72cm"><paragraph-text type="body">Four dimensional</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="7.33cm"><paragraph-text type="body">CAD</paragraph-text></table-column><table-column preferred-width="7.72cm"><paragraph-text type="body">Computer aided design</paragraph-text></table-column></table-row></table>
</abbreviations><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;Compression&quot; and &quot;Coding&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Decompression&quot; and &quot;Decoding&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Scene graph&quot; and &quot;Scene model&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Scene description graph&quot; and &quot;Scene graph&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Metadata&quot; and &quot;Parameter&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Contour coding&quot; and &quot;Shape coding&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Elevation data&quot; and &quot;Height data&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Object geometry models&quot; and &quot;Object models&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Natural image&quot; and &quot;Raster/Bitmap image&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Vector graphics&quot; and &quot;Scalable Vector Graphics&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T9/001</classification-symbol><definition-title>{Model-based coding, e.g. wire frame}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for the compression/coding of wire frame models, e.g. polygon meshes.</paragraph-text><paragraph-text type="body">Documents concerning mesh compression/coding by</paragraph-text><list><list-item><paragraph-text type="body">face merging</paragraph-text></list-item><list-item><paragraph-text type="body">incremental decimation</paragraph-text></list-item><list-item><paragraph-text type="body">simplification by remeshing for data reduction purpose are classified here.</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Animation</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T13/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Rendering of computer graphics data</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T15/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Re-meshing for manipulation, editing </paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T17/205</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Manipulation 3D objects</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Documents classified in <class-ref scheme="cpc">G06T9/001</class-ref>, <class-ref scheme="cpc">H04N19/20</class-ref> and <class-ref scheme="cpc">G06T9/001</class-ref>, <class-ref scheme="cpc">G06T15/00</class-ref>, <class-ref scheme="cpc">G06T17/00</class-ref>, <class-ref scheme="cpc">H04N19/20</class-ref> are transferred to <class-ref scheme="cpc">G06T9/001</class-ref>.</paragraph-text><paragraph-text type="body">Documents concerning re-meshing for manipulation, editing and similar, i.e. all means not having data reduction purpose are classified in <class-ref scheme="cpc">G06T17/205</class-ref>.</paragraph-text></section-body></special-rules><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;wireframe&quot; and &quot;polygon mesh&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T9/002</classification-symbol><definition-title>{using neural networks}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for the compression/coding of computer graphics data and natural image/video data using neural networks (NN).</paragraph-text></section-body></definition-statement><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">The compression/coding data concerning in this group includes:</paragraph-text><list><list-item><paragraph-text type="body">computer graphics data</paragraph-text></list-item><list-item><paragraph-text type="body">natural image/video data.</paragraph-text></list-item></list></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">NN</paragraph-text></table-column><table-column><paragraph-text type="body">Neural Networks</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2019-05-01"><classification-symbol scheme="cpc">G06T9/004</classification-symbol><definition-title>{Predictors, e.g. intraframe, interframe coding}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">This group is not used anymore, its content, which is not related with computer graphics data compression/coding, are transferred to <class-ref scheme="cpc">H04N19/105</class-ref>, <class-ref scheme="cpc">H04N19/103</class-ref> or <class-ref scheme="cpc">H04N19/107</class-ref>.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Coding or prediction mode selection</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N19/103</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Predictor</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N19/105</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Intracode mode selection</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N19/107</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2019-05-01"><classification-symbol scheme="cpc">G06T9/005</classification-symbol><definition-title>{Statistical coding, e.g. Huffman, run length coding}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">This group is not used anymore, its content, which is not related with computer graphics data compression/coding, will be transferred to <class-ref scheme="cpc">H04N19/13</class-ref>, <class-ref scheme="cpc">H04N19/91</class-ref>.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Variable length coding (VLC) or entropy coding</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N19/13</class-ref>, <class-ref scheme="cpc">H04N19/91</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">VLC</paragraph-text></table-column><table-column><paragraph-text type="body">Variable length coding</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2019-05-01"><classification-symbol scheme="cpc">G06T9/007</classification-symbol><definition-title>{Transform coding, e.g. discrete cosine transform}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">This group is not used anymore, its content, which is not related with computer graphics data compression/coding, will be transferred to <class-ref scheme="cpc">H04N19/60</class-ref>.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Transform coding</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N19/60</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">DCT</paragraph-text></table-column><table-column><paragraph-text type="body">Discrete cosine transform</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2019-05-01"><classification-symbol scheme="cpc">G06T9/008</classification-symbol><definition-title>{Vector quantisation}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">This group is not used anymore, its content, which is not related with computer graphics data compression/coding, will be transferred to <class-ref scheme="cpc">H04N19/94</class-ref>.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Vector coding</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N19/94</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;vector coding&quot; and &quot;vector quantization&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2024-08-01"><classification-symbol scheme="cpc">G06T9/20</classification-symbol><definition-title>Contour coding, e.g. using detection of edges</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for the compression/coding of computer graphics data using contour/shape coding method, e.g. by detection of edges.</paragraph-text></section-body></definition-statement><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Documents classified in <class-ref scheme="cpc">G06T9/20</class-ref>, <class-ref scheme="cpc">H04N19/20</class-ref> are transferred to <class-ref scheme="cpc">G06T9/20</class-ref>.</paragraph-text><paragraph-text type="body">The compression/coding data concerning in this sub-group includes:</paragraph-text><list><list-item><paragraph-text type="body">computer graphics data, e.g. vector graphics data</paragraph-text></list-item><list-item><paragraph-text type="body">natural image/video data.</paragraph-text></list-item></list></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">SVG</paragraph-text></table-column><table-column><paragraph-text type="body">Scalable Vector Graphics</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;contour coding&quot; and &quot;shape coding&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;vector graphics&quot; and &quot;scalable vector graphics&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2016-11-01"><classification-symbol scheme="cpc">G06T9/40</classification-symbol><definition-title>Tree coding, e.g. quadtree, octree</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for the compression/coding of computer graphics data by using a tree hierarchy, e.g. quadtree, octree, and similar.</paragraph-text><paragraph-text type="body">The documents concerning compression/coding of:</paragraph-text><list><list-item><paragraph-text type="body">computer graphics object models, scene models and related metadata, e.g. depth data,</paragraph-text></list-item></list><paragraph-text type="body">are classified here.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Modelling by tree structure</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T17/005</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Natural image/video tree coding</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N19/96</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Tree description</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T17/005</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Tree coding</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N19/96</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Bintree or binary tree </paragraph-text></table-column><table-column><paragraph-text type="body">tree structure in which each node has at most two child nodes</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Quadtree or quad tree</paragraph-text></table-column><table-column><paragraph-text type="body">tree structure in which each node has at most four child nodes</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">K-tree</paragraph-text></table-column><table-column><paragraph-text type="body">tree structure in which each node has at most K child nodes</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Hextree</paragraph-text></table-column><table-column><paragraph-text type="body">tree structure in which each node has at most six child nodes</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Volume octree</paragraph-text></table-column><table-column><paragraph-text type="body">tree structure in which each voxel is subdivided into at most 8 subvoxels</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Surface octree</paragraph-text></table-column><table-column><paragraph-text type="body">Volume octree with incorporated surface information </paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Multi tree</paragraph-text></table-column><table-column><paragraph-text type="body">directed acyclic graph in which the set of nodes reachable from any node forms a tree</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;scene graph&quot;, &quot;scene description graph&quot; and &quot;scene model&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T11/00</classification-symbol><definition-title>2D [Two Dimensional] image generation</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Documents dealing with generating a 2D image or texture in general. To a large extend, but not exclusively,&#160;<class-ref scheme="cpc">G06T11/00</class-ref>&#160;covers image generation &quot;from a description to a bit-mapped image&quot; in general.</paragraph-text></list-item><list-item><paragraph-text type="body">Software packages, systems</paragraph-text></list-item><list-item><paragraph-text type="body">Caricaturing, Identikit</paragraph-text></list-item><list-item><paragraph-text type="body">Fusion of images with different objects, e.g. fusion of real and virtual images, labelling of 2D images</paragraph-text></list-item><list-item><paragraph-text type="body">Clipping of 2D images</paragraph-text></list-item><list-item><paragraph-text type="body">2D and 3D reconstruction from projections, e.g. for computed tomography.</paragraph-text></list-item><list-item><paragraph-text type="body">Device independent techniques, i.e. it is not for documents which are specially adapted for I/O devices such as printers, scanners or displays.</paragraph-text></list-item><list-item><paragraph-text type="body">Note:</paragraph-text></list-item></list><paragraph-text type="body">General idea for&#160;<class-ref scheme="cpc">G06T11/00</class-ref>:</paragraph-text><list><list-item><paragraph-text type="body">For generating an image, </paragraph-text></list-item><list-item><paragraph-text type="body">first select a colour (<class-ref scheme="cpc">G06T11/001</class-ref>),</paragraph-text></list-item><list-item><paragraph-text type="body">then draw a line (<class-ref scheme="cpc">G06T11/203</class-ref>),</paragraph-text></list-item><list-item><paragraph-text type="body">fill a rectangle, circle or any other closed shape (<class-ref scheme="cpc">G06T11/40</class-ref>),</paragraph-text></list-item><list-item><paragraph-text type="body">edit your work (<class-ref scheme="cpc">G06T11/60</class-ref>).</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Image processing specially adapted for radiation diagnosis</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">A61B6/52</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Map generation for navigation systems</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01C21/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Producing output data for printers</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06K15/02</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Controller for display circuits, e.g. for LCDs, Plasma, OLEDs</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G09G5/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image generation for scanner, fax-machines, copy machines</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Studio circuits for video generation, mixing, special effects, blue/green screens</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N5/262</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Generating of panoramic or mosaic images</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T3/4038</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Generating high dynamic range images (HDR)</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T5/92</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Non-photorealistic rendering in 3D</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T15/02</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Input arrangements or combined input and output interaction between user and computer (user interfaces)</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F3/01</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Video editing</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G11B27/00</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T11/001</classification-symbol><definition-title>{Texturing; Colouring; Generation of texture or colour  (inpainting <class-ref scheme="cpc">G06T5/77</class-ref>)}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Texture generation</paragraph-text><list><list-item><paragraph-text type="body">Textures; endless, periodic pattern</paragraph-text></list-item><list-item><paragraph-text type="body">Texture synthesis, procedural textures</paragraph-text></list-item><list-item><paragraph-text type="body">Neural style transfers</paragraph-text></list-item><list-item><paragraph-text type="body">Brush strokes</paragraph-text></list-item><list-item><paragraph-text type="body">Fractals; Julia sets; Koch curves</paragraph-text></list-item></list><paragraph-text type="body">Colour generation, changing of selected colours</paragraph-text><list><list-item><paragraph-text type="body">Colour palettes, schemes; colour LUT; CLUT</paragraph-text></list-item><list-item><paragraph-text type="body">False colours</paragraph-text></list-item><list-item><paragraph-text type="body">Simulation of watercolour, oil paint, airbrush</paragraph-text></list-item></list><paragraph-text type="body">Illustrative examples:</paragraph-text><paragraph-text type="body"><media id="media199.png" file-name="cpc-def-G06T-0199.png" type="png" preferred-width="9.44cm" preferred-height="9.91cm"/></paragraph-text><paragraph-text type="body"><media id="media200.png" file-name="cpc-def-G06T-0200.png" type="png" preferred-width="5.84cm" preferred-height="10.71cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Inpainting</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T5/77</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Texture mapping</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T15/04</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Colour palettes, CLUTs for displays</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G09G5/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Colour space manipulation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/60</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><synonyms-keywords><section-title>Synonyms and Keywords</section-title><abbreviations>
<paragraph-text type="preamble">In patent documents, the following abbreviations are often used:</paragraph-text>
<table>
<table-row><table-column><paragraph-text type="body">LUT</paragraph-text></table-column><table-column><paragraph-text type="body">look-up table</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">CLUT</paragraph-text></table-column><table-column><paragraph-text type="body">colour look-up table</paragraph-text></table-column></table-row></table>
</abbreviations></synonyms-keywords></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T11/003</classification-symbol><definition-title>{Reconstruction from projections, e.g. tomography}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Reconstruction from tomographic projections, i.e. measurements of an unknown object function (e.g. density of matter, activity distribution) using penetrating radiation or electromagnetic waves, described by radiation transport equations, e. g. integration along lines (= Radon transform), for e.&#160;g. refraction tomography, CT, SPECT, PET, Tomosynthesis, Optical Tomography.</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Impedance measuring for diagnostic purposes</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">A61B5/053</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Apparatus for radiation diagnosis</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">A61B6/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Radiation diagnosis devices using data or image processing specially adapted for radiation diagnosis</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">A61B6/52</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Diagnostic device using ultrasound</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">A61B8/00</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Image enhancement in general</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T5/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image analysis, incl. biomedical image inspection, image registration, segmentation, analysis of motion, analysis of geometric attributes</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Depth or Shape recovery, from multiple images</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/55</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Analysis of materials using tomography, e.g. CT</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01N23/046</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">NMR</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01R33/4824</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Measuring and detection of X-radiation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01T1/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">ICT specially adapted for processing medical images, e.g. editing</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G16H30/40</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">In this group, it is desirable to add the indexing codes of groups <class-ref scheme="cpc">G06T2211/404</class-ref> - <class-ref scheme="cpc">G06T2211/464</class-ref>.</paragraph-text><paragraph-text type="body">The following list of symbols from the series <class-ref scheme="cpc">G06T2211/404</class-ref> - <class-ref scheme="cpc">G06T2211/464</class-ref> should be allocated to documents in <class-ref scheme="cpc">G06T11/003</class-ref> whenever relevant:</paragraph-text><list><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/404</class-ref> Angiography - Angiographic reconstruction includes all the reconstruction methods concerning vessels, tree structures etc.</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/408</class-ref> Dual energy - Reconstruction from dual or multi energy acquisition, polychromatic X-rays, photon-counting CT</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/412</class-ref> Dynamic - Dynamic reconstruction, i.e. moving objects are involved or motion compensation is required (e. g.: heart, lung movement, etc...)</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/416</class-ref> Exact reconstruction - Exact or quasi-exact reconstruction algorithms (in contrast to approximate algorithms)</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/421</class-ref> Filtered Back Projection based methods (the projection data can be handled sequentially, view-by-view)</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/424</class-ref> Iterative - Iterative methods including all the methods using iterations independent of the reconstruction method per-se (e.g. maximum likelihood (ML) or maximum a posteriori (MAP) estimation, regularisation, compressed sensing)</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/428</class-ref> Real-time - Real time reconstruction, e.g. fluoroscopy, intra-operative CT</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/432</class-ref> Truncation - All or part of the data from the detectors are spatially truncated, or incomplete projection data is used.</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/436</class-ref> Limited angle - limited-angle or few view acquisition, tomosynthesis</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/441</class-ref> AI-based methods, e.g. deep learning or convolutional artificial neural networks</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/444</class-ref> Low dose acquisition, reduction of radiation dose</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/448</class-ref> Involving metal artefacts, streaking artefacts, beam hardening, photon starvation</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/452</class-ref> Involving suppression of scattered radiation or scatter correction</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/456</class-ref> Optical coherence tomography [OCT]</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/461</class-ref> Phase contrast imaging or dark field imaging</paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2211/464</class-ref> Dual or multimodal imaging, i.e. combining two or more imaging modalities, e.g. PET-CT, PET-MRI</paragraph-text></list-item></list></section-body></special-rules><synonyms-keywords><section-title>Synonyms and Keywords</section-title><abbreviations>
<paragraph-text type="preamble">In patent documents, the following abbreviations are often used:</paragraph-text>
<table>
<table-row><table-column><paragraph-text type="body">CT</paragraph-text></table-column><table-column><paragraph-text type="body">Computed Tomography</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">NMR</paragraph-text></table-column><table-column><paragraph-text type="body">Nuclear Magnetic Resonance</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">MRI</paragraph-text></table-column><table-column><paragraph-text type="body">Magnetic Resonance Imaging</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">SPECT</paragraph-text></table-column><table-column><paragraph-text type="body">Single-Photon-Emission Computed Tomography</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">PET</paragraph-text></table-column><table-column><paragraph-text type="body">Positron Emission Tomography</paragraph-text></table-column></table-row></table>
</abbreviations></synonyms-keywords></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T11/005</classification-symbol><definition-title>{Specific pre-processing for tomographic reconstruction, e.g. calibration, source positioning, rebinning, scatter correction, retrospective gating}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Specific pre-processing for tomographic reconstruction</paragraph-text><list><list-item><paragraph-text type="body">Calibration</paragraph-text></list-item><list-item><paragraph-text type="body">Source positioning</paragraph-text></list-item><list-item><paragraph-text type="body">Synchronisation</paragraph-text></list-item><list-item><paragraph-text type="body">Scouts</paragraph-text></list-item><list-item><paragraph-text type="body">Rebinning</paragraph-text></list-item><list-item><paragraph-text type="body">Scatter correction</paragraph-text></list-item><list-item><paragraph-text type="body">Attenuation correction</paragraph-text></list-item><list-item><paragraph-text type="body">Metal artefact reduction (MAR)</paragraph-text></list-item></list><paragraph-text type="body">Example: Scatter and beam hardening correction in CT applications</paragraph-text><paragraph-text type="body"><media id="media195.png" file-name="cpc-def-G06T-0195.png" type="png" preferred-width="11.2cm" preferred-height="15.51cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T11/006</classification-symbol><definition-title>{Inverse problem, transformation from projection-space into object-space, e.g. transform methods, back-projection, algebraic methods}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Inverse problem, transformation from projection-space into object-space</paragraph-text></list-item><list-item><paragraph-text type="body">Fourier methods</paragraph-text></list-item><list-item><paragraph-text type="body">Algebraic methods</paragraph-text></list-item><list-item><paragraph-text type="body">Back-projection</paragraph-text></list-item><list-item><paragraph-text type="body">Statistical Methods, e.g. maximum likelihood</paragraph-text></list-item><list-item><paragraph-text type="body">Compressed sensing, sparsity </paragraph-text></list-item><list-item><paragraph-text type="body">AI-based methods, e. g. neural networks</paragraph-text></list-item></list><paragraph-text type="body">Example: Reconstruction method for cone-beam CT </paragraph-text><paragraph-text type="body"><media id="media196.png" file-name="cpc-def-G06T-0196.png" type="png" preferred-width="10.69cm" preferred-height="8.84cm"/></paragraph-text><paragraph-text type="body"><media id="media197.png" file-name="cpc-def-G06T-0197.png" type="png" preferred-width="11.55cm" preferred-height="9.4cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T11/008</classification-symbol><definition-title>{Specific post-processing after tomographic reconstruction, e.g. voxelisation, metal artifact correction}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Specific post-processing after tomographic reconstruction</paragraph-text></list-item><list-item><paragraph-text type="body">Processing which relies essentially on unique properties of tomographic images, e.g. projection geometry or interactions of radiation with matter</paragraph-text></list-item><list-item><paragraph-text type="body">Voxelisation</paragraph-text></list-item><list-item><paragraph-text type="body">Artefact correction (e.g. scatter, metal, cone-beam)</paragraph-text></list-item></list><paragraph-text type="body">Example: Method for post- reconstructive correction of images of a computer tomograph</paragraph-text><paragraph-text type="body"><media id="media198.png" file-name="cpc-def-G06T-0198.png" type="png" preferred-width="14.29cm" preferred-height="9.61cm"/></paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T11/203</classification-symbol><definition-title>{Drawing of straight lines or curves}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Rendering, scan conversion of vectors, lines, ellipses, circles</paragraph-text></list-item><list-item><paragraph-text type="body">Offset curves, contour curves</paragraph-text></list-item><list-item><paragraph-text type="body">Wide, thick lines or strokes</paragraph-text></list-item><list-item><paragraph-text type="body">Splines, B-splines, NURBS; B&#233;zier, algebraic, parametric, polynomial, cubic curves</paragraph-text></list-item><list-item><paragraph-text type="body">Approximation of curves or polygons</paragraph-text></list-item><list-item><paragraph-text type="body">Antialiasing of lines and curves; e. g. using supersampling; subpixel or area weighting</paragraph-text></list-item><list-item><paragraph-text type="body">Font rendering, e.g. scalable, outline, contour, edge fonts</paragraph-text></list-item><list-item><paragraph-text type="body">Sketching; freehand curve drawing</paragraph-text></list-item></list><paragraph-text type="body"><media id="media201.png" file-name="cpc-def-G06T-0201.png" type="png" preferred-width="9.61cm" preferred-height="4.32cm"/></paragraph-text><paragraph-text type="body"><media id="media202.png" file-name="cpc-def-G06T-0202.png" type="png" preferred-width="7.24cm" preferred-height="7.05cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Vehicle instruments</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">B60K35/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Printer fonts</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06K15/02</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Vector coding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T9/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Filling a planar surface by adding surface attributes</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T11/40</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Entering handwritten data</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F3/04883</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Font handling; Temporal or kinetic typography</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F40/109</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Feature extraction by contour coding</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V10/469</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Display character generators</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G09G5/24</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T11/206</classification-symbol><definition-title>{Drawing of charts or graphs}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Illustrative examples:</paragraph-text><paragraph-text type="body"><media id="media203.png" file-name="cpc-def-G06T-0203.png" type="png" preferred-width="8cm" preferred-height="9.57cm"/></paragraph-text><paragraph-text type="body"><media id="media204.jpg" file-name="cpc-def-G06T-0204.jpg" type="jpeg" preferred-width="8.97cm" preferred-height="10.99cm"/></paragraph-text><list><list-item><paragraph-text type="body">Diagram, graph layout; directed graph; flow graph; flowchart</paragraph-text></list-item><list-item><paragraph-text type="body">Venn diagram; nested tree-map</paragraph-text></list-item><list-item><paragraph-text type="body">Pie, tile, column, bar, business charts</paragraph-text></list-item><list-item><paragraph-text type="body">2D and 3D Visualization of data; fluid flows; vector fields; scattered data</paragraph-text></list-item><list-item><paragraph-text type="body">Sketched diagrams or graphs</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Navigational instruments, e.g. for aircrafts</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G01C21/00</class-ref>, <class-ref scheme="cpc">G01C23/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">ICT specially adapted for bioinformatics-related data visualisation, e.g. displaying of maps or networks</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G16B45/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">ICT specially adapted for medical reports, e.g. generation or transmission thereof </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G16H15/00</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Animation of fluid flows, 2D character animation</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T13/60</class-ref>, <class-ref scheme="cpc">G06T13/80</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Input devices, GUIs</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F3/048</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">GUI programs, e.g. file browsers</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F9/451</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Menu systems, graphical querying</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F16/54</class-ref>, <class-ref scheme="cpc">G06F16/532</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Administration, e.g. office automation or reservations; resource or project management</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06Q10/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Finance, e.g. banking, investment or tax processing; Insurance, e.g. risk analysis or pensions</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06Q40/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Network visualisation or monitoring </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04L41/06</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T11/40</classification-symbol><definition-title>Filling a planar surface by adding surface attributes, e.g. colour or texture</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Polygon scan conversion; rasterisation</paragraph-text></list-item><list-item><paragraph-text type="body">Scan-line algorithms, fragment processing</paragraph-text></list-item><list-item><paragraph-text type="body">Antialiasing, supersampling, subpixel or coverage masks </paragraph-text></list-item><list-item><paragraph-text type="body">Tile-based rendering</paragraph-text></list-item><list-item><paragraph-text type="body">Filling of a 2D shape, e.g. polygon, circle, ellipse, region, area</paragraph-text></list-item><list-item><paragraph-text type="body">Interior/exterior determination; edge lists or edge flags</paragraph-text></list-item><list-item><paragraph-text type="body">Colour blends, gradient fills, seed filling, e.g. for vector graphics</paragraph-text></list-item></list><paragraph-text type="body">Illustrative example:</paragraph-text><paragraph-text type="body"><media id="media205.png" file-name="cpc-def-G06T-0205.png" type="png" preferred-width="9.48cm" preferred-height="10.94cm"/></paragraph-text><paragraph-text type="body"><media id="media206.jpg" file-name="cpc-def-G06T-0206.jpg" type="jpeg" preferred-width="8.51cm" preferred-height="9.06cm"/></paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Drawing or scan conversion of lines and fonts</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T11/203</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">3D image rendering (architectures)</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T15/00</class-ref> ( <class-ref scheme="cpc">G06T15/005</class-ref>) </paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Control of the frame buffer(s)</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G09G5/39</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">In patent documents the terms &quot;rasterising&quot;, &quot;scan conversion&quot; and &quot;rendering&quot; are often used as synonyms.</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2023-08-01"><classification-symbol scheme="cpc">G06T11/60</classification-symbol><definition-title>Editing figures and text; Combining figures or text</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Editing of bitmaps or vector graphics</paragraph-text></list-item><list-item><paragraph-text type="body">Page layout, page composition, e.g. photo-album, collages, business or greeting cards</paragraph-text></list-item><list-item><paragraph-text type="body">Combining small images by editing in order to generate a new (big) one</paragraph-text></list-item><list-item><paragraph-text type="body">Graphical simulations, e. g. for 2D cosmetic or hairstyle</paragraph-text></list-item><list-item><paragraph-text type="body">Electronic or desktop publishing (DTP), Page Description Language (PDL), PostScript, TeX</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Face sketching with eye witnesses</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">A61B5/117</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">PDL specifically for printers</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06K15/02</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">ICT specially adapted for processing medical images, e.g. editing </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G16H30/40</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Mosaic or panoramic images</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T3/40</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image registration</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/30</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Annotating 3D objects with text</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Input devices, GUIs</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F3/048</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Formatting, i.e. changing of presentation of documents</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F40/103</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Form filling or merging of text</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06F40/174</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Document analysis</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06V30/41</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Composing, repositioning or geometrically modifying originals, from scanning</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N1/387</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><synonyms-keywords><section-title>Synonyms and Keywords</section-title><abbreviations>
<paragraph-text type="preamble">In patent documents, the following abbreviations are often used:</paragraph-text>
<table>
<table-row><table-column><paragraph-text type="body">DTP</paragraph-text></table-column><table-column><paragraph-text type="body">Desktop Publishing</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">PDL</paragraph-text></table-column><table-column><paragraph-text type="body">Page Description Language</paragraph-text></table-column></table-row></table>
</abbreviations></synonyms-keywords></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T11/80</classification-symbol><definition-title>Creating or modifying a manually drawn or painted image using a manual input device, e.g. mouse, light pen, direction keys on keyboard</definition-title><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">This group is not used for classification. Its subject-matter is covered by <class-ref scheme="cpc">G06F3/00</class-ref> and subgroups</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T13/00</classification-symbol><definition-title>Animation</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Generating and displaying a sequence of images of artwork or model positions in order to create the effect of movement in a scene.</paragraph-text><paragraph-text type="body">Animation of data representing a 3D or 2D image model or object.</paragraph-text><paragraph-text type="body">Time related computation of 2D or 3D images, generation of a sequence of 2D or 3D images is classified in this group.</paragraph-text><paragraph-text type="body">This group is also given as classification to indicate that animation aspects are present but the invention lies in another group than <class-ref scheme="cpc">G06T13/00</class-ref>.</paragraph-text><paragraph-text type="body">Documents only dealing with related subject-matter like for example motion capture for animation or navigation in virtual worlds and merely mentioning animation in passing are not classified in <class-ref scheme="cpc">G06T13/00</class-ref> i.e. the generation of an animation has to be a substantive part of the document to be classified here.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Geometric image transformations for image warping</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T3/18</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Motion capture (for animation)</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">3D modelling for computer graphics</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T17/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Manipulation of 3D models for computer graphics</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Navigation in virtual worlds</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T19/003</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Video games</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">A63F13/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Computer aided design using simulation</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F30/3308</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Processing, recording or transmission of stereoscopic or multi-view image signals</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/10</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Model based coding of video objects</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N19/20</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Deforming meshes for animation purposes get both classifications: <class-ref scheme="cpc">G06T13/00</class-ref> or one of its subgroups and <class-ref scheme="cpc">G06T17/20</class-ref>.</paragraph-text><paragraph-text type="body">The series <class-ref scheme="cpc">G06T2213/00</class-ref> of Indexing Codes is reserved for the use of documents classified in <class-ref scheme="cpc">G06T13/00</class-ref> and subgroups. They should be allocated to documents in <class-ref scheme="cpc">G06T13/00</class-ref> and subgroups whenever relevant:</paragraph-text><table>
<table-row><table-column preferred-width="5.0cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2213/00</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> Head group of indexing scheme for animation. This symbol should not be allocated to any documents because the group only serves as an internal node in the group hierarchy.</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.0cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2213/04</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> Animation description languages: computer languages for the description of an animation.</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.0cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2213/08</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> Animation software package: also includes hardware packages for animation.</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.0cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2213/12</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> Rule based animation: e.g. rules for behaviour, script, personality.</paragraph-text></table-column></table-row></table><paragraph-text type="body">Furthermore, Indexing Codes from the series <class-ref scheme="cpc">G06T2200/00</class-ref> and <class-ref scheme="cpc">G06T2210/00</class-ref> should be allocated to documents whenever relevant. Specific symbols from these series that are especially relevant for the documents in a certain subgroup are mentioned under the &quot;Specific rules for classification&quot; of the respective subgroups.</paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Animation system</paragraph-text></table-column><table-column><paragraph-text type="body">traditional animation systems are based on key-frames, which are a succession of individual states (the position, orientation, and current shape of objects) specified by an animator or user</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;simulation (of motion)&quot; and &quot;animation&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T13/20</classification-symbol><definition-title>3D [Three Dimensional] animation</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Subject matter wherein the animated image data presents a three-dimensional image model or object.</paragraph-text><paragraph-text type="body">Means or steps for the generation of a sequence of 3D images.</paragraph-text><paragraph-text type="body">Documents in this group concern the generation of an animation of 3D objects in general and articulated 3D objects not representing characters.</paragraph-text><paragraph-text type="body">Simulations with 3D objects (e.g. bouncing balls) or 2D surfaces in 3D space (e.g. cloth) are classified here.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Nominally claimed subject-matter directed to animation with significant user interaction or manipulation</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Coding of wireframe meshes for animation</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T9/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Simulating properties, behaviour or motion of objects in video games</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">A63F2300/64</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For documents concerning both 2D and 3D animation of objects the first place priority rule is applied, i.e. they are classified only in <class-ref scheme="cpc">G06T13/20</class-ref> or its subgroups.</paragraph-text><paragraph-text type="body">Documents where cloth moves according to wind effects are classified in both subgroups <class-ref scheme="cpc">G06T13/20</class-ref> and <class-ref scheme="cpc">G06T13/60</class-ref>.</paragraph-text><paragraph-text type="body">For specific aspects of documents in this group the following additional Indexing Codes from the series <class-ref scheme="cpc">G06T2210/00</class-ref> should be allocated to documents in <class-ref scheme="cpc">G06T13/20</class-ref> and subgroups whenever relevant:</paragraph-text><paragraph-text type="body">For animation of cloth: <class-ref scheme="cpc">G06T2210/16</class-ref></paragraph-text><paragraph-text type="body">For collision of 3D objects: <class-ref scheme="cpc">G06T2210/21</class-ref></paragraph-text><paragraph-text type="body">For fluid flows: <class-ref scheme="cpc">G06T2210/24</class-ref></paragraph-text><paragraph-text type="body">For animation using particles: <class-ref scheme="cpc">G06T2210/56</class-ref></paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">CFD</paragraph-text></table-column><table-column><paragraph-text type="body">Computational fluid dynamics</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2020-01-01"><classification-symbol scheme="cpc">G06T13/205</classification-symbol><definition-title>{driven by audio data}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for the generation of an animation sequence based on audio data.</paragraph-text><paragraph-text type="body">The input is audio data, e.g. music, speech data, i.e. no written text.</paragraph-text><paragraph-text type="body">Changes e.g. in motion, colour, shape or position of objects in the animation are generated based on time events in the audio data, e.g. the beat in the music or the change of instrumentation.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Electrophonic musical instruments</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G10H</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Emotion analysis from speech for face animation or talking heads</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G10L17/26</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Lip-synchronization or synthesis of lip shapes (visemes) from speech for face animation or talking heads</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G10L21/10</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Animation based on written text</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F40/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Video editing or indexing or timing</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G11B27/00</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Documents where the audio input animates a 2D object are classified in both subgroups <class-ref scheme="cpc">G06T13/205</class-ref> and <class-ref scheme="cpc">G06T13/80</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2016-11-01"><classification-symbol scheme="cpc">G06T13/40</classification-symbol><definition-title>of characters, e.g. humans, animals or virtual beings</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Subject matter wherein the animated object exhibits lifelike motions or behaviours.</paragraph-text><paragraph-text type="body">Means or steps for the generation of an animation sequence of articulated objects representing virtual characters or for the generation of an animation sequence of &quot;body&quot; parts.</paragraph-text><paragraph-text type="body">The animated characters herein include, e.g. humans, animals or virtual beings.</paragraph-text><paragraph-text type="body">Animation of a character normally consists of an articulated skeleton surrounded by an implicitly defined volume or a wireframe surface mesh.</paragraph-text><paragraph-text type="body">Lifelike motions include walking, running, waving or talking. Lifelike behaviours include showing emotions or reactions to events.</paragraph-text><paragraph-text type="body">Animation of e.g. faces, lips, eyes, gestures, hair or feathers on a character.</paragraph-text><paragraph-text type="body">Documents concerning only the synthesizing aspect of character animations for Tele- or Videoconferencing (no image capturing, no data transmission)</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Interaction of avatars in virtual worlds</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">A63F13/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Interaction of avatars in virtual worlds for business</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06Q30/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Tele- or Video-conferencing</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N7/14</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Animation of articulated objects in general, i.e. not exclusively or not with the main application for character animation</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T13/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Garment try-on simulators</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref> , <class-ref scheme="cpc">G06T2210/16</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Computing the motion of game characters with respect to other game characters, virtual objects or elements of a game scene</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">A63F2300/6607</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Head tracking input arrangements for interaction between user and computer</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F3/012</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Eye tracking input arrangements for interaction between user and computer</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F3/013</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Emotion analysis from speech for face animation or talking heads</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G10L17/26</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Lip-synchronization or synthesis of lip shapes (visemes) from speech for face animation or talking heads</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G10L21/10</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><list><list-item><paragraph-text type="body">Documents where the characters are only 2D are classified in both subgroups <class-ref scheme="cpc">G06T13/40</class-ref> and <class-ref scheme="cpc">G06T13/80</class-ref>.</paragraph-text></list-item><list-item><paragraph-text type="body">Documents where the hair on a character is moved by wind effects are classified in both subgroups <class-ref scheme="cpc">G06T13/40</class-ref> and <class-ref scheme="cpc">G06T13/60</class-ref>.</paragraph-text></list-item><list-item><paragraph-text type="body">Documents where the animation data for the character results from motion capture of real characters are classified in both subgroups <class-ref scheme="cpc">G06T7/00</class-ref> and <class-ref scheme="cpc">G06T13/40</class-ref>.</paragraph-text></list-item></list></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Avatar</paragraph-text></table-column><table-column><paragraph-text type="body">graphical representation of the user or the user&apos;s character</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">(inverse) kinematics</paragraph-text></table-column><table-column><paragraph-text type="body">calculates the motions necessary to achieve a desired position of the character</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Mocap</paragraph-text></table-column><table-column><paragraph-text type="body">motion capture</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Motion retargeting</paragraph-text></table-column><table-column><paragraph-text type="body">transferring the motion from one character to another, different one </paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Skeleton</paragraph-text></table-column><table-column><paragraph-text type="body">tree structure composed of several joints to facilitate modelling the motion of the character</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Skinning</paragraph-text></table-column><table-column><paragraph-text type="body">technique to deform the skin from the deformation of the skeleton</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;Avatar&quot; and &quot;character&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2020-01-01"><classification-symbol scheme="cpc">G06T13/60</classification-symbol><definition-title>of natural phenomena, e.g. rain, snow, water or plants</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Subject-matter wherein the animated images are associated with natural phenomena.</paragraph-text><paragraph-text type="body">Means or steps for the generation of a simulation of natural elements or phenomena.</paragraph-text><paragraph-text type="body">Documents concerning:</paragraph-text><list><list-item><paragraph-text type="body">the simulation of rain, water, foam, water waves, clouds, fog, snow, fireworks, explosions or</paragraph-text></list-item><list-item><paragraph-text type="body">wind effects on grass, plants, flags or hair or</paragraph-text></list-item><list-item><paragraph-text type="body">growing processes of plants or beings or</paragraph-text></list-item><list-item><paragraph-text type="body">destruction processes</paragraph-text></list-item></list><paragraph-text type="body">are classified here.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="10.99cm"><paragraph-text type="body">Physical forces (other than wind) acting on 3D objects, e.g. simulation of a flying bullet or bouncing of a ball</paragraph-text></table-column><table-column preferred-width="4.05cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T13/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="10.99cm"><paragraph-text type="body">The simulation of behavioural effects of characters, e.g. the flee behaviour of sea anemons</paragraph-text></table-column><table-column preferred-width="4.05cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T13/40</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="10.99cm"><paragraph-text type="body"> Simulation of fluid flows in general (3D flows)</paragraph-text></table-column><table-column preferred-width="4.05cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T13/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="10.99cm"><paragraph-text type="body"> Simulation of fluid flows in general (2D flows)</paragraph-text></table-column><table-column preferred-width="4.05cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T13/80</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="10.99cm"><paragraph-text type="body">Computer aided design using simulation</paragraph-text></table-column><table-column preferred-width="4.05cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F30/3308</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Documents where the hair on a character is moved by wind effects are classified in both subgroups <class-ref scheme="cpc">G06T13/40</class-ref> and <class-ref scheme="cpc">G06T13/60</class-ref>.</paragraph-text><paragraph-text type="body">Documents where cloth moves according to wind effects are classified in both subgroups <class-ref scheme="cpc">G06T13/20</class-ref> and <class-ref scheme="cpc">G06T13/60</class-ref>.</paragraph-text><paragraph-text type="body">For specific aspects of documents In this group the following additional Indexing Codes from the series <class-ref scheme="cpc">G06T2210/00</class-ref> should be allocated whenever relevant:</paragraph-text><paragraph-text type="body">For fluid flows: <class-ref scheme="cpc">G06T2210/24</class-ref></paragraph-text><paragraph-text type="body">For animation using particles, e.g. fireworks, dust: <class-ref scheme="cpc">G06T2210/56</class-ref></paragraph-text><paragraph-text type="body">For weathering effects like e.g. aging, corrosion: <class-ref scheme="cpc">G06T2210/64</class-ref></paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Weathering</paragraph-text></table-column><table-column><paragraph-text type="body">aging process of material by exposure to weather, e.g. wind, water, certain temperatures </paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T13/80</classification-symbol><definition-title>2D [Two Dimensional] animation, e.g. using sprites</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><list><list-item><paragraph-text type="body">Subject matter wherein the animated image data is a 2D image object.</paragraph-text></list-item><list-item><paragraph-text type="body">Means or steps for time related computation of a sequence of 2D images, e.g. a small moveable 2D graphic pattern on a display, often used in video game animation.</paragraph-text></list-item><list-item><paragraph-text type="body">Generation of 2D animated cartoons.</paragraph-text></list-item><list-item><paragraph-text type="body">Animation of 2D text, 2D letters.</paragraph-text></list-item><list-item><paragraph-text type="body">Change over in slide shows, leafing through digital photo albums.</paragraph-text></list-item><list-item><paragraph-text type="body">General aspects of 2D morphing or keyframe interpolation.</paragraph-text></list-item><list-item><paragraph-text type="body">All documents exclusively dealing with the animation of 2D images, i.e. no 3D animation.</paragraph-text></list-item><list-item><paragraph-text type="body">Generation of 2D motion blur.</paragraph-text></list-item></list></section-body></definition-statement><references><section-title>References</section-title><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Geometric image transformations for image warping</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T3/18</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Video editing or indexing or timing</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G11B27/00</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><list><list-item><paragraph-text type="body">Documents where the animated 2D object is a character, i.e. 2D character animation, are classified in both subgroups <class-ref scheme="cpc">G06T13/40</class-ref> and <class-ref scheme="cpc">G06T13/80</class-ref>.</paragraph-text></list-item><list-item><paragraph-text type="body">Documents where the motion blur concerns only the background image are classified in both subgroups <class-ref scheme="cpc">G06T13/20</class-ref> and <class-ref scheme="cpc">G06T13/80</class-ref>.</paragraph-text></list-item><list-item><paragraph-text type="body">Documents where the audio input animates a 2D object are classified in both subgroups <class-ref scheme="cpc">G06T13/205</class-ref> and <class-ref scheme="cpc">G06T13/80</class-ref>.</paragraph-text></list-item><list-item><paragraph-text type="body">For documents concerning both 2D and 3D animation of objects with similar algorithms the first place priority rule is applied, i.e. they are classified only in <class-ref scheme="cpc">G06T13/20</class-ref> or its subgroups, not in <class-ref scheme="cpc">G06T13/80</class-ref>.</paragraph-text></list-item><list-item><paragraph-text type="body">Documents concerning morphing or warping are additionally classified with the Indexing Code <class-ref scheme="cpc">G06T2210/44</class-ref>.</paragraph-text></list-item></list></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Keyframe interpolation</paragraph-text></table-column><table-column><paragraph-text type="body">generation of a smooth transition between a starting and an ending keyframe</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Morphing</paragraph-text></table-column><table-column><paragraph-text type="body">continuous transformation between images (shape and colour)</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Sprite</paragraph-text></table-column><table-column><paragraph-text type="body">2D image or animation that is integrated into a larger 2D scene</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Warping</paragraph-text></table-column><table-column><paragraph-text type="body">geometric transformation of the 2D object shape</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;Keyframe interpolation&quot; and &quot;inbetweening&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Morphing&quot; and &quot;warping&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T15/00</classification-symbol><definition-title>3D [Three Dimensional] image rendering</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for generating a displayable monoscopic image from a 3D model or 3D data set.</paragraph-text><paragraph-text type="body">The 3D model is a description of three-dimensional objects in a strictly defined language or data structure.</paragraph-text><paragraph-text type="body">A 3D data set may include voxel data.</paragraph-text><paragraph-text type="body">Included in this group are input data sets of 3D coordinates or higher.</paragraph-text><paragraph-text type="body">This group covers the geometry subsystem of the graphics rendering pipeline, i.e. modeling transformation, lighting, viewing transformation, clipping, mapping to viewport.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Rasterization</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T11/40</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Visualization of models without surface characteristics or attributes</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T17/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Manipulation and visualization of 3D models for computer graphics</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image signal generator</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/20</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Video games</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">A63F13/00</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">The boundaries between <class-ref scheme="cpc">G06T15/00</class-ref> (in particular <class-ref scheme="cpc">G06T15/08</class-ref> and <class-ref scheme="cpc">G06T15/10</class-ref>) on the one hand, and <class-ref scheme="cpc">G06T3/06</class-ref> and subgroups on the other hand is not yet completely determined. Thus double classification should be considered.</paragraph-text><paragraph-text type="body">Architectural elements are in general classified in <class-ref scheme="cpc">G06T15/005</class-ref>. However, if the architectural element is only related to a certain part or function within the graphics pipeline (e.g. texture mapping or ray tracing) the document is classified in the respective subgroup (e.g. <class-ref scheme="cpc">G06T15/04</class-ref> for texture mapping) and additionally the Indexing Code <class-ref scheme="cpc">G06T2200/28</class-ref> is assigned.</paragraph-text><paragraph-text type="body">The series <class-ref scheme="cpc">G06T2215/00</class-ref> of Indexing Codes is reserved for the use of documents classified in <class-ref scheme="cpc">G06T15/00</class-ref> and subgroups. They should be allocated to documents in <class-ref scheme="cpc">G06T15/00</class-ref> and subgroups whenever relevant:</paragraph-text><table>
<table-row><table-column preferred-width="5.0cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2215/00</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> Indexing scheme for image rendering: SHOULD BE EMPTY!</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.0cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2215/06</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> curved planar reformation of 3D line structures: CPR of tubular structures (e.g. bronchia, arteries, colon, vertebrae), deployment of line structures in 3D to a 2D plane</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.0cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2215/08</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> gnomonic or central projection: projection from a center of an object, e.g. a ball, to the surrounding surface, related to VTV (virtual television)</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.0cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2215/12</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> shadow map, environment map: generation and use of shadow maps, soft shadows, environment maps</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.0cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2215/16</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> using real world measurements to influence rendering: e.g. shadow based on actual light, viewport based on viewer&apos;s pose, texturing with real-time output from camera</paragraph-text></table-column></table-row></table></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">OpenGL</paragraph-text></table-column><table-column><paragraph-text type="body">Open Graphics Library: standard specification defining an application programming interface (API) for writing applications that produce 2D and 3D computer-graphics</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Direct3D</paragraph-text></table-column><table-column><paragraph-text type="body">standard specification defining an API for writing graphic applications; is part of DirectX</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Graphics pipeline</paragraph-text></table-column><table-column><paragraph-text type="body">rendering pipeline</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;rasterization&quot; and &quot;rendering&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2016-11-01"><classification-symbol scheme="cpc">G06T15/005</classification-symbol><definition-title>{General purpose rendering architectures}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Functional or operational structure of an image rendering computer system.</paragraph-text><paragraph-text type="body">Documents in this group focus largely on the way by which the central processing unit (CPU) performs internally with the different units (e.g. the GPU) and accesses memories.</paragraph-text><paragraph-text type="body">Information relevant is the selection and interconnection of hardware components or functional units in 3D rendering systems.</paragraph-text><paragraph-text type="body">Hardware and software shader units.</paragraph-text><paragraph-text type="body">This subgroup is given as classification if the document covers elements of the whole pipeline architecture or if the architectural element covers multiple functions of the graphics pipeline.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Architectures for general purpose image data processing</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T1/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Memory management for general purpose image data processing</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T1/60</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Program control in graphics processors</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F9/44</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Use of graphics processors for other purposes than rendering</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F9/44</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Graphics controllers, e.g. control of visual indicators or display of a graphic pattern</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G09G5/363</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">GPU</paragraph-text></table-column><table-column><paragraph-text type="body">graphics processing unit</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Shader unit</paragraph-text></table-column><table-column><paragraph-text type="body">instruction sets (in software or hardware) to calculate rendering effects on the graphics hardware</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;shader unit&quot; and &quot;hardware shader&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2016-11-01"><classification-symbol scheme="cpc">G06T15/02</classification-symbol><definition-title>Non-photorealistic rendering</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for rendering a scene in a style intended to look like a painting or drawing.</paragraph-text><paragraph-text type="body">Illustrative examples of non-photorealistic rendering may include, e.g. cartoons, sketches, paintings or drawings.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Generation of texture or colour, e.g. brush strokes</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T11/001</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;Cartoon-style rendering&quot;, &quot;Freehand-style rendering&quot;, &quot;Handmade-style rendering&quot;, &quot;Ink rendering&quot;, &quot;Painterly rendering&quot;, &quot;Pen rendering&quot;, &quot;Pencil rendering&quot;, &quot;Silhouette rendering&quot;, &quot;Sketchy rendering&quot;, &quot;Toon-Style rendering&quot; and &quot;non-photorealistic rendering&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T15/04</classification-symbol><definition-title>Texture mapping</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for applying or mapping surface detail or colour pattern to a computer-generated graphic, geometry or 3D-model.</paragraph-text><paragraph-text type="body">Texture mapping used for the generation of a surface image in final format or form is classified herein.</paragraph-text><paragraph-text type="body">MIP maps, bump mapping, displacement mapping, environment mapping, shadow maps.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Generation of texture</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T11/001</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Documents dealing with shadow maps are classified in both subgroups <class-ref scheme="cpc">G06T15/04</class-ref> and <class-ref scheme="cpc">G06T15/60</class-ref>.</paragraph-text><paragraph-text type="body">Documents dealing with environment mapping are classified in both subgroups <class-ref scheme="cpc">G06T15/04</class-ref> and <class-ref scheme="cpc">G06T15/506</class-ref>.</paragraph-text><paragraph-text type="body">Documents concerning environment maps or shadow maps are additionally classified with the Indexing Code <class-ref scheme="cpc">G06T2215/12</class-ref>.</paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Texel</paragraph-text></table-column><table-column><paragraph-text type="body">texture element or texture pixel</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2016-11-01"><classification-symbol scheme="cpc">G06T15/06</classification-symbol><definition-title>Ray-tracing</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for creating an image by tracing rays from a viewpoint through each pixel to a visible point on an object.</paragraph-text></section-body></definition-statement><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Ray casting for hidden part removal is classified in both subgroups <class-ref scheme="cpc">G06T15/06</class-ref> and <class-ref scheme="cpc">G06T15/40</class-ref>.</paragraph-text><paragraph-text type="body">Generation of a photon map via photon tracing is classified in both subgroups <class-ref scheme="cpc">G06T15/06</class-ref> and <class-ref scheme="cpc">G06T15/506</class-ref>.</paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Ray casting</paragraph-text></table-column><table-column><paragraph-text type="body">non-recursive variant of ray tracing</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;ray tracing&quot; and &quot;ray casting (especially in early patent documents)&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2018-05-01"><classification-symbol scheme="cpc">G06T15/08</classification-symbol><definition-title>Volume rendering</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for displaying a two-dimensional representation of three-dimensional volume data sets.</paragraph-text><paragraph-text type="body">Volume data sets are typically voxels or 3D data sets consisting of groups of 2D slice images acquired by e.g. CT, MRT.</paragraph-text><paragraph-text type="body">Illustrative examples of volume rendering techniques are Direct Volume Rendering Techniques (e.g. splatting, shear warp), Maximum Intensity Projection (MIP), Minimum Intensity Projection, Curved Planar Reformation (CPR), Multiplanar Reformatting (MPR), Curved Multiplanar Reformatting (CMPR).</paragraph-text><paragraph-text type="body">Technical details of the projection or mapping technique used for volume rendering.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Definition of the position of the projection plane, surface or curve for volume rendering</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref> , <class-ref scheme="cpc">G06T2219/008</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Volumetric displays for the representation of 3D data sets</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N13/388</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Documents concerning curved planar reformation of tubular structures are additionally classified with the symbol <class-ref scheme="cpc">G06T2215/06</class-ref> .</paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">CMPR</paragraph-text></table-column><table-column><paragraph-text type="body">Curved Multi-Planar Reformatting</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">CPR</paragraph-text></table-column><table-column><paragraph-text type="body">Curved Planar Reformation</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">MIP</paragraph-text></table-column><table-column><paragraph-text type="body">Maximum (or Minimum) Intensity Projection</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">MPR</paragraph-text></table-column><table-column><paragraph-text type="body">Multi-Planar Reformatting</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;curved Planar Reformatting&quot;, &quot;curved Multiplanar Reformatting&quot;, &quot;curved Multiplanar Reformation&quot;, &quot;deployment&quot; and &quot;Curved Planar Reformation&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T15/10</classification-symbol><definition-title>Geometric effects</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for changing the visualization of a graphical object due to view transformations.</paragraph-text><paragraph-text type="body">Generation of views, multiple views.</paragraph-text><paragraph-text type="body">Visualization of a graphical object through projection, e.g. parallel projections, oblique projections, gnomonic projections</paragraph-text><paragraph-text type="body">Mapping of the 3D graphical object on a subspace for visualization, e.g. on (a part of) a plane or on a surface in 3D space (e.g. a bend virtual screen)</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Visualization of volume data sets</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T15/08</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Perspective projections</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T15/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Changes in the visualization related to lighting effects</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T15/50</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Changes in the visualization due to geometric transformations of the object (rotation, translation etc.)</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Stereoscopic imaging or 3D displays</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N13/00</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Geometric transformations in the plane of the image, i.e. from 2D to 2D</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T3/00</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">The boundaries between <class-ref scheme="cpc">G06T15/10</class-ref> on the one hand, and <class-ref scheme="cpc">G06T3/08</class-ref> on the other hand is not yet completely determined. Thus double classification should be considered.</paragraph-text><paragraph-text type="body">Documents concerning gnomonic or central projections are additionally classified with the Indexing Code <class-ref scheme="cpc">G06T2215/08</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2018-05-01"><classification-symbol scheme="cpc">G06T15/20</classification-symbol><definition-title>Perspective computation</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for presenting a 3D-object on a screen such that objects closer to the viewpoint appear larger than if farther from the viewpoint.</paragraph-text><paragraph-text type="body">Perspective projections of graphical objects.</paragraph-text><paragraph-text type="body">Subject matter related to details of viewpoint determination or computation with claimed or disclosed rendering aspects.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">View determination or computation without rendering</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Changing the viewpoint for navigation without details of view generation</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T19/003</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Transformation of image signals corresponding to virtual viewpoints</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/111</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Changing parameters of virtual cameras in video games</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">A63F2300/66</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Navigational Instruments, e.g. visual route guidance with on-board computers using 3D or perspective road maps</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G01C21/3635</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Interaction techniques, e.g. control of the viewpoint to navigate in a 3D environment</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F3/04815</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">TV systems, e.g. alteration of picture orientation, perspective, position etc.</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N5/2628</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Stereoscopic images</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">H04N13/00</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Multiple views</paragraph-text></table-column><table-column><paragraph-text type="body">rendering a graphical object seen from different viewpoints</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">View generation</paragraph-text></table-column><table-column><paragraph-text type="body">visual rendering of geometric properties of a graphical object seen from a certain viewpoint</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Viewpoint alteration</paragraph-text></table-column><table-column><paragraph-text type="body">change of a viewpoint (of a virtual camera)</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Virtual camera</paragraph-text></table-column><table-column><paragraph-text type="body">display of a view of a 3D virtual world</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Virtual Studio</paragraph-text></table-column><table-column><paragraph-text type="body">technological tools for simulating a physical television or movie studio, the image of the virtual camera is rendered in real-time from the same perspective as the real camera in 3D space</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2017-01-01"><classification-symbol scheme="cpc">G06T15/205</classification-symbol><definition-title>{Image-based rendering}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for rendering a 3D-object or scene using a set of two-dimensional images of it.</paragraph-text><paragraph-text type="body">Generation of a new view of a graphics object exclusively from 2D images of the object without prior generation of a 3D model.</paragraph-text><paragraph-text type="body">Rendering using billboards.</paragraph-text><paragraph-text type="body">Pixel based rendering or point based rendering of 3D objects which are not volume data.</paragraph-text><paragraph-text type="body">Depth image-based rendering.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">From multiple images</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/55</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Determining parameters from multiple pictures</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/97</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Splatting of volume data</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T15/08</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Rendering of a 3D model generated from 2D images of it </paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T17/00</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">IBR</paragraph-text></table-column><table-column><paragraph-text type="body">image-based rendering</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Billboard</paragraph-text></table-column><table-column><paragraph-text type="body">textured rectangles that are used as simplified version of 3D models for rendering</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2016-11-01"><classification-symbol scheme="cpc">G06T15/30</classification-symbol><definition-title>Clipping</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for eliminating those portions of graphics primitives that extend beyond a predetermined region.</paragraph-text><paragraph-text type="body">The predetermined region may include a viewing volume or any subset of the view volume of any shape.</paragraph-text><paragraph-text type="body">The shape of the graphics primitives that partly extend beyond the predetermined region is modified.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Cropping of 2D images</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T11/60</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Documents where a bounding box or shape is defined or used are additionally classified with the Indexing Code <class-ref scheme="cpc">G06T2210/12</class-ref>.</paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Bounding box or bounding shape</paragraph-text></table-column><table-column><paragraph-text type="body">minimal box or convex polygon surrounding the graphic object</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Viewport</paragraph-text></table-column><table-column><paragraph-text type="body">rectangular area on the screen for displaying the rendered graphical object</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;viewing volume&quot;, &quot;view volume&quot; and &quot;view frustum&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T15/40</classification-symbol><definition-title>Hidden part removal</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for determining which surfaces or part of surfaces of a graphic object are visible from a certain viewpoint and optionally removing them.</paragraph-text><paragraph-text type="body">Hidden surface or line removal.</paragraph-text><paragraph-text type="body">Culling, e.g. frustum culling, backface culling, frontface culling, occlusion culling. Culling removes graphics objects or scene graph nodes that are completely falling outside the view frustum. This is usually performed before clipping.</paragraph-text></section-body></definition-statement><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">VSD</paragraph-text></table-column><table-column><paragraph-text type="body">visible surface determination</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2016-11-01"><classification-symbol scheme="cpc">G06T15/405</classification-symbol><definition-title>{using Z-buffer}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for determining which surfaces or parts of surfaces of a graphic object are visible from a certain viewpoint and optionally removing them using Z-Buffer information.</paragraph-text></section-body></definition-statement><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;Z-Buffer&quot; and &quot;Depth-Buffer&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T15/50</classification-symbol><definition-title>Lighting effects</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for determining intensity or colour on a surface of an object based on interaction of light with the object, considering surface properties or its orientation.</paragraph-text></section-body></definition-statement></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T15/503</classification-symbol><definition-title>{Blending, e.g. for anti-aliasing}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for computing an image or pixel-value form several (source) images or pixel-values taking into account their weighting factors.</paragraph-text><paragraph-text type="body">Weighting factors are usually opacity or transparency associated values.</paragraph-text><paragraph-text type="body">Compositing.</paragraph-text><paragraph-text type="body">Vertex or geometry blending.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Video editing or indexing or timing</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G11B27/00</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body"> Alpha channel or alpha transparency channel</paragraph-text></table-column><table-column><paragraph-text type="body">a portion of each pixel&apos;s data that is reserved for transparency information</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Alpha compositing</paragraph-text></table-column><table-column><paragraph-text type="body">combining an image with a background to create the appearance of partial or full transparency</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Matte</paragraph-text></table-column><table-column><paragraph-text type="body">contains the coverage information, e.g. the shape of the object to be drawn</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T15/506</classification-symbol><definition-title>{Illumination models}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for computing the amount of energy absorbed, reflected, diffracted or transmitted by an object (or element) to be 3D rendered.</paragraph-text><paragraph-text type="body">Illumination models usually include composition, direction or geometry of the light source, surface orientation and/or surface properties of the object.</paragraph-text><paragraph-text type="body">Local illumination models only take into account light arriving straight from the light source.</paragraph-text><paragraph-text type="body">Global illumination models take into account light arriving after interaction with another object in the scene.</paragraph-text><paragraph-text type="body">Direct light sources, indirect light sources, multiple light sources, physically based illumination models.</paragraph-text></section-body></definition-statement><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Generation of a photon map via photon tracing is classified in both subgroups <class-ref scheme="cpc">G06T15/06</class-ref> and <class-ref scheme="cpc">G06T15/506</class-ref>.</paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">BRDF</paragraph-text></table-column><table-column><paragraph-text type="body">bidirectional reflectance distribution function</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T15/55</classification-symbol><definition-title>Radiosity</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for rendering graphic objects through computing the balancing of substantially all light energy coming toward and going away from every point on a surface.</paragraph-text><paragraph-text type="body">In radiosity, the balance of light energy is usually independent of the viewpoint.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Subject matter directed to illumination models that only consider viewpoint dependent vectors</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T15/506</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T15/60</classification-symbol><definition-title>Shadow generation</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for determination and generation of a region of darkness on an object where light is at least partially blocked by another graphical object.</paragraph-text><paragraph-text type="body">The blocking object herein might be a semitransparent object.</paragraph-text><paragraph-text type="body">Shadow computation normally refers to computation of shadow caused by one object onto another object.</paragraph-text><paragraph-text type="body">Concave Objects where the shadow caused by one portion of the object falls onto another portion of the concave object is classified herein, e.g. an &quot;L&quot; shaped object can cast a shadow from the vertical portion onto the horizontal portion.</paragraph-text></section-body></definition-statement><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Documents concerning the calculation of the position of the light source from the shadow are classified in both subgroups <class-ref scheme="cpc">G06T15/50</class-ref> and <class-ref scheme="cpc">G06T15/60</class-ref>.</paragraph-text><paragraph-text type="body">Documents concerning shadow maps are classified in both subgroups <class-ref scheme="cpc">G06T15/04</class-ref> and <class-ref scheme="cpc">G06T15/60</class-ref> and are additionally classified with the Indexing Code <class-ref scheme="cpc">G06T2215/12</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T15/80</classification-symbol><definition-title>Shading</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for assigning colour or intensity alterations or gradations in a particular area of a graphical object&apos;s surface based on its relationship with light.</paragraph-text><paragraph-text type="body">Relationship of light herein includes vector of light which consists of angle and distance or it even may include ambient light.</paragraph-text><paragraph-text type="body">Surfaces may include polygons or curved surfaces or patches.</paragraph-text><paragraph-text type="body">Interpolation of colour or shade based on vertex data or other pixels on the surface is classified herein.</paragraph-text><paragraph-text type="body">Shading caused by the object blocking light on the back side of the same object with respect to a light source is classified herein.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Shader units</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T15/005</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references></references><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Scanline interpolation</paragraph-text></table-column><table-column><paragraph-text type="body"> Interpolation of values along each surface edge linearly and interpolatation of values in the interior of each surface from left edge to rightedge, i.e. along a scanline</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T15/83</classification-symbol><definition-title>Phong shading</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for interpolating surface normals from the vertices of a graphical object in rasterizing a surface thereby calculating specular reflections on a graphical object.</paragraph-text></section-body></definition-statement></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T15/87</classification-symbol><definition-title>Gouraud shading</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for producing a smooth variation of surface intensity over a surface by bilinearly interpolating the color or intensities from the vertices of a graphical object.</paragraph-text></section-body></definition-statement></definition-item>
<definition-item date-revised="2020-01-01"><classification-symbol scheme="cpc">G06T17/00</classification-symbol><definition-title>Three dimensional [3D] modelling, e.g. data description of 3D objects</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for generating a description of a 3D model or scene.</paragraph-text><paragraph-text type="body">The 3D model description is usually generated from point clouds, 2D images, mathematical definitions for the description of curves, surfaces or volumes or data from different sensors.</paragraph-text><paragraph-text type="body">Marching Cubes, sampled distance fields.</paragraph-text><paragraph-text type="body">Image data format conversions, e.g. converting polar coordinates to rectangular coordinates or IGES to combinatorial geometry descriptions.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Depth or shape recovery</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/50</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Manipulating 3D models or images for computer graphics</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Route guidance using 3D or perspective road maps including 3D objects and buildings</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G01C21/3635</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Generation of 3D objects with NC-machines</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G05B19/4099</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">CAM (Computer aided manufacturing)</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G05D3/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">CAD (Computer aided design) in general</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F30/00</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Methods for drafting or marking-out cutting-out patterns for cloth</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">A41H3/007</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Collision detection for path planning of manipulators</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">B25J9/1666</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Collision detection for programme-controlled systems </paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G05B19/4061</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Image signal generators</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/268</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Documents concerning image data format conversion are additionally classified with the Indexing Code <class-ref scheme="cpc">G06T2210/32</class-ref> - image data format.</paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">IGES</paragraph-text></table-column><table-column><paragraph-text type="body">Initial Graphics Exchange Specification</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2016-11-01"><classification-symbol scheme="cpc">G06T17/005</classification-symbol><definition-title>{Tree description, e.g. octree, quadtree}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for generating a hierarchical tree-based description of a 3D model or scene.</paragraph-text></section-body></definition-statement><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Documents concerning scene graphs are additionally classified with the Indexing Code <class-ref scheme="cpc">G06T2210/61</class-ref> - scene description</paragraph-text></section-body></special-rules><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;Bintree or binary tree&quot; and &quot;tree structure in which each node has at most two child nodes&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Quadtree or quad tree&quot; and &quot;tree structure in which each node has at most four child nodes&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;K-tree&quot; and &quot;tree structure in which each node has at most K child nodes&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Hextree&quot; and &quot;tree structure in which each node has at most six child nodes&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Volume octree&quot; and &quot;tree structure in which each voxel is subdivided into at most 8 subvoxels&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Surface octree&quot; and &quot;Volume octree with incorporated surface information&quot;</paragraph-text></list-item><list-item><paragraph-text type="body">&quot;Multi tree&quot; and &quot;directed acyclic graph in which the set of nodes reachable from any node forms a tree&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T17/05</classification-symbol><definition-title>Geographic models</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for generating 3D models which relate to geographic data.</paragraph-text><paragraph-text type="body">The geographic data is usually obtained from different sensors, e.g. LIDAR, stereo photogrammetry from aerial surveys, radar, infrared cameras, GPS, satellite photography and maps e.g. topographic maps, road maps, development plans.</paragraph-text><paragraph-text type="body">Digital Elevation Models (DEM), contour maps, digital cartography.</paragraph-text><paragraph-text type="body">Superimposing or overlaying of registered geographic data from different sensors.</paragraph-text><paragraph-text type="body">Editing of maps, e.g. modelling of roofs or generation of 3D models for buildings displayed on a map.</paragraph-text><paragraph-text type="body">Map revision, map updating.</paragraph-text><paragraph-text type="body">Calculation of visibility fields for geographic areas.</paragraph-text><paragraph-text type="body">Geographical fractal modeling.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Determination of transform parameters for the alignment of images, i.e. image registration</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/30</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Navigation in a road network, GPS for navigation</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G01C21/26</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Navigational Instruments, e.g. visual route guidance using 3D or perspective road maps (including 3D objects and buildings)</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G01C21/3635</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Geometric image transformations for image registration</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T3/14</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">This subgroup is an application oriented group. Therefore, whenever possible, documents classified herein should also be classified in a function oriented group.</paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">GIS</paragraph-text></table-column><table-column><paragraph-text type="body">Geographic Information Systems</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">AMS</paragraph-text></table-column><table-column><paragraph-text type="body">Automated Mapping System</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><section-body><paragraph-text type="preamble">In patent documents the following expressions are often used as synonyms:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Chorography</paragraph-text></table-column><table-column><paragraph-text type="body">description of a landscape</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Choropleth map</paragraph-text></table-column><table-column><paragraph-text type="body">thematic map</paragraph-text></table-column></table-row></table></section-body></synonyms-keywords></definition-item>
<definition-item date-revised="2016-11-01"><classification-symbol scheme="cpc">G06T17/10</classification-symbol><definition-title>Constructive solid geometry [CSG] using solid primitives, e.g. cylinders, cubes</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for generating 3D models using boundary or volumetric representations of solid primitive objects.</paragraph-text><paragraph-text type="body">Incremental feature generation, feature modification or modelling, feature-based design is classified here.</paragraph-text><paragraph-text type="body">Solid modelling via sheet modelling or via sweeping or extrusion of contours, areas or volumes, e.g. the generation of sweep objects or generalized cylinders.</paragraph-text><paragraph-text type="body">Modelling of solids using volumetric representations, an &quot;alternating sum of volumes&quot; process, volume or convex decomposition or boundary representations.</paragraph-text><paragraph-text type="body">Generation of 3D objects from 2D line drawings.</paragraph-text></section-body></definition-statement><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For specific aspects of documents In this group the following additional Indexing Codes from the series <class-ref scheme="cpc">G06T2210/00</class-ref> should be allocated whenever relevant:</paragraph-text><paragraph-text type="body">For convex hull for 3D objects: <class-ref scheme="cpc">G06T2210/12</class-ref></paragraph-text><paragraph-text type="body">For collision detection or intersection of 3D objects: <class-ref scheme="cpc">G06T2210/21</class-ref></paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">B-rep or BREP</paragraph-text></table-column><table-column><paragraph-text type="body">boundary representation</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Alternating sum of volumes (ASV) process</paragraph-text></table-column><table-column><paragraph-text type="body">a convex decomposition method for volumetric objects</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;sweep object&quot; and &quot;generalized cylinder&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2020-01-01"><classification-symbol scheme="cpc">G06T17/20</classification-symbol><definition-title>Finite element generation, e.g. wire-frame surface description, {tesselation}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for the generation or modification of polygonal surface descriptions of 3D models or parts thereof.</paragraph-text><paragraph-text type="body">Meshes, grids, tessellations, tessellated surface patches, triangulations, tilings are classified here.</paragraph-text><paragraph-text type="body">Delaunay triangulation, Voronoi diagrams.</paragraph-text><paragraph-text type="body">Concatenation of tessellated surface patches, T-junctions.</paragraph-text><paragraph-text type="body">Meshes for finite element modelling.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Compression using wireframes</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T9/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Computer-aided design using finite element methods</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F30/23</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Seismic models</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G01V1/282</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Geologic models</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G09B23/40</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For specific aspects of documents In this group the following additional Indexing Codes from the series <class-ref scheme="cpc">G06T2210/00</class-ref> should be allocated whenever relevant:</paragraph-text><paragraph-text type="body">For modelling of cloth: <class-ref scheme="cpc">G06T2210/16</class-ref></paragraph-text><paragraph-text type="body">For collision detection or intersection of 3D objects: <class-ref scheme="cpc">G06T2210/21</class-ref></paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">FEM</paragraph-text></table-column><table-column><paragraph-text type="body">Finite element modelling</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">TIN</paragraph-text></table-column><table-column><paragraph-text type="body">Triangulated irregular network</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">T-junction</paragraph-text></table-column><table-column><paragraph-text type="body">a spot where two polygons meet along the edge of another polygon</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T17/205</classification-symbol><definition-title>{Re-meshing}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for modifying the structure of a mesh by inserting or deleting mesh vertices.</paragraph-text><paragraph-text type="body">Generation of meshes with different level of detail from a source mesh.</paragraph-text><paragraph-text type="body">Refinement or simplification of meshes, honeycomb scheme.</paragraph-text><paragraph-text type="body">The refinement or coarsening may be locally or globally.</paragraph-text></section-body></definition-statement><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Documents concerning the generation of meshes with different levels of detail are additionally classified with the Indexing Code <class-ref scheme="cpc">G06T2210/36</class-ref>.</paragraph-text></section-body></special-rules></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T17/30</classification-symbol><definition-title>Polynomial surface description</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for generating a meshfree surface description.</paragraph-text><paragraph-text type="body">Polynomial surface descriptions, e.g. NURBS, B&#233;zier surfaces, B-spline surfaces, Coons patches, Tensor product patches, without mesh generation or visualization based on tessellations.</paragraph-text><paragraph-text type="body">Analytical surface descriptions.</paragraph-text><paragraph-text type="body">Free-form surfaces.</paragraph-text></section-body></definition-statement><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">NURBS</paragraph-text></table-column><table-column><paragraph-text type="body">Non-Uniform Rational B-Spline</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T19/00</classification-symbol><definition-title>Manipulating 3D models or images for computer graphics</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for changing 3D models, for adding information or for changing the visualization via a user interface.</paragraph-text><paragraph-text type="body">View determination or computation without rendering details, geometric transformations of the whole 3D object to change the viewpoint.</paragraph-text><paragraph-text type="body">Manipulating 3D models by multiple users in a collaborative environment.</paragraph-text><paragraph-text type="body">Annotating or labelling of 3D models with text, markers</paragraph-text><paragraph-text type="body">Dimensioning and tolerancing of 3D models, e.g. display of dimension information for each part</paragraph-text><paragraph-text type="body">Display of 3D models as an exploded view drawing.</paragraph-text><paragraph-text type="body">Unfolding or flattening of 3D models or graphs.</paragraph-text><paragraph-text type="body">Positioning or defining a cut plane or a curved surface in a 3D volume data set, e.g. for projection in volume rendering.</paragraph-text><paragraph-text type="body">Manipulating 3D data while displaying or updating several views at the same time, e.g. top, front, and side view or sagittal, coronal, and axial view for medical applications.</paragraph-text><paragraph-text type="body">Virtual try-on or virtual 3D design systems, e.g. virtual dressing or fitting-rooms, virtual mannequins, virtual interior or garden design, architectural design, virtual car configurators.</paragraph-text><paragraph-text type="body">For documents in this group the function of manipulating 3D objects is prevailing, not the details how it is achieved. Therefore, the documents are usually general and do not contain specific technical details, e.g. documents concerning the change of the viewpoint via a GUI are classified here whereas documents with mathematical details on the change of the viewpoint and the frustum are classified in <class-ref scheme="cpc">G06T15/20</class-ref>.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">CAD-CAM (Computer Aided Design and Manufacturing)</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G05B19/4097</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Generation of 3D objects with NC-machines</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G05B19/4099</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Interaction techniques for graphical user interfaces</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F3/048</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">2D cosmetic or hairstyle simulations</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T11/60</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Video games</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">A63F13/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Computer-aided design</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F30/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Transformation of image signals corresponding to virtual viewpoints</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/111</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">The boundaries between <class-ref scheme="cpc">G06T19/00</class-ref> on the one hand, and <class-ref scheme="cpc">G06T3/06</class-ref> and subgroups and <class-ref scheme="cpc">G06T3/08</class-ref> on the other hand is not yet completely determined. Thus double classification should be considered.</paragraph-text><paragraph-text type="body">The Indexing Code series <class-ref scheme="cpc">G06T2219/00</class-ref> and below is reserved for documents classified in <class-ref scheme="cpc">G06T19/00</class-ref> and subgroups. They should be allocated to documents in <class-ref scheme="cpc">G06T19/00</class-ref> whenever relevant:</paragraph-text><table>
<table-row><table-column preferred-width="5.01cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/00</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> Indexing scheme for manipulating 3D models or images for computer graphics: SHOULD BE EMPTY!</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.01cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/004</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> annotating, labelling: annotating or labelling of 3D models or 3D images with text or markers</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.01cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/008</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> cut plane or projection plane definition: positioning or defining a cut plane or a curved surface in a 3D volume data set, e.g. for projection in volume rendering</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.01cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/012</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> dimensioning, tolerancing: dimensioning or tolerancing of 3D models, e.g. display of dimension information for each part of the model</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.01cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/016</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> exploded view: displaying 3D models as an exploded view drawing</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.01cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/021</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> flattening: unfolding or flattening of 3D models or graphs in a 2D plane</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.01cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/024</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> multi-user, collaborative environment: collaborative environments, multi-user environments</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="5.01cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/028</class-ref></paragraph-text></table-column><table-column preferred-width="10.03cm"><paragraph-text type="body"> multiple view windows (top-side-front-sagittal-orthogonal): manipulating 3D data while displaying or updating several views at the same time, e.g. sagittal, axial, and coronal view or top, side, and front view</paragraph-text></table-column></table-row></table><paragraph-text type="body">The Indexing Code series <class-ref scheme="cpc">G06T2219/20</class-ref> and below is reserved exclusively for documents classified in <class-ref scheme="cpc">G06T19/20</class-ref>. To each document classified in <class-ref scheme="cpc">G06T19/20</class-ref> at least one of the symbols from this series should be allocated:</paragraph-text><table>
<table-row><table-column preferred-width="4.68cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/20</class-ref></paragraph-text></table-column><table-column preferred-width="10.36cm"><paragraph-text type="body"> Indexing scheme for editing of 3D models: SHOULD BE EMPTY!</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="4.68cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/2004</class-ref></paragraph-text></table-column><table-column preferred-width="10.36cm"><paragraph-text type="body"> aligning objects, relative positioning of parts: aligning graphical objects or relative positioning of parts of a 3D model</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="4.68cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/2008</class-ref></paragraph-text></table-column><table-column preferred-width="10.36cm"><paragraph-text type="body"> assembling, disassembling: assembling and disassembling of parts of a 3D model</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="4.68cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/2012</class-ref></paragraph-text></table-column><table-column preferred-width="10.36cm"><paragraph-text type="body"> colour coding, editing, changing, or manipulating: colour modifications, e.g. colour coding, use of pseudo-colour, highlighting object parts in a different colour</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="4.68cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/2016</class-ref></paragraph-text></table-column><table-column preferred-width="10.36cm"><paragraph-text type="body"> rotation, translation, scaling: Euclidian transformations of the object or parts thereof, i.e. rotation, translation/dragging/shifting, reflection/mirroring, or size changes of a 3D object or parts thereof</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="4.68cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/2021</class-ref></paragraph-text></table-column><table-column preferred-width="10.36cm"><paragraph-text type="body"> shape modification: shape modifications of a 3D object, e.g. adding or deleting parts of the object, shearing, free-form deformations</paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="4.68cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T2219/2024</class-ref></paragraph-text></table-column><table-column preferred-width="10.36cm"><paragraph-text type="body"> style variation: modifications of the display style, e.g. changes of patterns for surfaces, change of line drawing style (e.g. bold lines, dotted lines), displaying more details of an object or of parts thereof in a separate window</paragraph-text></table-column></table-row></table><paragraph-text type="body">Furthermore, symbols from the Indexing Code series <class-ref scheme="cpc">G06T2200/00</class-ref> and below as well as <class-ref scheme="cpc">G06T2210/00</class-ref> and below should be allocated to documents in <class-ref scheme="cpc">G06T19/00</class-ref> and subgroups whenever relevant.</paragraph-text><paragraph-text type="body">For the documents in the group <class-ref scheme="cpc">G06T19/00</class-ref> the following additional symbols from the Indexing Code series <class-ref scheme="cpc">G06T2210/00</class-ref> and below are especially relevant and should be allocated whenever possible:</paragraph-text><paragraph-text type="body">For architectural design: <class-ref scheme="cpc">G06T2210/04</class-ref></paragraph-text><paragraph-text type="body">For bandwidth reduction: <class-ref scheme="cpc">G06T2210/08</class-ref></paragraph-text><paragraph-text type="body">Convex hull for 3D objects: <class-ref scheme="cpc">G06T2210/12</class-ref></paragraph-text><paragraph-text type="body">For virtual dressing rooms: <class-ref scheme="cpc">G06T2210/16</class-ref></paragraph-text><paragraph-text type="body">For collision detection of 3D objects: <class-ref scheme="cpc">G06T2210/21</class-ref></paragraph-text><paragraph-text type="body">For medical applications concerning e.g. heart, lung, brain, tumours: <class-ref scheme="cpc">G06T2210/41</class-ref></paragraph-text></section-body></special-rules></definition-item>
<definition-item date-revised="2021-08-01"><classification-symbol scheme="cpc">G06T19/003</classification-symbol><definition-title>{Navigation within 3D models or images}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for generating a sequence of images of a virtual movement (e.g. flight, walk, sail) through a 3D space or scene.</paragraph-text><paragraph-text type="body">Navigation path or flight path determination.</paragraph-text><paragraph-text type="body">Virtual navigation within human or animal bodies or organs, e.g. virtual medical endoscopy of the colon, of the ventricular system, of the vascular system, of the bronchial tree, or within 3D objects, e.g. virtual inspection of pipeline tubes.</paragraph-text><paragraph-text type="body">Walk- or flight-through a virtual museum, a virtual building, a virtual landscape etc.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Navigational instruments, e.g. visual route guidance using 3D or perspective road maps (including 3D objects and buildings)</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G01C21/3635</class-ref> , <class-ref scheme="cpc">G01C21/3638</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Interaction techniques for GUIs, e.g. control of the viewpoint to navigate in a 3D environment</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06F3/04815</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><application-references><section-title>Application-oriented references</section-title><section-body><paragraph-text type="preamble">Examples of places where the subject matter of this place is covered when specially adapted, used for a particular purpose, or incorporated in a larger system:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">ICT specially adapted for processing medical images, e.g. editing </paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G16H30/40</class-ref></paragraph-text></table-column></table-row></table></section-body></application-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Segmentation; Edge detection</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/10</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Analysis of geometric attributes</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T7/60</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">3D animation</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T13/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Centreline of tubular or elongated structure</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30172</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Virtual racing games</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">A63F13/803</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">Virtual angioscopy</paragraph-text></table-column><table-column><paragraph-text type="body">virtual endoscopy of the vascular system</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Virtual bronchoscopy</paragraph-text></table-column><table-column><paragraph-text type="body">virtual endoscopy of the bronchial tree</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Virtual colonoscopy</paragraph-text></table-column><table-column><paragraph-text type="body">virtual endoscopy of the colon</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Virtual ventriculoscopy</paragraph-text></table-column><table-column><paragraph-text type="body">virtual endoscopy of the ventricular system </paragraph-text></table-column></table-row></table></section-body></glossary-of-terms><synonyms-keywords><section-title>Synonyms and Keywords</section-title><synonyms>
<paragraph-text type="preamble">In patent documents, the following words/expressions are often used as synonyms:</paragraph-text>
<list><list-item><paragraph-text type="body">&quot;virtual fly through navigation&quot;, &quot;virtual navigation&quot;, &quot;virtual flight&quot;, &quot;virtual fly-through&quot; and &quot;virtual walk-through&quot;</paragraph-text></list-item></list>
</synonyms></synonyms-keywords></definition-item>
<definition-item date-revised="2018-05-01"><classification-symbol scheme="cpc">G06T19/006</classification-symbol><definition-title>{Mixed reality  (object pose determination, tracking or camera calibration for mixed reality <class-ref scheme="cpc">G06T7/00</class-ref>)}</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for generating 3D mixed reality, i.e. displaying 3D virtual model data together with 2D or 3D real-world image data or for displaying 2D virtual model data together with 3D real-world image data, e.g. real volume data.</paragraph-text><paragraph-text type="body">3D mixed reality encompasses 3D augmented reality and 3D augmented virtuality.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="10.99cm"><paragraph-text type="body">Object pose determination, tracking or camera calibration for mixed reality</paragraph-text></table-column><table-column preferred-width="4.05cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T7/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="10.99cm"><paragraph-text type="body">Mixed reality by combining 2D virtual models or text with 2D real image data</paragraph-text></table-column><table-column preferred-width="4.05cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T11/00</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="10.99cm"><paragraph-text type="body">Head-up displays, head mounted displays</paragraph-text></table-column><table-column preferred-width="4.05cm"><paragraph-text type="body"><class-ref scheme="cpc">G02B27/01</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">With head-mounted left-right displays</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/344</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body">Volumetric display, i.e. systems where the image distributed through a volume</paragraph-text></table-column><table-column><paragraph-text type="body"><class-ref scheme="cpc">H04N13/388</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references></definition-item>
<definition-item><classification-symbol scheme="cpc">G06T19/20</classification-symbol><definition-title>Editing of 3D images, e.g. changing shapes or colours, aligning objects or positioning parts</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Means or steps for changing the visual appearance of the 3D object or parts thereof or for changing the position of the 3D object or parts thereof in the visualization environment.</paragraph-text><paragraph-text type="body">Shape modifications of the 3D object, e.g. adding or deleting parts of the 3D object, shearing, free-form deformations.</paragraph-text><paragraph-text type="body">Colour modifications, e.g. colour coding, use of pseudo-colour, highlighting object parts in a different colour.</paragraph-text><paragraph-text type="body">Modifications of the display style, e.g. changes of patterns for surfaces, change of line drawing style (e.g. stroke width and pattern), displaying more details of the object or of parts thereof in a separate window).</paragraph-text><paragraph-text type="body">Shifting objects or parts thereof, aligning objects, rotating parts of the object or model, Euclidian transformations, size changes of the object or parts thereof.</paragraph-text><paragraph-text type="body">Assembling and disassembling of object parts, connecting or mating different 3D parts.</paragraph-text></section-body></definition-statement><references><section-title>References</section-title><limiting-references><section-title>Limiting references</section-title><section-body><paragraph-text type="preamble">This place does not cover:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Geometric transformations of the whole 3D object to change the viewpoint but without rendering details</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T19/00</class-ref></paragraph-text></table-column></table-row></table></section-body></limiting-references><informative-references><section-title>Informative references</section-title><section-body><paragraph-text type="preamble">Attention is drawn to the following places, which may be of interest for search:</paragraph-text><table>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Geometric image transforms in the image plane</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T3/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Colour changes in 2D images</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T11/001</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Editing of 2D images</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T11/60</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Time-related zooming on 3D objects</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T13/20</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column preferred-width="11.42cm"><paragraph-text type="body">Time-related zooming on 2D images</paragraph-text></table-column><table-column preferred-width="3.62cm"><paragraph-text type="body"><class-ref scheme="cpc">G06T13/80</class-ref></paragraph-text></table-column></table-row></table></section-body></informative-references></references><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">For the documents in the group <class-ref scheme="cpc">G06T19/00</class-ref> the following additional symbols from the Indexing Code series <class-ref scheme="cpc">G06T2210/00</class-ref> and below are especially relevant. To each document classified in <class-ref scheme="cpc">G06T19/20</class-ref> at least one of the following symbols should be allocated:</paragraph-text><paragraph-text type="body">For aligning objects, relative positioning of parts: <class-ref scheme="cpc">G06T2219/2004</class-ref></paragraph-text><paragraph-text type="body">For assembling, disassembling: <class-ref scheme="cpc">G06T2219/2008</class-ref></paragraph-text><paragraph-text type="body">For colour coding, editing, changing, or manipulating, pseudo-colours, highlighting: <class-ref scheme="cpc">G06T2219/2012</class-ref></paragraph-text><paragraph-text type="body">For rotation, translation, scaling: <class-ref scheme="cpc">G06T2219/2016</class-ref></paragraph-text><paragraph-text type="body">For shape modifications, adding or deleting parts, shearing, free form deformations: <class-ref scheme="cpc">G06T2219/2021</class-ref></paragraph-text><paragraph-text type="body">For modifications of the display style, e.g. changes of patterns for surfaces, change of line drawing style: <class-ref scheme="cpc">G06T2219/2024</class-ref></paragraph-text></section-body></special-rules><glossary-of-terms><section-title>Glossary of terms</section-title><section-body><paragraph-text type="preamble">In this place, the following terms or expressions are used with the meaning indicated:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body">DDM</paragraph-text></table-column><table-column><paragraph-text type="body">Direct deformation method</paragraph-text></table-column></table-row></table></section-body></glossary-of-terms></definition-item>
<definition-item date-revised="2024-01-01"><classification-symbol scheme="cpc">G06T2207/00</classification-symbol><definition-title>Indexing scheme for image analysis or image enhancement</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><paragraph-text type="body">Indexing Codes that relate to</paragraph-text><list><list-item><paragraph-text type="body">the modality with which the processed image was acquired</paragraph-text></list-item><list-item><paragraph-text type="body">special algorithmic details, also in the sense of further breakdown of groups</paragraph-text></list-item><list-item><paragraph-text type="body">the imaged subject or the context of the image processing</paragraph-text></list-item></list></section-body></definition-statement><special-rules><section-title>Special rules of classification</section-title><section-body><paragraph-text type="body">Whenever classifying in <class-ref scheme="cpc">G06T5/00</class-ref> and <class-ref scheme="cpc">G06T7/00</class-ref>, additional information should be classified using one or more of the Indexing Codes from the range of <class-ref scheme="cpc">G06T2207/00</class-ref>.The use of the Indexing Codes is obligatory.</paragraph-text><paragraph-text type="body">For Image acquisition modality, see Indexing Code <class-ref scheme="cpc">G06T2207/10</class-ref>. </paragraph-text><paragraph-text type="body">For Special algorithmic details, see Indexing Code <class-ref scheme="cpc">G06T2207/20</class-ref>.</paragraph-text><paragraph-text type="body">For Subject of image; Context of image processing, see Indexing Code <class-ref scheme="cpc">G06T2207/30</class-ref>.</paragraph-text><paragraph-text type="body">For example, the Indexing Codes would be used to classify that a model-based segmentation (<class-ref scheme="cpc">G06T7/12</class-ref> and <class-ref scheme="cpc">G06T7/149</class-ref>) using an active shape model (<class-ref scheme="cpc">G06T2207/20124</class-ref>) is done on a CT image (<class-ref scheme="cpc">G06T2207/10081</class-ref>) of the heart (<class-ref scheme="cpc">G06T2207/30048</class-ref>), or to classify that extrinsic camera parameters (<class-ref scheme="cpc">G06T7/80</class-ref>) are determined for an infrared camera (<class-ref scheme="cpc">G06T2207/10048</class-ref>) mounted on a car facing to the exterior of the car (<class-ref scheme="cpc">G06T2207/30252</class-ref>), wherein multiresolution image processing is used (<class-ref scheme="cpc">G06T2207/20016</class-ref>).</paragraph-text><paragraph-text type="body">As a basic principle, the Indexing Codes from <class-ref scheme="cpc">G06T2207/00</class-ref> are applicable only in connection with <class-ref scheme="cpc">G06T5/00</class-ref> and <class-ref scheme="cpc">G06T7/00</class-ref>.</paragraph-text><paragraph-text type="body">However, not all Indexing Codes are applicable over the whole range of <class-ref scheme="cpc">G06T5/00</class-ref> and <class-ref scheme="cpc">G06T7/00</class-ref>. The following restrictions apply:</paragraph-text><list><list-item><paragraph-text type="body">The Indexing Codes in the range <class-ref scheme="cpc">G06T2207/20116</class-ref> - <class-ref scheme="cpc">G06T2207/20168</class-ref> are applicable only together with <class-ref scheme="cpc">G06T7/10</class-ref> and subgroups.</paragraph-text></list-item><list-item><paragraph-text type="body">The Indexing Codes in the range <class-ref scheme="cpc">G06T2207/20182</class-ref> - <class-ref scheme="cpc">G06T2207/20204</class-ref> are applicable only together with <class-ref scheme="cpc">G06T5/00</class-ref> and subgroups.</paragraph-text></list-item><list-item><paragraph-text type="body">The Indexing Code <class-ref scheme="cpc">G06T2207/20228</class-ref> is applicable only together with <class-ref scheme="cpc">G06T7/97</class-ref>.</paragraph-text></list-item></list><paragraph-text type="body">The following Indexing Codes are only used as nodes to build the classification hierarchy and should not contain any documents, i.e. only their subgroups are used for classification:</paragraph-text><list><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/00</class-ref></paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10</class-ref></paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10004</class-ref></paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10141</class-ref></paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20</class-ref></paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20024</class-ref></paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20112</class-ref></paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20172</class-ref></paragraph-text></list-item><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30</class-ref></paragraph-text></list-item></list><paragraph-text type="body">Moreover, the following Indexing Code is considered redundant in the context of image processing and is, thus, not used for classification:</paragraph-text><list><list-item><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10004</class-ref></paragraph-text></list-item></list></section-body></special-rules></definition-item>
<definition-item date-revised="2019-08-01"><classification-symbol scheme="cpc">G06T2207/10</classification-symbol><definition-title>Image acquisition modality</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10012</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Stereo images - image acquisition by two cameras or a single camera that is displaced acquire at least one stereo image pair</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10024</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Color image - image acquisition by color or multichannel camera; only to be used when color aspect is of some importance also in the processing</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10028</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Range image; Depth image; 3D point clouds - range image, depth image, surface image, i.e. 2D image providing depth information; 3D point clouds</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10032</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Satellite or aerial image; Remote sensing - satellite or aerial imaging; space-based; remote sensing; Fernerkundung (German expression)</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10036</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Multispectral image; Hyperspectral image - multispectral or hyperspectral radiometers in satellite or aerial imaging</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10068</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Endoscopic image - image acquisition by endoscopic instrument, e.g. ultrasound catheter, colonoscope, video endoscope, capsule/pill endoscope</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10084</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Hybrid tomography; Concurrent acquisition with multiple different tomographic modalities - image acquisition by hybrid tomographic scanner, i.e. by system that combines different tomographic modalities</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10112</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Digital tomosynthesis [DTS] - image from digital tomosynthesis [DTS], i.e. limited angle reconstruction based on radiographies</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10124</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Digitally reconstructed radiograph [DRR] - DRR reconstructed from 3D tomographic data</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10128</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Scintigraphy - image acquisition by scintigraphy or gamma camera</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10144</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Varying exposure - acquisition of multiple images with varying exposure parameters</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10148</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Varying focus - modification of focus during acquisition of single image or of multiple images</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/10152</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Varying illumination - acquisition of multiple images with varying illumination conditions</paragraph-text></table-column></table-row></table></section-body></definition-statement></definition-item>
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T2207/20</classification-symbol><definition-title>Special algorithmic details</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20008</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Globally adaptive - processing of whole image with the same parameters, e.g. the same filter weights, but parameters may vary from image to image</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20012</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Locally adaptive - processing of image in a locally differing manner; covers also the limiting of processing to a ROI</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20081</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Training; Learning - training or learning, e.g. of background for motion analysis or of model or atlas for segmentation</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20096</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Interactive definition of curve of interest - involving interactive definition of non-closed curve of interest; closed curve, see <class-ref scheme="cpc">G06T2207/20104</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20104</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Interactive definition of region of interest [ROI] - involving interactive definition of ROI; setting of closed curve or box</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20132</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Image cropping - cutting out, cropping, i.e. defining automatically a ROI of simple shape, e.g. rectangular, circular, usually for limiting the further processing to the ROI; this place does not cover manual definition of the ROI: <class-ref scheme="cpc">G06T2207/20104</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20156</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Automatic seed setting - automatic setting of seed, e.g. based on statistics of a region of interest, usually for subsequent region-growing or for edge-growing/following; this place does not cover manual seed-setting: <class-ref scheme="cpc">G06T2207/20101</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20164</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Salient point detection; Corner detection - detection of salient points, e.g. corners, T-junctions, end points; this place does not cover automatic seed setting: <class-ref scheme="cpc">G06T2207/20156</class-ref>; salient points for pattern recognition: <class-ref scheme="cpc">G06F18/00</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20201</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Motion blur correction - correcting motion blur in still image or video</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20208</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">High dynamic range [HDR] image processing; - High Dynamic Range Imaging [HDR or HDRI] from a series of conventional images of lower dynamic range</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20216</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Image averaging - averaging of multiple images</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20221</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Image fusion; Image merging - image fusion, i.e. merging of images of same subject</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/20224</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Image subtraction - subtraction of images of same subject, e.g. temporal subtraction, subtraction of images with varying illumination conditions or for masking out certain pre-segmented image parts</paragraph-text></table-column></table-row></table></section-body></definition-statement></definition-item>
<definition-item date-revised="2023-01-01"><classification-symbol scheme="cpc">G06T2207/30</classification-symbol><definition-title>Subject of image; Context of image processing</definition-title><definition-statement><section-title>Definition statement</section-title><section-body><paragraph-text type="preamble">This place covers:</paragraph-text><table>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30021</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Catheter; Guide wire - subject of image: catheter, endoscope or guide wire when imaged in biomedical image</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30052</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Implant; Prosthesis - subject of image: implant or prosthesis; also non-synthetical transplants</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30068</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Mammography; Breast - subject of image: mammography; breast, usage not limited to x-ray image</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30076</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Plethysmography - measurement of possibly periodic volume/size/position changes, e.g. due to blood flow</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30101</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Blood vessel; Artery; Vein; Vascular - subject of image: vascular structures, blood vessel, artery, vein, angiography</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30132</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Masonry; Concrete- inspection of concrete or masonry in buildings, dams, bridges, etc.</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30144</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Printing quality - inspection of printed product</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30152</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Solder - inspection of solder, electrical contacts</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30164</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Workpiece; Machine component - inspection of workpiece, e.g. machine component; Werkst&#252;ck (German expression)</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30172</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Centreline of tubular or elongated structure - determining the centreline of a tubular or elongated structure, e.g. of a lumen, vessel, colon, pipe</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30176</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Document - enhancement or analysis of document image; this place does not cover document recognition: <class-ref scheme="cpc">G06F18/00</class-ref>, <class-ref scheme="cpc">G06V</class-ref></paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30181</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Earth observation - earth observation with image from remote sensing</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30184</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Infrastructure - observation of infrastructure, e.g. urban infrastructure, roads, railway, water channel, power transmission line</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30188</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Vegetation; Agriculture - observation of vegetation areas , e.g. agriculture</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30192</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Weather; Meteorology - weather, meteorology, climate</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30204</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Marker - subject of image: artificial marker or symbol in image, e.g. used for calibration, registration or tracking</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30212</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Military - military application, e.g. target tracking</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30216</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Redeye defect - redeye defect detection and correction</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30232</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Surveillance - application in video surveillance</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30236</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Traffic on road, railway or crossing - subject of image: traffic on road, railway, crossing, square</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30241</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Trajectory - determination of trajectory, track, trace</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30244</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Camera pose - determination of camera pose, as opposed to the determination of the pose of image content</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30248</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Vehicle exterior or interior - imaging with camera placed on a vehicle, car, train, plane, boat or mobile robot</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30252</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Vehicle exterior; Vicinity of vehicle - subject of image: exterior of a vehicle; imaging from a vehicle</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30256</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Lane; Road marking - subject of image: lane, road marking, railroad, pathway</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30261</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Obstacle - subject of image: obstacle, e.g. pedestrian, other vehicle</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30264</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Parking - imaging from a vehicle, e.g. for parking aid</paragraph-text></table-column></table-row>
<table-row><table-column><paragraph-text type="body"><class-ref scheme="cpc">G06T2207/30268</class-ref></paragraph-text></table-column><table-column><paragraph-text type="body">Vehicle interior - subject of image: interior of a vehicle</paragraph-text></table-column></table-row></table></section-body></definition-statement></definition-item></definitions>